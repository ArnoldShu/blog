{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1603459783374},{"_id":"source/about/index.md","hash":"ff80bef3c6122313c935998e5ab9b14d94c1a9a6","modified":1576394226000},{"_id":"source/categories/index.md","hash":"870a13f0b74fb12583716659408e1d925d6991d3","modified":1576394226000},{"_id":"source/share/index.md","hash":"1ab4ce463dea7f4a212f736c50c35aff01d07868","modified":1576394226000},{"_id":"source/tags/index.md","hash":"bd45d2481edccd9c88360fb2dcc142b144cd1ad4","modified":1576394226000},{"_id":"source/_posts/book/2019-11-26-15.md","hash":"a145c940fd0d3215c09e5c3f9a20a0c4e68ba7a2","modified":1576394226000},{"_id":"source/_posts/book/2019-11-26-19.md","hash":"4d859ae54713f8ebfc1038a08619013ee070b516","modified":1576394226000},{"_id":"source/_posts/book/2019-11-26-20.md","hash":"53b0c14488a9ff0564b5850e3afbaade49f6bee8","modified":1576394226000},{"_id":"source/_posts/book/2019-11-26-21.md","hash":"d8726156666c52d192a9b0e15299d2482d624007","modified":1576394226000},{"_id":"source/_posts/book/2020-01-12-16.md","hash":"cd3e7ff6b90b4d832ce88365f1ec610c90e5c38b","modified":1578819697000},{"_id":"source/_posts/summary/2019-11-26.md","hash":"4b0ce09f5cd3c44d1f6e8446dff5548ba9f7ce8a","modified":1576394226000},{"_id":"source/_posts/summary/2019-12-15-15.md","hash":"22a1d9d5ccbb41c7d03c9eb78fd3c8c28c833c54","modified":1576396775000},{"_id":"source/_posts/summary/2019-12-15.md","hash":"f53773523371326f489152027db803d02b560f72","modified":1576395269000},{"_id":"source/_posts/summary/2020-03-07.md","hash":"20394135f1270a43fa23fbac778da8b0d6fb54ef","modified":1583659919000},{"_id":"source/_posts/summary/2020-03-08.md","hash":"c8475ab9d6f8e1f6df79f009d0422858f9b265e0","modified":1583660035000},{"_id":"themes/next/.editorconfig","hash":"8570735a8d8d034a3a175afd1dd40b39140b3e6a","modified":1585668906000},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1585668906000},{"_id":"themes/next/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1585668906000},{"_id":"themes/next/.gitignore","hash":"7b68ca7a46104cf9aa84ec0541a4856ab1836eca","modified":1585668906000},{"_id":"themes/next/.stylintrc","hash":"2cf4d637b56d8eb423f59656a11f6403aa90f550","modified":1585668906000},{"_id":"themes/next/.travis.yml","hash":"ecca3b919a5b15886e3eca58aa84aafc395590da","modified":1585668906000},{"_id":"themes/next/LICENSE.md","hash":"18144d8ed58c75af66cb419d54f3f63374cd5c5b","modified":1585668906000},{"_id":"themes/next/README.md","hash":"9b4b7d66aca47f9c65d6321b14eef48d95c4dff1","modified":1585668906000},{"_id":"themes/next/_config.yml","hash":"061f6c9716b937c6e9f16a1e5e77611db0e7897f","modified":1603550373770},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1585668906000},{"_id":"themes/next/gulpfile.js","hash":"1b4fc262b89948937b9e3794de812a7c1f2f3592","modified":1585668906000},{"_id":"themes/next/package.json","hash":"62fad6de02adbbba9fb096cbe2dcc15fe25f2435","modified":1585668906000},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"aa4cb7aff595ca628cb58160ee1eee117989ec4e","modified":1585668906000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"e554931b98f251fd49ff1d2443006d9ea2c20461","modified":1585668906000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1a435c20ae8fa183d49bbf96ac956f7c6c25c8af","modified":1585668906000},{"_id":"themes/next/.github/config.yml","hash":"1d3f4e8794986817c0fead095c74f756d45f91ed","modified":1585668906000},{"_id":"themes/next/.github/issue-close-app.yml","hash":"7cba457eec47dbfcfd4086acd1c69eaafca2f0cd","modified":1585668906000},{"_id":"themes/next/.github/issue_label_bot.yaml","hash":"fca600ddef6f80c5e61aeed21722d191e5606e5b","modified":1585668906000},{"_id":"themes/next/.github/lock.yml","hash":"61173b9522ebac13db2c544e138808295624f7fd","modified":1585668906000},{"_id":"themes/next/.github/mergeable.yml","hash":"0ee56e23bbc71e1e76427d2bd255a9879bd36e22","modified":1585668906000},{"_id":"themes/next/.github/release-drafter.yml","hash":"3cc10ce75ecc03a5ce86b00363e2a17eb65d15ea","modified":1585668906000},{"_id":"themes/next/.github/stale.yml","hash":"fdf82de9284f8bc8e0b0712b4cc1cb081a94de59","modified":1585668906000},{"_id":"themes/next/.github/support.yml","hash":"d75db6ffa7b4ca3b865a925f9de9aef3fc51925c","modified":1585668906000},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1585668906000},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"c7a994b9542040317d8f99affa1405c143a94a38","modified":1585668906000},{"_id":"themes/next/docs/AUTHORS.md","hash":"10135a2f78ac40e9f46b3add3e360c025400752f","modified":1585668906000},{"_id":"themes/next/docs/DATA-FILES.md","hash":"cddbdc91ee9e65c37a50bec12194f93d36161616","modified":1585668906000},{"_id":"themes/next/docs/INSTALLATION.md","hash":"af88bcce035780aaa061261ed9d0d6c697678618","modified":1585668906000},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"94dc3404ccb0e5f663af2aa883c1af1d6eae553d","modified":1585668906000},{"_id":"themes/next/docs/LICENSE.txt","hash":"368bf2c29d70f27d8726dd914f1b3211cae4bbab","modified":1585668906000},{"_id":"themes/next/docs/MATH.md","hash":"d645b025ec7fb9fbf799b9bb76af33b9f5b9ed93","modified":1585668906000},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"8b6e4b2c9cfcb969833092bdeaed78534082e3e6","modified":1585668906000},{"_id":"themes/next/languages/ar.yml","hash":"9815e84e53d750c8bcbd9193c2d44d8d910e3444","modified":1585668906000},{"_id":"themes/next/languages/de.yml","hash":"74c59f2744217003b717b59d96e275b54635abf5","modified":1585668906000},{"_id":"themes/next/languages/default.yml","hash":"45bc5118828bdc72dcaa25282cd367c8622758cb","modified":1585668906000},{"_id":"themes/next/languages/en.yml","hash":"45bc5118828bdc72dcaa25282cd367c8622758cb","modified":1585668906000},{"_id":"themes/next/languages/es.yml","hash":"c64cf05f356096f1464b4b1439da3c6c9b941062","modified":1585668906000},{"_id":"themes/next/languages/fa.yml","hash":"3676b32fda37e122f3c1a655085a1868fb6ad66b","modified":1585668906000},{"_id":"themes/next/languages/fr.yml","hash":"752bf309f46a2cd43890b82300b342d7218d625f","modified":1585668906000},{"_id":"themes/next/languages/hu.yml","hash":"b1ebb77a5fd101195b79f94de293bcf9001d996f","modified":1585668906000},{"_id":"themes/next/languages/id.yml","hash":"572ed855d47aafe26f58c73b1394530754881ec2","modified":1585668906000},{"_id":"themes/next/languages/it.yml","hash":"44759f779ce9c260b895532de1d209ad4bd144bf","modified":1585668906000},{"_id":"themes/next/languages/ja.yml","hash":"0cf0baa663d530f22ff380a051881216d6adcdd8","modified":1585668906000},{"_id":"themes/next/languages/ko.yml","hash":"0feea9e43cd399f3610b94d755a39fff1d371e97","modified":1585668906000},{"_id":"themes/next/languages/nl.yml","hash":"5af3473d9f22897204afabc08bb984b247493330","modified":1585668906000},{"_id":"themes/next/languages/pt-BR.yml","hash":"67555b1ba31a0242b12fc6ce3add28531160e35b","modified":1585668906000},{"_id":"themes/next/languages/pt.yml","hash":"718d131f42f214842337776e1eaddd1e9a584054","modified":1585668906000},{"_id":"themes/next/languages/ru.yml","hash":"e993d5ca072f7f6887e30fc0c19b4da791ca7a88","modified":1585668906000},{"_id":"themes/next/languages/tr.yml","hash":"fe793f4c2608e3f85f0b872fd0ac1fb93e6155e2","modified":1585668906000},{"_id":"themes/next/languages/uk.yml","hash":"3a6d635b1035423b22fc86d9455dba9003724de9","modified":1585668906000},{"_id":"themes/next/languages/vi.yml","hash":"93393b01df148dcbf0863f6eee8e404e2d94ef9e","modified":1585668906000},{"_id":"themes/next/languages/zh-CN.yml","hash":"a1f15571ee7e1e84e3cc0985c3ec4ba1a113f6f8","modified":1585668906000},{"_id":"themes/next/languages/zh-HK.yml","hash":"3789f94010f948e9f23e21235ef422a191753c65","modified":1585668906000},{"_id":"themes/next/languages/zh-TW.yml","hash":"8c09da7c4ec3fca2c6ee897b2eea260596a2baa1","modified":1585668906000},{"_id":"themes/next/layout/_layout.swig","hash":"6a6e92a4664cdb981890a27ac11fd057f44de1d5","modified":1585668906000},{"_id":"themes/next/layout/archive.swig","hash":"e4e31317a8df68f23156cfc49e9b1aa9a12ad2ed","modified":1585668906000},{"_id":"themes/next/layout/category.swig","hash":"1bde61cf4d2d171647311a0ac2c5c7933f6a53b0","modified":1585668906000},{"_id":"themes/next/layout/index.swig","hash":"7f403a18a68e6d662ae3e154b2c1d3bbe0801a23","modified":1585668906000},{"_id":"themes/next/layout/page.swig","hash":"db581bdeac5c75fabb0f17d7c5e746e47f2a9168","modified":1585668906000},{"_id":"themes/next/layout/post.swig","hash":"2f6d992ced7e067521fdce05ffe4fd75481f41c5","modified":1585668906000},{"_id":"themes/next/layout/tag.swig","hash":"0dfb653bd5de980426d55a0606d1ab122bd8c017","modified":1585668906000},{"_id":"themes/next/scripts/renderer.js","hash":"49a65df2028a1bc24814dc72fa50d52231ca4f05","modified":1585668906000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/bug-report.md","hash":"c3e6b8196c983c40fd140bdeca012d03e6e86967","modified":1585668906000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/feature-request.md","hash":"12d99fb8b62bd9e34d9672f306c9ae4ace7e053e","modified":1585668906000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/other.md","hash":"d3efc0df0275c98440e69476f733097916a2d579","modified":1585668906000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/question.md","hash":"53df7d537e26aaf062d70d86835c5fd8f81412f3","modified":1585668906000},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"0bd2d696f62a997a11a7d84fec0130122234174e","modified":1585668906000},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"9c4fe2873123bf9ceacab5c50d17d8a0f1baef27","modified":1585668906000},{"_id":"themes/next/docs/ru/README.md","hash":"85dd68ed1250897a8e4a444a53a68c1d49eb7e11","modified":1585668906000},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"5237a368ab99123749d724b6c379415f2c142a96","modified":1585668906000},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"34b88784ec120dfdc20fa82aadeb5f64ef614d14","modified":1585668906000},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"fb23b85db6f7d8279d73ae1f41631f92f64fc864","modified":1585668906000},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"d3f03be036b75dc71cf3c366cd75aee7c127c874","modified":1585668906000},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"ca1030efdfca5e20f9db2e7a428998e66a24c0d0","modified":1585668906000},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"579c7bd8341873fb8be4732476d412814f1a3df7","modified":1585668906000},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"8b18f84503a361fc712b0fe4d4568e2f086ca97d","modified":1585668906000},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"b92585d251f1f9ebe401abb5d932cb920f9b8b10","modified":1585668906000},{"_id":"themes/next/docs/zh-CN/README.md","hash":"c038629ff8f3f24e8593c4c8ecf0bef3a35c750d","modified":1585668906000},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"d9ce7331c1236bbe0a551d56cef2405e47e65325","modified":1585668906000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"c4ec5822d644ddcedf2401837e6f6e6d3b63fbcd","modified":1585668906000},{"_id":"themes/next/layout/_macro/post.swig","hash":"71e4dc5a56cbc403d9785526f7719d824f4c8911","modified":1585668906000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"71655ca21907e9061b6e8ac52d0d8fbf54d0062b","modified":1585668906000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"db6ab5421b5f4b7cb32ac73ad0e053fdf065f83e","modified":1585668906000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"af2d688f688923080aaf8f20be33cfda629797ea","modified":1585668906000},{"_id":"themes/next/layout/_partials/languages.swig","hash":"ba9e272f1065b8f0e8848648caa7dea3f02c6be1","modified":1585668906000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9876dbfc15713c7a47d4bcaa301f4757bd978269","modified":1585668906000},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"83a40ce83dfd5cada417444fb2d6f5470aae6bb0","modified":1585668906000},{"_id":"themes/next/layout/_scripts/index.swig","hash":"cea942b450bcb0f352da78d76dc6d6f1d23d5029","modified":1585668906000},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"d1f2bfde6f1da51a2b35a7ab9e7e8eb6eefd1c6b","modified":1585668906000},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"4d2c93c66e069852bb0e3ea2e268d213d07bfa3f","modified":1585668906000},{"_id":"themes/next/layout/_scripts/three.swig","hash":"a4f42f2301866bd25a784a2281069d8b66836d0b","modified":1585668906000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"ef38c213679e7b6d2a4116f56c9e55d678446069","modified":1585668906000},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"8627c8c8b031ecee16c522433b66fa4d6979b8ea","modified":1585668906000},{"_id":"themes/next/layout/_third-party/index.swig","hash":"70c3c01dd181de81270c57f3d99b6d8f4c723404","modified":1585668906000},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"311e5eceec9e949f1ea8d623b083cec0b8700ff2","modified":1585668906000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"2731e262a6b88eaee2a3ca61e6a3583a7f594702","modified":1585668906000},{"_id":"themes/next/scripts/events/index.js","hash":"bf5e93f9209d111a014a7a6a17e86c05be552d13","modified":1585668906000},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"aec50ed57b9d5d3faf2db3c88374f107203617e0","modified":1585668906000},{"_id":"themes/next/scripts/filters/front-matter.js","hash":"703bdd142a671b4b67d3d9dfb4a19d1dd7e7e8f7","modified":1585668906000},{"_id":"themes/next/scripts/filters/locals.js","hash":"b193a936ee63451f09f8886343dcfdca577c0141","modified":1585668906000},{"_id":"themes/next/scripts/filters/minify.js","hash":"19985723b9f677ff775f3b17dcebf314819a76ac","modified":1585668906000},{"_id":"themes/next/scripts/filters/post.js","hash":"d86849559ae54a4098aef4e2ab9dc8f99a1d186c","modified":1585668906000},{"_id":"themes/next/scripts/helpers/engine.js","hash":"22d77bd511fc7c1bbd12339d65004ed5bfb0713c","modified":1585668906000},{"_id":"themes/next/scripts/helpers/font.js","hash":"40cf00e9f2b7aa6e5f33d412e03ed10304b15fd7","modified":1585668906000},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"5e11f30ddb5093a88a687446617a46b048fa02e5","modified":1585668906000},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"958e86b2bd24e4fdfcbf9ce73e998efe3491a71f","modified":1585668906000},{"_id":"themes/next/scripts/tags/button.js","hash":"946dd7beede408d1f090d5e9774d74763828b97c","modified":1585668906000},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"94e0bbc7999b359baa42fa3731bdcf89c79ae2b3","modified":1585668906000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"0f133f27b61e8351cfd0959ba8a1b8551a9a8cc6","modified":1585668906000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"d902fd313e8d35c3cc36f237607c2a0536c9edf1","modified":1585668906000},{"_id":"themes/next/scripts/tags/label.js","hash":"fc5b267d903facb7a35001792db28b801cccb1f8","modified":1585668906000},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"983c6c4adea86160ecc0ba2204bc312aa338121d","modified":1585668906000},{"_id":"themes/next/scripts/tags/note.js","hash":"0a02bb4c15aec41f6d5f1271cdb5c65889e265d9","modified":1585668906000},{"_id":"themes/next/scripts/tags/pdf.js","hash":"8c613b39e7bff735473e35244b5629d02ee20618","modified":1585668906000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"00ca6340d4fe0ccdae7525373e4729117775bbfa","modified":1585668906000},{"_id":"themes/next/scripts/tags/video.js","hash":"e5ff4c44faee604dd3ea9db6b222828c4750c227","modified":1585668906000},{"_id":"themes/next/source/css/_colors.styl","hash":"19c836f367977fb712b9868f3281ff5d757a8d5c","modified":1585668906000},{"_id":"themes/next/source/css/_mixins.styl","hash":"b79ff3debd5709397b122292fc7e551ae9d40782","modified":1585668906000},{"_id":"themes/next/source/css/main.styl","hash":"a3a3bbb5a973052f0186b3523911cb2539ff7b88","modified":1585668906000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1585668906000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1585668906000},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1585668906000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1585668906000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1585668906000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1585668906000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1585668906000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1585668906000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1585668906000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1585668906000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1585668906000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1585668906000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1585668906000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1585668906000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1585668906000},{"_id":"themes/next/source/js/algolia-search.js","hash":"23cc3c013185eb97ef347c3b4c92d928f2f3398f","modified":1585668906000},{"_id":"themes/next/source/js/bookmark.js","hash":"a00945ff886e9f6f835731cdaf29a3a3727c8877","modified":1585668906000},{"_id":"themes/next/source/js/local-search.js","hash":"b42bd1c883ce91db8632d96e0f0e062cb6b73adc","modified":1585668906000},{"_id":"themes/next/source/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1585668906000},{"_id":"themes/next/source/js/next-boot.js","hash":"a22eeb6048ddd6b9224c8a671cbcfa303a2f7a1a","modified":1585668906000},{"_id":"themes/next/source/js/utils.js","hash":"95c5d37aa06521675afcf8619cfc5dbba3d2e18a","modified":1585668906000},{"_id":"themes/next/source/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1585668906000},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"000bad572d76ee95d9c0a78f9ccdc8d97cc7d4b4","modified":1585668906000},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"1ea12d4b9490d9065ebf1b8739b90ce5defd6398","modified":1585668906000},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"c70f8e71e026e878a4e9d5ab3bbbf9b0b23c240c","modified":1585668906000},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"7dbe93b8297b746afb89700b4d29289556e85267","modified":1585668906000},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"12aeb9ee0d1d49d347f82a91e6bab568e1b59037","modified":1585668906000},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"958e097790551c9520426a1233add03515034f35","modified":1585668906000},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"ae2261bea836581918a1c2b0d1028a78718434e0","modified":1585668906000},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"c851717497ca64789f2176c9ecd1dedab237b752","modified":1585668906000},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"9b7a66791d7822c52117fe167612265356512477","modified":1585668906000},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"94d54b0c65d504f772af1e62424952e092b6c21d","modified":1585668906000},{"_id":"themes/next/layout/_partials/post/post-followme.swig","hash":"12cd9adb0c33adc484201f9e8a4e64ccf3011bae","modified":1585668906000},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"8f14f3f8a1b2998d5114cc56b680fb5c419a6b07","modified":1585668906000},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"f79c44692451db26efce704813f7a8872b7e63a0","modified":1585668906000},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"2b1a73556595c37951e39574df5a3f20b2edeaef","modified":1585668906000},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"48430bd03b8f19c9b8cdb2642005ed67d56c6e0b","modified":1585668906000},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"2be50f9bfb1c56b85b3b6910a7df27f51143632c","modified":1585668906000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"f48a6a8eba04eb962470ce76dd731e13074d4c45","modified":1585668906000},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"ec20ff43845723e0ac2a245047c7a7e5aead6e88","modified":1585668906000},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"077b5d66f6309f2e7dcf08645058ff2e03143e6c","modified":1585668906000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1585668906000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1585668906000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1585668906000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1585668906000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"4790058691b7d36cf6d2d6b4e93795a7b8d608ad","modified":1585668906000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"2fa2b51d56bfac6a1ea76d651c93b9c20b01c09b","modified":1585668906000},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"5adea065641e8c55994dd2328ddae53215604928","modified":1585668906000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"1472cabb0181f60a6a0b7fec8899a4d03dfb2040","modified":1585668906000},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"f910618292c63871ca2e6c6e66c491f344fa7b1f","modified":1585668906000},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"cba0e6e0fad08568a9e74ba9a5bee5341cfc04c1","modified":1585668906000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"f39a5bf3ce9ee9adad282501235e0c588e4356ec","modified":1585668906000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b14908644225d78c864cd0a9b60c52407de56183","modified":1585668906000},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"82f5b6822aa5ec958aa987b101ef860494c6cf1f","modified":1585668906000},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"d6ceb70648555338a80ae5724b778c8c58d7060d","modified":1585668906000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"f7a9eca599a682479e8ca863db59be7c9c7508c8","modified":1585668906000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"be0a8eccf1f6dc21154af297fc79555343031277","modified":1585668906000},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"6c5976621efd5db5f7c4c6b4f11bc79d6554885f","modified":1585668906000},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"4791c977a730f29c846efcf6c9c15131b9400ead","modified":1585668906000},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"ecf751321e799f0fb3bf94d049e535130e2547aa","modified":1585668906000},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"d35a999d67f4c302f76fdf13744ceef3c6506481","modified":1585668906000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"767b6c714c22588bcd26ba70b0fc19b6810cbacd","modified":1585668906000},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"ba0dbc06b9d244073a1c681ff7a722dcbf920b51","modified":1585668906000},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"d7258d02bcf0dac6c0fd8377c0909ddecb09d1d4","modified":1585668906000},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"a17ace37876822327a2f9306a472974442c9005d","modified":1585668906000},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"b26ac2bfbe91dd88267f8b96aee6bb222b265b7a","modified":1585668906000},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"5f6a966c509680dbfa70433f9d658cee59c304d7","modified":1585668906000},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"d56d5af427cdfecc33a0f62ee62c056b4e33d095","modified":1585668906000},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"f3c43664a071ff3c0b28bd7e59b5523446829576","modified":1585668906000},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"d30b0e255a8092043bac46441243f943ed6fb09b","modified":1585668906000},{"_id":"themes/next/scripts/events/lib/config.js","hash":"d34c6040b13649714939f59be5175e137de65ede","modified":1585668906000},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"6661c1c91c7cbdefc6a5e6a034b443b8811235a1","modified":1585668906000},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"f233d8d0103ae7f9b861344aa65c1a3c1de8a845","modified":1585668906000},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"1f20213af8da3127701e6bb9da995e5c91be2051","modified":1585668906000},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"0803d4f4d3d02c24417c163ad0b27b60fda79250","modified":1585668906000},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"7f2d93af012c1e14b8596fecbfc7febb43d9b7f5","modified":1585668906000},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"19cbd24880d0fbbd4d5698cd54da598f03b942da","modified":1585668906000},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"7f8b92913d21070b489457fa5ed996d2a55f2c32","modified":1585668906000},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"e51dc3072c1ba0ea3008f09ecae8b46242ec6021","modified":1585668906000},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"d5fefc31fba4ab0188305b1af1feb61da49fdeb0","modified":1585668906000},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"6a72b5928cdab9526a288177991e4b2aedd028cf","modified":1585668906000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"f4e694e5db81e57442c7e34505a416d818b3044a","modified":1585668906000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"f70be8e229da7e1715c11dd0e975a2e71e453ac8","modified":1585668906000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"62df49459d552bbf73841753da8011a1f5e875c8","modified":1585668906000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"799fdf4f258a51d45d1e2b02fb59b337e46b5b3c","modified":1585668906000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"dae390efcb5da9c021ad7f25fe2d39ff36938cc6","modified":1585668906000},{"_id":"themes/next/source/js/schemes/muse.js","hash":"47c4f60eb7f7dc3303e84914b611dc34827069e1","modified":1585668906000},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"3d9d3c14b77044d66be1898a9a934696e9127c82","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1585668906000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1585668906000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"ca5e70662dcfb261c25191cc5db5084dcf661c76","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"a47725574e1bee3bc3b63b0ff2039cc982b17eff","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"8e7b57a72e757cf95278239641726bb2d5b869d1","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"2e3bf7baf383c9073ec5e67f157d3cb3823c0957","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"681d33e3bc85bdca407d93b134c089264837378c","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"a1690e035b505d28bdef2b4424c13fc6312ab049","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"220da37051ed5dac9cf7bd126451f6aba4f94d21","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"a2e9e00962e43e98ec2614d6d248ef1773bb9b78","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"b1f0fab7344a20ed6748b04065b141ad423cf4d9","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"8f58570a1bbc34c4989a47a1b7d42a8030f38b06","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"b3bea92eef0e1fe2e7e294dac2184d16b5b8d666","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"179e33b8ac7f4d8a8e76736a7e4f965fe9ab8b42","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"7785bd756e0c4acede3a47fec1ed7b55988385a5","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"f6516d0f7d89dc7b6c6e143a5af54b926f585d82","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"bb7ace23345364eb14983e860a7172e1683a4c94","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"7104b9cef90ca3b140d7a7afcf15540a250218fc","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"6136da4bbb7e70cec99f5c7ae8c7e74f5e7c261a","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"a717969829fa6ef88225095737df3f8ee86c286b","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"f0131db6275ceaecae7e1a6a3798b8f89f6c850d","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"4d1c17345d2d39ef7698f7acf82dfc0f59308c34","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"5e644b1303ab6dcd1b65ee0fd6b91309b04ce64d","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"2b2e7b5cea7783c9c8bb92655e26a67c266886f0","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"e282df938bd029f391c466168d0e68389978f120","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"70a4324b70501132855b5e59029acfc5d3da1ebd","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"ccb71d732b12acd02ac26ed6bbda4861d027857d","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e4f958677a75de87ee1caf7e22ba46a0602f22dd","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"82025c3ad7af12e532e2e81be98deb0a74ff23ac","modified":1585668906000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"fafc96c86926b22afba8bb9418c05e6afbc05a57","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"2bd0eb1512415325653b26d62a4463e6de83c5ac","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"c1daeb60c23945f745703ac2c3f4bf99d0ea3d95","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"7ddb7453bf9b85b01bff136e9d10a7f06baac9e8","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"89f76380091f1be49936c69bac02e984dae5ff87","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f49ca072b5a800f735e8f01fc3518f885951dd8e","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"902569a9dea90548bec21a823dd3efd94ff7c133","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"ded41fd9d20a5e8db66aaff7cc50f105f5ef2952","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"1e4190c10c9e0c9ce92653b0dbcec21754b0b69d","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"72d495a88f7d6515af425c12cbc67308a57d88ea","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"66211794e4ed47e779ca81150cef588e0b4f2fc5","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"796eb941ba0ca03fd5ca6d15a1f6a56afd9aa174","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"eca4d80dd0df1c3b1bc06bd39e6a4bd6c56198df","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"f5c2788a78790aca1a2f37f7149d6058afb539e0","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"99e12c9ce3d14d4837e3d3f12fc867ba9c565317","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"5b5649b9749e3fd8b63aef22ceeece0a6e1df605","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"a760ee83ba6216871a9f14c5e56dc9bd0d9e2103","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"8a7fc03a568b95be8d3337195e38bc7ec5ba2b23","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"b49e9fbd3c182b8fc066b8c2caf248e3eb748619","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"e2992846b39bf3857b5104675af02ba73e72eed5","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"9f0b93d109c9aec79450c8a0cf4a4eab717d674d","modified":1585668906000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9a878d0119785a2316f42aebcceaa05a120b9a7a","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"454a4aebfabb4469b92a8cbb49f46c49ac9bf165","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"e02b1097a72a7d2ddc45ea8d53aa6d77c25ac407","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"e7a9fdb6478b8674b1cdf94de4f8052843fb71d9","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"a793cfff86ad4af818faef04c18013077873f8f0","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"0caf32492692ba8e854da43697a2ec8a41612194","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"555762730f1f31451113e8fdc84ec438ea738d90","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"45a239edca44acecf971d99b04f30a1aafbf6906","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"b2fc519828fe89a1f8f03ff7b809ad68cd46f3d7","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"2cb1876e9e0c9ac32160888af27b1178dbcb0616","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"fa0222197b5eee47e18ac864cdc6eac75678b8fe","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"44487d9ab290dc97871fa8dd4487016deb56e123","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"a237c290e8934d1a8cbbf22b3f30503d9663021d","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"9b479c2f9a9bfed77885e5093b8245cc5d768ec7","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"a960a2dd587b15d3b3fe1b59525d6fa971c6a6ec","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"a05a4031e799bc864a4536f9ef61fe643cd421af","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"b3220db827e1adbca7880c2bb23e78fa7cbe95cb","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"a9cd93c36bae5af9223e7804963096274e8a4f03","modified":1585668906000},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"2a47f8a6bb589c2fb635e6c1e4a2563c7f63c407","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"f71a3e86c05ea668b008cf05a81f67d92b6d65e4","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"d3f73688bb7423e3ab0de1efdf6db46db5e34f80","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"35c871a809afa8306c8cde13651010e282548bc6","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"3b3acc5caa0b95a2598bef4eeacb21bab21bea56","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"7213e3d0ad7c95717ecd4e701d6ee9248ef2bf9f","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"709d10f763e357e1472d6471f8be384ec9e2d983","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"d7fce4b51b5f4b7c31d93a9edb6c6ce740aa0d6b","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"9b3cce30c58e57b59e45d3f668a71a4129d3a8e4","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"b49c64f8e9a6ca1c45c0ba98febf1974fdd03616","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"f23670f1d8e749f3e83766d446790d8fd9620278","modified":1585668906000},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"9e4c0653cfd3cc6908fa0d97581bcf80861fb1e7","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1585668906000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1585668906000},{"_id":"public/about/index.html","hash":"eb5926735fe67f4a68aefe5612deec6abab58557","modified":1603551084978},{"_id":"public/categories/index.html","hash":"fe96b842b29d91eeebaecf99a1940ec88fe9a56e","modified":1603551084978},{"_id":"public/share/index.html","hash":"351495b5fa75d5cc12a95fafad7e65072b2bf418","modified":1603551084978},{"_id":"public/tags/index.html","hash":"8a965ebcede999a3465347303692e5e3bd11a502","modified":1603551084978},{"_id":"public/2020/10/23/hello-world/index.html","hash":"bbbb28eaab8443e1e8f4c45e68cc17f780f5da2b","modified":1603550986693},{"_id":"public/2019/09/22/book/2019-11-26-21/index.html","hash":"8714538ffe4bcd0cabc67fe8bd97a4a97164958b","modified":1603551084978},{"_id":"public/2019/09/21/book/2019-11-26-20/index.html","hash":"0ab4a2d60a36cc2e493877e3e8778b793664cc09","modified":1603551084978},{"_id":"public/2019/09/02/book/2019-11-26-19/index.html","hash":"472931b30d78512277af7c76937ce47d5ae7fa30","modified":1603551084978},{"_id":"public/archives/index.html","hash":"4fe56ec632b3e3edb7d2b95019a429dc5ce90402","modified":1603551084978},{"_id":"public/archives/page/2/index.html","hash":"d035e2b62a7f5454ec8aec7d1a8986cf4ba48c46","modified":1603550986693},{"_id":"public/archives/2017/index.html","hash":"32570a957853ca9507172bf2b4b7bca4e77a01f2","modified":1603551084978},{"_id":"public/archives/2017/05/index.html","hash":"0505600798c1b82434a85d173753516a20050aab","modified":1603551084978},{"_id":"public/archives/2019/index.html","hash":"f0c4c947dd6f1dad0d36b8de5d9774afc59b2a26","modified":1603551084978},{"_id":"public/archives/2019/09/index.html","hash":"4dd55d8d6087c65f64d9e159545bc1239c551f0e","modified":1603551084978},{"_id":"public/archives/2019/12/index.html","hash":"ae68fcd052d3bc1a226648e265dfeb6dc010b007","modified":1603551084978},{"_id":"public/archives/2020/index.html","hash":"5dc9abfcdd3118970f807f84a9bd887a2244e263","modified":1603551084978},{"_id":"public/archives/2020/01/index.html","hash":"5cbbd5b4a1e27c98c26897e632ac39bfc7c4a8f9","modified":1603551084978},{"_id":"public/archives/2020/03/index.html","hash":"0a21743f7e3b07162e54d5bdcd6c21085b526b7e","modified":1603551084978},{"_id":"public/archives/2020/10/index.html","hash":"8ded4e0df623c5b5aafebc5e3739b64f85eade8a","modified":1603550986693},{"_id":"public/categories/看书摘记/index.html","hash":"10f582d7bfe757be043a14284193122f9b0113d3","modified":1603551084978},{"_id":"public/categories/日常总结/index.html","hash":"8eb538c2190551b782033970200c502193ca9b31","modified":1603551084978},{"_id":"public/page/2/index.html","hash":"56a73606a1fd7f013dd9aab7ff3afde393495248","modified":1603550986693},{"_id":"public/tags/Data-structure-and-algorithm/index.html","hash":"cc7011a7bb6f13bb360bfe7496bbe0e82540ccb1","modified":1603551084978},{"_id":"public/tags/linux/index.html","hash":"88fc08a97fd6329c592416acd3863c3d5efdd878","modified":1603551084978},{"_id":"public/tags/java/index.html","hash":"11ff1f93804150370051a8edbe5fbc7635ffff1f","modified":1603551084978},{"_id":"public/tags/annotations/index.html","hash":"f41954831ae0ab49f4aa424c2a8dcf144a5fc12b","modified":1603551084978},{"_id":"public/tags/大数据/index.html","hash":"c9cbf0424ac7487993671b7cffeb1892d2a113f7","modified":1603551084978},{"_id":"public/tags/zookeeper/index.html","hash":"47c3bea6862fb8c583543bbd5d0690474b040e71","modified":1603551084978},{"_id":"public/tags/中间件/index.html","hash":"4b030a759ff9e4ece00275d348caafb4e5a06e71","modified":1603551084978},{"_id":"public/tags/kafka/index.html","hash":"29c7e26daab9dc29e32eed8718ee8224620f729b","modified":1603551084978},{"_id":"public/tags/maven/index.html","hash":"1a67c54d32a696f8b58603390bbf2a525a8e7803","modified":1603551084978},{"_id":"public/tags/Docker/index.html","hash":"ae12340e7e591916c0af685ba9251d8b449a053a","modified":1603551084978},{"_id":"public/2020/03/08/summary/2020-03-08/index.html","hash":"3df8fa2063a1d2eeeffa6d0c18606a412d39c826","modified":1603551084978},{"_id":"public/2020/03/01/summary/2020-03-07/index.html","hash":"1fd5593e20c9f3bf8d761603fa773419db3a3f47","modified":1603551084978},{"_id":"public/2020/01/12/book/2020-01-12-16/index.html","hash":"0c30a2884755cc300e9884e74e8e0cb2a9f9472d","modified":1603551084978},{"_id":"public/2019/12/15/summary/2019-12-15-15/index.html","hash":"120a1e4456c50448bbcf531ff885fc52a847b7fa","modified":1603551084978},{"_id":"public/2019/12/15/summary/2019-12-15/index.html","hash":"163c1900d79ac5233fbf8f69e07aafb5928478d0","modified":1603551084978},{"_id":"public/2019/09/01/book/2019-11-26-15/index.html","hash":"974c3541cae02f90f9d70ee0c42d754a74b8cb7e","modified":1603551084978},{"_id":"public/2017/05/23/summary/2019-11-26/index.html","hash":"4c3066f6c1a276297e2db0482c43586e2d7286c4","modified":1603551084978},{"_id":"public/index.html","hash":"c6b7bec31b5cc60751c43870ab5f1f783f41dd63","modified":1603551084978},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1603550986693},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1603550986693},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1603550986693},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1603550986693},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1603550986693},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1603550986693},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1603550986693},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1603550986693},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1603550986693},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1603550986693},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1603550986693},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1603550986693},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1603550986693},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1603550986693},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1603550986693},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1603550986693},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1603550986693},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1603550986693},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1603550986693},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1603550986693},{"_id":"public/js/algolia-search.js","hash":"23cc3c013185eb97ef347c3b4c92d928f2f3398f","modified":1603550986693},{"_id":"public/js/bookmark.js","hash":"a00945ff886e9f6f835731cdaf29a3a3727c8877","modified":1603550986693},{"_id":"public/js/local-search.js","hash":"b42bd1c883ce91db8632d96e0f0e062cb6b73adc","modified":1603550986693},{"_id":"public/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1603550986693},{"_id":"public/js/next-boot.js","hash":"a22eeb6048ddd6b9224c8a671cbcfa303a2f7a1a","modified":1603550986693},{"_id":"public/js/utils.js","hash":"95c5d37aa06521675afcf8619cfc5dbba3d2e18a","modified":1603550986693},{"_id":"public/js/schemes/muse.js","hash":"47c4f60eb7f7dc3303e84914b611dc34827069e1","modified":1603550986693},{"_id":"public/js/schemes/pisces.js","hash":"3d9d3c14b77044d66be1898a9a934696e9127c82","modified":1603550986693},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1603550986693},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1603550986693},{"_id":"public/css/main.css","hash":"3b3816f7934491255599ad2c6f15f3ce1bac883c","modified":1603550986693},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1603550986693},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1603550986693},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1603550986693},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1603550986693}],"Category":[{"name":"看书摘记","_id":"ckgnsue1t0006bcvz9fvjh74q"},{"name":"日常总结","_id":"ckgnsue2b000obcvz8pcwf2d0"}],"Data":[],"Page":[{"_content":"# 关于我\n\njava工程师，有一位我很爱同时也很爱我的傻乎乎的未婚妻。\n\n\n\n# 热爱\njava技术栈的所有相关技术(虽然可能技术并不是每项技术都很厉害)\n家事国事天下事,事事关心的微胖少年,有趣且逐渐懂事的痞气Boy\n看书音乐都还蛮喜欢\n\n\n\n# 关于本站\n本站有一些文章可成系列，多为平时工作总结和看书所得,摘记以供回味学习,其余文章则随心所致。\n\n\n\n\n# 版权与协议\n若无特殊说明，本站所有文章均为原创文章，并遵循 CC BY-SA 4.0 协议发布。\n\n你可以自由地对博客中内容进行分享、创作演绎直至商业性的使用，但必须在文章末尾或参考文献处注明文章的出处（文章链接）。完整的[协议](https://creativecommons.org/licenses/by-nc-sa/4.0/)可以参看这里。","source":"about/index.md","raw":"# 关于我\n\njava工程师，有一位我很爱同时也很爱我的傻乎乎的未婚妻。\n\n\n\n# 热爱\njava技术栈的所有相关技术(虽然可能技术并不是每项技术都很厉害)\n家事国事天下事,事事关心的微胖少年,有趣且逐渐懂事的痞气Boy\n看书音乐都还蛮喜欢\n\n\n\n# 关于本站\n本站有一些文章可成系列，多为平时工作总结和看书所得,摘记以供回味学习,其余文章则随心所致。\n\n\n\n\n# 版权与协议\n若无特殊说明，本站所有文章均为原创文章，并遵循 CC BY-SA 4.0 协议发布。\n\n你可以自由地对博客中内容进行分享、创作演绎直至商业性的使用，但必须在文章末尾或参考文献处注明文章的出处（文章链接）。完整的[协议](https://creativecommons.org/licenses/by-nc-sa/4.0/)可以参看这里。","date":"2020-10-23T14:08:36.902Z","updated":"2019-12-15T07:17:06.000Z","path":"about/index.html","title":"","comments":1,"layout":"page","_id":"ckgnsue0i0000bcvzhijm4sy3","content":"<h1 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h1><p>java工程师，有一位我很爱同时也很爱我的傻乎乎的未婚妻。</p>\n<h1 id=\"热爱\"><a href=\"#热爱\" class=\"headerlink\" title=\"热爱\"></a>热爱</h1><p>java技术栈的所有相关技术(虽然可能技术并不是每项技术都很厉害)<br>家事国事天下事,事事关心的微胖少年,有趣且逐渐懂事的痞气Boy<br>看书音乐都还蛮喜欢</p>\n<h1 id=\"关于本站\"><a href=\"#关于本站\" class=\"headerlink\" title=\"关于本站\"></a>关于本站</h1><p>本站有一些文章可成系列，多为平时工作总结和看书所得,摘记以供回味学习,其余文章则随心所致。</p>\n<h1 id=\"版权与协议\"><a href=\"#版权与协议\" class=\"headerlink\" title=\"版权与协议\"></a>版权与协议</h1><p>若无特殊说明，本站所有文章均为原创文章，并遵循 CC BY-SA 4.0 协议发布。</p>\n<p>你可以自由地对博客中内容进行分享、创作演绎直至商业性的使用，但必须在文章末尾或参考文献处注明文章的出处（文章链接）。完整的<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">协议</a>可以参看这里。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h1><p>java工程师，有一位我很爱同时也很爱我的傻乎乎的未婚妻。</p>\n<h1 id=\"热爱\"><a href=\"#热爱\" class=\"headerlink\" title=\"热爱\"></a>热爱</h1><p>java技术栈的所有相关技术(虽然可能技术并不是每项技术都很厉害)<br>家事国事天下事,事事关心的微胖少年,有趣且逐渐懂事的痞气Boy<br>看书音乐都还蛮喜欢</p>\n<h1 id=\"关于本站\"><a href=\"#关于本站\" class=\"headerlink\" title=\"关于本站\"></a>关于本站</h1><p>本站有一些文章可成系列，多为平时工作总结和看书所得,摘记以供回味学习,其余文章则随心所致。</p>\n<h1 id=\"版权与协议\"><a href=\"#版权与协议\" class=\"headerlink\" title=\"版权与协议\"></a>版权与协议</h1><p>若无特殊说明，本站所有文章均为原创文章，并遵循 CC BY-SA 4.0 协议发布。</p>\n<p>你可以自由地对博客中内容进行分享、创作演绎直至商业性的使用，但必须在文章末尾或参考文献处注明文章的出处（文章链接）。完整的<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">协议</a>可以参看这里。</p>\n"},{"title":"分类","date":"2019-11-26T12:48:48.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2019-11-26 20:48:48\ntype: categories\n---\n","updated":"2019-12-15T07:17:06.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ckgnsue1d0002bcvz9dgrdqm5","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"资源分享","date":"2019-12-05T11:36:45.000Z","_content":"# 看过书籍资源分享\n 1. [Docker技术入门与实战  第3版.pdf](https://pan.baidu.com/s/1lHuZLYJuqAM3ZepjqXuxuA)\n 2. [计算机网络-自顶向下方法](https://pan.baidu.com/s/1F9Lsq6a7n_PUJfMuTc5JiQ)\n \n#  免责声明:上述资源为网络收集,如有侵权及时联系本人QQ:409196007\n","source":"share/index.md","raw":"---\ntitle: 资源分享\ndate: 2019-12-05 19:36:45\n---\n# 看过书籍资源分享\n 1. [Docker技术入门与实战  第3版.pdf](https://pan.baidu.com/s/1lHuZLYJuqAM3ZepjqXuxuA)\n 2. [计算机网络-自顶向下方法](https://pan.baidu.com/s/1F9Lsq6a7n_PUJfMuTc5JiQ)\n \n#  免责声明:上述资源为网络收集,如有侵权及时联系本人QQ:409196007\n","updated":"2019-12-15T07:17:06.000Z","path":"share/index.html","comments":1,"layout":"page","_id":"ckgnsue1k0004bcvz84iac4ra","content":"<h1 id=\"看过书籍资源分享\"><a href=\"#看过书籍资源分享\" class=\"headerlink\" title=\"看过书籍资源分享\"></a>看过书籍资源分享</h1><ol>\n<li><a href=\"https://pan.baidu.com/s/1lHuZLYJuqAM3ZepjqXuxuA\">Docker技术入门与实战  第3版.pdf</a></li>\n<li><a href=\"https://pan.baidu.com/s/1F9Lsq6a7n_PUJfMuTc5JiQ\">计算机网络-自顶向下方法</a></li>\n</ol>\n<h1 id=\"免责声明-上述资源为网络收集-如有侵权及时联系本人QQ-409196007\"><a href=\"#免责声明-上述资源为网络收集-如有侵权及时联系本人QQ-409196007\" class=\"headerlink\" title=\"免责声明:上述资源为网络收集,如有侵权及时联系本人QQ:409196007\"></a>免责声明:上述资源为网络收集,如有侵权及时联系本人QQ:409196007</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"看过书籍资源分享\"><a href=\"#看过书籍资源分享\" class=\"headerlink\" title=\"看过书籍资源分享\"></a>看过书籍资源分享</h1><ol>\n<li><a href=\"https://pan.baidu.com/s/1lHuZLYJuqAM3ZepjqXuxuA\">Docker技术入门与实战  第3版.pdf</a></li>\n<li><a href=\"https://pan.baidu.com/s/1F9Lsq6a7n_PUJfMuTc5JiQ\">计算机网络-自顶向下方法</a></li>\n</ol>\n<h1 id=\"免责声明-上述资源为网络收集-如有侵权及时联系本人QQ-409196007\"><a href=\"#免责声明-上述资源为网络收集-如有侵权及时联系本人QQ-409196007\" class=\"headerlink\" title=\"免责声明:上述资源为网络收集,如有侵权及时联系本人QQ:409196007\"></a>免责声明:上述资源为网络收集,如有侵权及时联系本人QQ:409196007</h1>"},{"title":"标签","date":"2019-11-26T12:48:12.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2019-11-26 20:48:12\ntype: tags\n---\n","updated":"2019-12-15T07:17:06.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ckgnsue1v0008bcvz6db260qb","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"数据结构与算法书摘-1绪论","date":"2019-09-01T14:40:57.000Z","_content":"数据及其逻辑结构,数据(Data):信息的载体,是对客观事物的符号表示...\n<!--more-->\n## 数据及其逻辑结构\n\n 1. **基本概念**\n \t**数据(Data)**:信息的载体,是对客观事物的符号表示.\n\n\t**数据元素(Data Element)**:数据的基本单位,在计算机程序中通常作为一个整体进行考虑和处理.\n\t\n\t**数据对象(Data Object)**:性质相同的数据元素的集合,是数据的一个子集.\n\n\t**逻辑结构(Logical Structure)**:数据元素之间的逻辑关系,通常数据的逻辑结构有**四种基本逻辑结构:**![逻辑结构示意图](https://img-blog.csdnimg.cn/20190901122329813.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMzQwNTQ3,size_16,color_FFFFFF,t_70)\n\n 2. **数据结构**\n \t**数据结构(Data Structire)**:没有个一公认的定义,我读的这本书中的定义:相互之间存在一种或多种特定关系的数据元素的集合,一般包括三个方面:**数据的逻辑结构,数据的存储结构(数据的物理结构),数据的运算**\n \t\n \t**数据类型**:明显或隐含地规定在程序执行期间各个变量或表达式的取值范围,存储方式,以及允许进行的运算,其中又可以分为**简单(基本)数据类型**和**结构类型**\n\n 3. **存储实现与运算实现**\n \t存储实现:基本目的就是建立数据结构在计算机内部的表示和实现,包括数据以及逻辑关系的物理表达,也被称为存储结构或物理结构.常用的**四种常用的存储结构类型**:\n \t\n| 结构类型定义| 特点 |\n|--|--|\n| **顺序存储结构(Sequential Storage Structure)**:逻辑上相邻的节点在物理位置上也相邻的存储单元,节点之间的逻辑关系则由存储单元的相邻关系来表达(**主要用于线性数据结构**) | 节点只存储数据本身,节点之间的逻辑关系没有占用额外空间,存储空间利用率高;数据结构中的每个节点的存储地址可以通过公式直接计算,第i个节点的存储地址为:Li=L0+(i-1)*B.L0为第一个节点的存储位置,B为每个节点所占用的存储单位个数;对节点进行插入删除运算,会引起大量的节点移动,操作不便 |\n|**链式存储结构(Linked Storage Structure)**:逻辑相邻节点在物理上不一定相邻,节点之间的逻辑关系由附加的指针来表达,指针指向相邻的节点,通过指针把所有节点串联起来(链式存储结构一般有两部分组成,**数据域,指针域**(可以有多个指针)) | 除了数据域,还包含存储域的节点指针,比顺序存储结构浪费空间;物理上不必相邻可用于线性表,树,图等多种逻辑结构的存储;节点进行删除和插入比较灵活,不必移动节点,只需要移动指针指向就行 |\n|**索引存储结构(Index Storage Structure)**:附加一个索引表,索引的每一项称作索引项利用索引项的值来确定节点的实际存储单元地址,索引项一般形式为关键字,地址,关键字唯一标识一个节点 | 检索速度快,直接对节点进行随机访问;插入删除快,只需要移动存储索引中对应节点的存储地址;附件索引表,空间开销大  |\n|**散列存储结构(Hash Storage Structure)**:根据节点的关键字(散列函数,一般取模)直接计算出节点的存储地址 | 检索,增加删除节点快;因为通过散列函数会出现节点单元冲突碰撞,增大时间和空间开销  |\n\n 4. **运算实现**\n \t运算实现依赖于存储结构\n \n 5. **算法描述和算法分析**\n \t**算法**:是一组有穷的且定义明确的规则;算法的**五个基本特征**:\n\n| 特征 | 描述 |\n|--|--|\n| 有穷性(Finiteness); |  一个算法必须在执行又穷步数之后结束;并且每一步在有穷时间内完成 |\n| 确定性(Dfiniteness); |  算法中的每一步都由明确的定义,且无多义性 |\n| 可行性(Effectiveness);|  算法中的每一步都是可行的,可通过已经实现的基本操作执行有限次得以实现 |\n| 输入(Input); | 有零个或者多个输入,初始化参数  |\n| 输出(Output) |  有零个或者多个输出参数 |\n好的算法还要考虑真确性,可读性,健壮性,高效性;\n\n 6. **算法描述**\n \t自然语言,流程图,程序设计语言,伪代码等.\n \t\n 7. **算法分析(Algorithm Analysis)**\n\t算法分析就是对算法所消耗的资源进行估算;方法:事后统计法和事前分析估算法;\n\t算法=控制结构(顺序,分支,循环)+原操作(固有数据类型的操作)\n\t评估算法:**时间复杂度和空间复杂度**\n\tO(1)常数阶<O(log2n)对数阶<O(n)线性阶<O(nlog2n)<O(n2)平方阶<O(n3)立方阶<O(2n)指数阶<O(n!)\n\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/100181800](https://blog.csdn.net/qq_20340547/article/details/100181800)\n \t\n\n\t\t\t\n\n \t\t\n \t","source":"_posts/book/2019-11-26-15.md","raw":"---\ntitle: 数据结构与算法书摘-1绪论\ndate: 2019-09-01 22:40:57\ntags: Data structure and algorithm\ncategories: 看书摘记\n---\n数据及其逻辑结构,数据(Data):信息的载体,是对客观事物的符号表示...\n<!--more-->\n## 数据及其逻辑结构\n\n 1. **基本概念**\n \t**数据(Data)**:信息的载体,是对客观事物的符号表示.\n\n\t**数据元素(Data Element)**:数据的基本单位,在计算机程序中通常作为一个整体进行考虑和处理.\n\t\n\t**数据对象(Data Object)**:性质相同的数据元素的集合,是数据的一个子集.\n\n\t**逻辑结构(Logical Structure)**:数据元素之间的逻辑关系,通常数据的逻辑结构有**四种基本逻辑结构:**![逻辑结构示意图](https://img-blog.csdnimg.cn/20190901122329813.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMzQwNTQ3,size_16,color_FFFFFF,t_70)\n\n 2. **数据结构**\n \t**数据结构(Data Structire)**:没有个一公认的定义,我读的这本书中的定义:相互之间存在一种或多种特定关系的数据元素的集合,一般包括三个方面:**数据的逻辑结构,数据的存储结构(数据的物理结构),数据的运算**\n \t\n \t**数据类型**:明显或隐含地规定在程序执行期间各个变量或表达式的取值范围,存储方式,以及允许进行的运算,其中又可以分为**简单(基本)数据类型**和**结构类型**\n\n 3. **存储实现与运算实现**\n \t存储实现:基本目的就是建立数据结构在计算机内部的表示和实现,包括数据以及逻辑关系的物理表达,也被称为存储结构或物理结构.常用的**四种常用的存储结构类型**:\n \t\n| 结构类型定义| 特点 |\n|--|--|\n| **顺序存储结构(Sequential Storage Structure)**:逻辑上相邻的节点在物理位置上也相邻的存储单元,节点之间的逻辑关系则由存储单元的相邻关系来表达(**主要用于线性数据结构**) | 节点只存储数据本身,节点之间的逻辑关系没有占用额外空间,存储空间利用率高;数据结构中的每个节点的存储地址可以通过公式直接计算,第i个节点的存储地址为:Li=L0+(i-1)*B.L0为第一个节点的存储位置,B为每个节点所占用的存储单位个数;对节点进行插入删除运算,会引起大量的节点移动,操作不便 |\n|**链式存储结构(Linked Storage Structure)**:逻辑相邻节点在物理上不一定相邻,节点之间的逻辑关系由附加的指针来表达,指针指向相邻的节点,通过指针把所有节点串联起来(链式存储结构一般有两部分组成,**数据域,指针域**(可以有多个指针)) | 除了数据域,还包含存储域的节点指针,比顺序存储结构浪费空间;物理上不必相邻可用于线性表,树,图等多种逻辑结构的存储;节点进行删除和插入比较灵活,不必移动节点,只需要移动指针指向就行 |\n|**索引存储结构(Index Storage Structure)**:附加一个索引表,索引的每一项称作索引项利用索引项的值来确定节点的实际存储单元地址,索引项一般形式为关键字,地址,关键字唯一标识一个节点 | 检索速度快,直接对节点进行随机访问;插入删除快,只需要移动存储索引中对应节点的存储地址;附件索引表,空间开销大  |\n|**散列存储结构(Hash Storage Structure)**:根据节点的关键字(散列函数,一般取模)直接计算出节点的存储地址 | 检索,增加删除节点快;因为通过散列函数会出现节点单元冲突碰撞,增大时间和空间开销  |\n\n 4. **运算实现**\n \t运算实现依赖于存储结构\n \n 5. **算法描述和算法分析**\n \t**算法**:是一组有穷的且定义明确的规则;算法的**五个基本特征**:\n\n| 特征 | 描述 |\n|--|--|\n| 有穷性(Finiteness); |  一个算法必须在执行又穷步数之后结束;并且每一步在有穷时间内完成 |\n| 确定性(Dfiniteness); |  算法中的每一步都由明确的定义,且无多义性 |\n| 可行性(Effectiveness);|  算法中的每一步都是可行的,可通过已经实现的基本操作执行有限次得以实现 |\n| 输入(Input); | 有零个或者多个输入,初始化参数  |\n| 输出(Output) |  有零个或者多个输出参数 |\n好的算法还要考虑真确性,可读性,健壮性,高效性;\n\n 6. **算法描述**\n \t自然语言,流程图,程序设计语言,伪代码等.\n \t\n 7. **算法分析(Algorithm Analysis)**\n\t算法分析就是对算法所消耗的资源进行估算;方法:事后统计法和事前分析估算法;\n\t算法=控制结构(顺序,分支,循环)+原操作(固有数据类型的操作)\n\t评估算法:**时间复杂度和空间复杂度**\n\tO(1)常数阶<O(log2n)对数阶<O(n)线性阶<O(nlog2n)<O(n2)平方阶<O(n3)立方阶<O(2n)指数阶<O(n!)\n\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/100181800](https://blog.csdn.net/qq_20340547/article/details/100181800)\n \t\n\n\t\t\t\n\n \t\t\n \t","slug":"book/2019-11-26-15","published":1,"updated":"2019-12-15T07:17:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue1h0003bcvz1sa992uq","content":"<p>数据及其逻辑结构,数据(Data):信息的载体,是对客观事物的符号表示…</p>\n<a id=\"more\"></a>\n<h2 id=\"数据及其逻辑结构\"><a href=\"#数据及其逻辑结构\" class=\"headerlink\" title=\"数据及其逻辑结构\"></a>数据及其逻辑结构</h2><ol>\n<li><p><strong>基本概念</strong><br> <strong>数据(Data)</strong>:信息的载体,是对客观事物的符号表示.</p>\n<p><strong>数据元素(Data Element)</strong>:数据的基本单位,在计算机程序中通常作为一个整体进行考虑和处理.</p>\n<p><strong>数据对象(Data Object)</strong>:性质相同的数据元素的集合,是数据的一个子集.</p>\n<p><strong>逻辑结构(Logical Structure)</strong>:数据元素之间的逻辑关系,通常数据的逻辑结构有<strong>四种基本逻辑结构:</strong><img src=\"https://img-blog.csdnimg.cn/20190901122329813.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMzQwNTQ3,size_16,color_FFFFFF,t_70\" alt=\"逻辑结构示意图\"></p>\n</li>\n<li><p><strong>数据结构</strong><br> <strong>数据结构(Data Structire)</strong>:没有个一公认的定义,我读的这本书中的定义:相互之间存在一种或多种特定关系的数据元素的集合,一般包括三个方面:<strong>数据的逻辑结构,数据的存储结构(数据的物理结构),数据的运算</strong></p>\n<p> <strong>数据类型</strong>:明显或隐含地规定在程序执行期间各个变量或表达式的取值范围,存储方式,以及允许进行的运算,其中又可以分为<strong>简单(基本)数据类型</strong>和<strong>结构类型</strong></p>\n</li>\n<li><p><strong>存储实现与运算实现</strong><br> 存储实现:基本目的就是建立数据结构在计算机内部的表示和实现,包括数据以及逻辑关系的物理表达,也被称为存储结构或物理结构.常用的<strong>四种常用的存储结构类型</strong>:</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>结构类型定义</th>\n<th>特点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>顺序存储结构(Sequential Storage Structure)</strong>:逻辑上相邻的节点在物理位置上也相邻的存储单元,节点之间的逻辑关系则由存储单元的相邻关系来表达(<strong>主要用于线性数据结构</strong>)</td>\n<td>节点只存储数据本身,节点之间的逻辑关系没有占用额外空间,存储空间利用率高;数据结构中的每个节点的存储地址可以通过公式直接计算,第i个节点的存储地址为:Li=L0+(i-1)*B.L0为第一个节点的存储位置,B为每个节点所占用的存储单位个数;对节点进行插入删除运算,会引起大量的节点移动,操作不便</td>\n</tr>\n<tr>\n<td><strong>链式存储结构(Linked Storage Structure)</strong>:逻辑相邻节点在物理上不一定相邻,节点之间的逻辑关系由附加的指针来表达,指针指向相邻的节点,通过指针把所有节点串联起来(链式存储结构一般有两部分组成,<strong>数据域,指针域</strong>(可以有多个指针))</td>\n<td>除了数据域,还包含存储域的节点指针,比顺序存储结构浪费空间;物理上不必相邻可用于线性表,树,图等多种逻辑结构的存储;节点进行删除和插入比较灵活,不必移动节点,只需要移动指针指向就行</td>\n</tr>\n<tr>\n<td><strong>索引存储结构(Index Storage Structure)</strong>:附加一个索引表,索引的每一项称作索引项利用索引项的值来确定节点的实际存储单元地址,索引项一般形式为关键字,地址,关键字唯一标识一个节点</td>\n<td>检索速度快,直接对节点进行随机访问;插入删除快,只需要移动存储索引中对应节点的存储地址;附件索引表,空间开销大</td>\n</tr>\n<tr>\n<td><strong>散列存储结构(Hash Storage Structure)</strong>:根据节点的关键字(散列函数,一般取模)直接计算出节点的存储地址</td>\n<td>检索,增加删除节点快;因为通过散列函数会出现节点单元冲突碰撞,增大时间和空间开销</td>\n</tr>\n</tbody></table>\n<ol start=\"4\">\n<li><p><strong>运算实现</strong><br> 运算实现依赖于存储结构</p>\n</li>\n<li><p><strong>算法描述和算法分析</strong><br> <strong>算法</strong>:是一组有穷的且定义明确的规则;算法的<strong>五个基本特征</strong>:</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>特征</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>有穷性(Finiteness);</td>\n<td>一个算法必须在执行又穷步数之后结束;并且每一步在有穷时间内完成</td>\n</tr>\n<tr>\n<td>确定性(Dfiniteness);</td>\n<td>算法中的每一步都由明确的定义,且无多义性</td>\n</tr>\n<tr>\n<td>可行性(Effectiveness);</td>\n<td>算法中的每一步都是可行的,可通过已经实现的基本操作执行有限次得以实现</td>\n</tr>\n<tr>\n<td>输入(Input);</td>\n<td>有零个或者多个输入,初始化参数</td>\n</tr>\n<tr>\n<td>输出(Output)</td>\n<td>有零个或者多个输出参数</td>\n</tr>\n<tr>\n<td>好的算法还要考虑真确性,可读性,健壮性,高效性;</td>\n<td></td>\n</tr>\n</tbody></table>\n<ol start=\"6\">\n<li><p><strong>算法描述</strong><br> 自然语言,流程图,程序设计语言,伪代码等.</p>\n</li>\n<li><p><strong>算法分析(Algorithm Analysis)</strong><br>算法分析就是对算法所消耗的资源进行估算;方法:事后统计法和事前分析估算法;<br>算法=控制结构(顺序,分支,循环)+原操作(固有数据类型的操作)<br>评估算法:<strong>时间复杂度和空间复杂度</strong><br>O(1)常数阶&lt;O(log2n)对数阶&lt;O(n)线性阶&lt;O(nlog2n)&lt;O(n2)平方阶&lt;O(n3)立方阶&lt;O(2n)指数阶&lt;O(n!)</p>\n</li>\n</ol>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/100181800\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/100181800</a></p>\n","site":{"data":{}},"excerpt":"<p>数据及其逻辑结构,数据(Data):信息的载体,是对客观事物的符号表示…</p>","more":"<h2 id=\"数据及其逻辑结构\"><a href=\"#数据及其逻辑结构\" class=\"headerlink\" title=\"数据及其逻辑结构\"></a>数据及其逻辑结构</h2><ol>\n<li><p><strong>基本概念</strong><br> <strong>数据(Data)</strong>:信息的载体,是对客观事物的符号表示.</p>\n<p><strong>数据元素(Data Element)</strong>:数据的基本单位,在计算机程序中通常作为一个整体进行考虑和处理.</p>\n<p><strong>数据对象(Data Object)</strong>:性质相同的数据元素的集合,是数据的一个子集.</p>\n<p><strong>逻辑结构(Logical Structure)</strong>:数据元素之间的逻辑关系,通常数据的逻辑结构有<strong>四种基本逻辑结构:</strong><img src=\"https://img-blog.csdnimg.cn/20190901122329813.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMzQwNTQ3,size_16,color_FFFFFF,t_70\" alt=\"逻辑结构示意图\"></p>\n</li>\n<li><p><strong>数据结构</strong><br> <strong>数据结构(Data Structire)</strong>:没有个一公认的定义,我读的这本书中的定义:相互之间存在一种或多种特定关系的数据元素的集合,一般包括三个方面:<strong>数据的逻辑结构,数据的存储结构(数据的物理结构),数据的运算</strong></p>\n<p> <strong>数据类型</strong>:明显或隐含地规定在程序执行期间各个变量或表达式的取值范围,存储方式,以及允许进行的运算,其中又可以分为<strong>简单(基本)数据类型</strong>和<strong>结构类型</strong></p>\n</li>\n<li><p><strong>存储实现与运算实现</strong><br> 存储实现:基本目的就是建立数据结构在计算机内部的表示和实现,包括数据以及逻辑关系的物理表达,也被称为存储结构或物理结构.常用的<strong>四种常用的存储结构类型</strong>:</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>结构类型定义</th>\n<th>特点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>顺序存储结构(Sequential Storage Structure)</strong>:逻辑上相邻的节点在物理位置上也相邻的存储单元,节点之间的逻辑关系则由存储单元的相邻关系来表达(<strong>主要用于线性数据结构</strong>)</td>\n<td>节点只存储数据本身,节点之间的逻辑关系没有占用额外空间,存储空间利用率高;数据结构中的每个节点的存储地址可以通过公式直接计算,第i个节点的存储地址为:Li=L0+(i-1)*B.L0为第一个节点的存储位置,B为每个节点所占用的存储单位个数;对节点进行插入删除运算,会引起大量的节点移动,操作不便</td>\n</tr>\n<tr>\n<td><strong>链式存储结构(Linked Storage Structure)</strong>:逻辑相邻节点在物理上不一定相邻,节点之间的逻辑关系由附加的指针来表达,指针指向相邻的节点,通过指针把所有节点串联起来(链式存储结构一般有两部分组成,<strong>数据域,指针域</strong>(可以有多个指针))</td>\n<td>除了数据域,还包含存储域的节点指针,比顺序存储结构浪费空间;物理上不必相邻可用于线性表,树,图等多种逻辑结构的存储;节点进行删除和插入比较灵活,不必移动节点,只需要移动指针指向就行</td>\n</tr>\n<tr>\n<td><strong>索引存储结构(Index Storage Structure)</strong>:附加一个索引表,索引的每一项称作索引项利用索引项的值来确定节点的实际存储单元地址,索引项一般形式为关键字,地址,关键字唯一标识一个节点</td>\n<td>检索速度快,直接对节点进行随机访问;插入删除快,只需要移动存储索引中对应节点的存储地址;附件索引表,空间开销大</td>\n</tr>\n<tr>\n<td><strong>散列存储结构(Hash Storage Structure)</strong>:根据节点的关键字(散列函数,一般取模)直接计算出节点的存储地址</td>\n<td>检索,增加删除节点快;因为通过散列函数会出现节点单元冲突碰撞,增大时间和空间开销</td>\n</tr>\n</tbody></table>\n<ol start=\"4\">\n<li><p><strong>运算实现</strong><br> 运算实现依赖于存储结构</p>\n</li>\n<li><p><strong>算法描述和算法分析</strong><br> <strong>算法</strong>:是一组有穷的且定义明确的规则;算法的<strong>五个基本特征</strong>:</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>特征</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>有穷性(Finiteness);</td>\n<td>一个算法必须在执行又穷步数之后结束;并且每一步在有穷时间内完成</td>\n</tr>\n<tr>\n<td>确定性(Dfiniteness);</td>\n<td>算法中的每一步都由明确的定义,且无多义性</td>\n</tr>\n<tr>\n<td>可行性(Effectiveness);</td>\n<td>算法中的每一步都是可行的,可通过已经实现的基本操作执行有限次得以实现</td>\n</tr>\n<tr>\n<td>输入(Input);</td>\n<td>有零个或者多个输入,初始化参数</td>\n</tr>\n<tr>\n<td>输出(Output)</td>\n<td>有零个或者多个输出参数</td>\n</tr>\n<tr>\n<td>好的算法还要考虑真确性,可读性,健壮性,高效性;</td>\n<td></td>\n</tr>\n</tbody></table>\n<ol start=\"6\">\n<li><p><strong>算法描述</strong><br> 自然语言,流程图,程序设计语言,伪代码等.</p>\n</li>\n<li><p><strong>算法分析(Algorithm Analysis)</strong><br>算法分析就是对算法所消耗的资源进行估算;方法:事后统计法和事前分析估算法;<br>算法=控制结构(顺序,分支,循环)+原操作(固有数据类型的操作)<br>评估算法:<strong>时间复杂度和空间复杂度</strong><br>O(1)常数阶&lt;O(log2n)对数阶&lt;O(n)线性阶&lt;O(nlog2n)&lt;O(n2)平方阶&lt;O(n3)立方阶&lt;O(2n)指数阶&lt;O(n!)</p>\n</li>\n</ol>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/100181800\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/100181800</a></p>"},{"title":"数据结构与算法书摘-2线性表","date":"2019-09-02T14:59:40.000Z","_content":"线性表的基本概念:线性表是所有数据结构中最为重要最为基础的一个抽象,线性表是计算机编程的基础.\n<!--more-->\n 1. **本章的知识架构图**\n ![线性表知识架构图](https://img-blog.csdnimg.cn/20190902222730514.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMzQwNTQ3,size_16,color_FFFFFF,t_70)\n 2. **线性表的基本概念**\n \t线性表是所有数据结构中最为重要最为基础的一个抽象,线性表是计算机编程的基础.\n \t**线性表的定义:** **是一个非空的有限集合;存在唯一的第一个元素,也存在唯一的最后一个元素;除了第一个元素外,其他每一个元素都有唯一的直接前驱元素(直接前驱);除了最后一个元素其他每一个元素都有唯一的一个直接后继元素(直接后继).**\n \t\n 3. **线性表顺序表示和实现**\n \t线性表顺序表示:一组连续的存储单元依次存储线性表的数据元素,线性表在内存中是以连续的方式进行存放的,线性表是一种随机存取方式的存储结构.\n \n \n 4. **线性表的链接表示和实现**\n \t线性表的链式表示:线性表中的每个元素申请独立的内存空间,元素与元素之间的内存地址可以不连续,除了包含元素本身信息,还包含指针域,指向该元素的直接前驱元素和直接后继元素,通过指针链接起来形成一个链.根据指针域不同,链式线性表可分为**单向链表和双向链表和循环链表**\n \t\n 5. **两种结构算法比较**\n \t**顺序存储线性表**主要通过**数组**实现,数据元素存储在**连续的内存地址**上,插入和删除通过移动内存元素来实现;\n \t**链式存储线性表**引用指针,元素存放在不连续的内存中,插入和删除移动指针引用就行.\n \t所以上诉的特点导致顺序存储线性表比链式存储线性表浪费内存空间,插入和删除数据链表比顺序存储快.\n \t\n 6. **上述结构图中的一些没有讲到的定义,可自行百度,以及之间的相互的区别特点,百度一下你都知道,嘿嘿嘿!!**\n \t\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/100412128](https://blog.csdn.net/qq_20340547/article/details/100412128)","source":"_posts/book/2019-11-26-19.md","raw":"---\ntitle: 数据结构与算法书摘-2线性表\ndate: 2019-09-02 22:59:40\ntags: Data structure and algorithm\ncategories: 看书摘记\n---\n线性表的基本概念:线性表是所有数据结构中最为重要最为基础的一个抽象,线性表是计算机编程的基础.\n<!--more-->\n 1. **本章的知识架构图**\n ![线性表知识架构图](https://img-blog.csdnimg.cn/20190902222730514.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMzQwNTQ3,size_16,color_FFFFFF,t_70)\n 2. **线性表的基本概念**\n \t线性表是所有数据结构中最为重要最为基础的一个抽象,线性表是计算机编程的基础.\n \t**线性表的定义:** **是一个非空的有限集合;存在唯一的第一个元素,也存在唯一的最后一个元素;除了第一个元素外,其他每一个元素都有唯一的直接前驱元素(直接前驱);除了最后一个元素其他每一个元素都有唯一的一个直接后继元素(直接后继).**\n \t\n 3. **线性表顺序表示和实现**\n \t线性表顺序表示:一组连续的存储单元依次存储线性表的数据元素,线性表在内存中是以连续的方式进行存放的,线性表是一种随机存取方式的存储结构.\n \n \n 4. **线性表的链接表示和实现**\n \t线性表的链式表示:线性表中的每个元素申请独立的内存空间,元素与元素之间的内存地址可以不连续,除了包含元素本身信息,还包含指针域,指向该元素的直接前驱元素和直接后继元素,通过指针链接起来形成一个链.根据指针域不同,链式线性表可分为**单向链表和双向链表和循环链表**\n \t\n 5. **两种结构算法比较**\n \t**顺序存储线性表**主要通过**数组**实现,数据元素存储在**连续的内存地址**上,插入和删除通过移动内存元素来实现;\n \t**链式存储线性表**引用指针,元素存放在不连续的内存中,插入和删除移动指针引用就行.\n \t所以上诉的特点导致顺序存储线性表比链式存储线性表浪费内存空间,插入和删除数据链表比顺序存储快.\n \t\n 6. **上述结构图中的一些没有讲到的定义,可自行百度,以及之间的相互的区别特点,百度一下你都知道,嘿嘿嘿!!**\n \t\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/100412128](https://blog.csdn.net/qq_20340547/article/details/100412128)","slug":"book/2019-11-26-19","published":1,"updated":"2019-12-15T07:17:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue1s0005bcvzfs7627dy","content":"<p>线性表的基本概念:线性表是所有数据结构中最为重要最为基础的一个抽象,线性表是计算机编程的基础.</p>\n<a id=\"more\"></a>\n<ol>\n<li><p><strong>本章的知识架构图</strong><br><img src=\"https://img-blog.csdnimg.cn/20190902222730514.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMzQwNTQ3,size_16,color_FFFFFF,t_70\" alt=\"线性表知识架构图\"></p>\n</li>\n<li><p><strong>线性表的基本概念</strong><br> 线性表是所有数据结构中最为重要最为基础的一个抽象,线性表是计算机编程的基础.<br> <strong>线性表的定义:</strong> <strong>是一个非空的有限集合;存在唯一的第一个元素,也存在唯一的最后一个元素;除了第一个元素外,其他每一个元素都有唯一的直接前驱元素(直接前驱);除了最后一个元素其他每一个元素都有唯一的一个直接后继元素(直接后继).</strong></p>\n</li>\n<li><p><strong>线性表顺序表示和实现</strong><br> 线性表顺序表示:一组连续的存储单元依次存储线性表的数据元素,线性表在内存中是以连续的方式进行存放的,线性表是一种随机存取方式的存储结构.</p>\n</li>\n</ol>\n<ol start=\"4\">\n<li><p><strong>线性表的链接表示和实现</strong><br> 线性表的链式表示:线性表中的每个元素申请独立的内存空间,元素与元素之间的内存地址可以不连续,除了包含元素本身信息,还包含指针域,指向该元素的直接前驱元素和直接后继元素,通过指针链接起来形成一个链.根据指针域不同,链式线性表可分为<strong>单向链表和双向链表和循环链表</strong></p>\n</li>\n<li><p><strong>两种结构算法比较</strong><br> <strong>顺序存储线性表</strong>主要通过<strong>数组</strong>实现,数据元素存储在<strong>连续的内存地址</strong>上,插入和删除通过移动内存元素来实现;<br> <strong>链式存储线性表</strong>引用指针,元素存放在不连续的内存中,插入和删除移动指针引用就行.<br> 所以上诉的特点导致顺序存储线性表比链式存储线性表浪费内存空间,插入和删除数据链表比顺序存储快.</p>\n</li>\n<li><p><strong>上述结构图中的一些没有讲到的定义,可自行百度,以及之间的相互的区别特点,百度一下你都知道,嘿嘿嘿!!</strong></p>\n</li>\n</ol>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/100412128\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/100412128</a></p>\n","site":{"data":{}},"excerpt":"<p>线性表的基本概念:线性表是所有数据结构中最为重要最为基础的一个抽象,线性表是计算机编程的基础.</p>","more":"<ol>\n<li><p><strong>本章的知识架构图</strong><br><img src=\"https://img-blog.csdnimg.cn/20190902222730514.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMzQwNTQ3,size_16,color_FFFFFF,t_70\" alt=\"线性表知识架构图\"></p>\n</li>\n<li><p><strong>线性表的基本概念</strong><br> 线性表是所有数据结构中最为重要最为基础的一个抽象,线性表是计算机编程的基础.<br> <strong>线性表的定义:</strong> <strong>是一个非空的有限集合;存在唯一的第一个元素,也存在唯一的最后一个元素;除了第一个元素外,其他每一个元素都有唯一的直接前驱元素(直接前驱);除了最后一个元素其他每一个元素都有唯一的一个直接后继元素(直接后继).</strong></p>\n</li>\n<li><p><strong>线性表顺序表示和实现</strong><br> 线性表顺序表示:一组连续的存储单元依次存储线性表的数据元素,线性表在内存中是以连续的方式进行存放的,线性表是一种随机存取方式的存储结构.</p>\n</li>\n</ol>\n<ol start=\"4\">\n<li><p><strong>线性表的链接表示和实现</strong><br> 线性表的链式表示:线性表中的每个元素申请独立的内存空间,元素与元素之间的内存地址可以不连续,除了包含元素本身信息,还包含指针域,指向该元素的直接前驱元素和直接后继元素,通过指针链接起来形成一个链.根据指针域不同,链式线性表可分为<strong>单向链表和双向链表和循环链表</strong></p>\n</li>\n<li><p><strong>两种结构算法比较</strong><br> <strong>顺序存储线性表</strong>主要通过<strong>数组</strong>实现,数据元素存储在<strong>连续的内存地址</strong>上,插入和删除通过移动内存元素来实现;<br> <strong>链式存储线性表</strong>引用指针,元素存放在不连续的内存中,插入和删除移动指针引用就行.<br> 所以上诉的特点导致顺序存储线性表比链式存储线性表浪费内存空间,插入和删除数据链表比顺序存储快.</p>\n</li>\n<li><p><strong>上述结构图中的一些没有讲到的定义,可自行百度,以及之间的相互的区别特点,百度一下你都知道,嘿嘿嘿!!</strong></p>\n</li>\n</ol>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/100412128\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/100412128</a></p>"},{"title":"数据结构与算法书摘-3栈和队列","date":"2019-09-21T14:24:12.000Z","_content":"栈(Stack):又叫堆栈,它是一种操作受限的线性表,其限制是在仅允许在表的一端进行插入和删除操作,又把栈叫做LIFO表(Last In Firsr Out),栈具有**后进先出**的特性...\n<!--more-->\n1. **栈的定义**\n \t栈(Stack):又叫堆栈,它是一种操作受限的线性表,其限制是在仅允许在表的一端进行插入和删除操作,又把栈叫做LIFO表(Last In Firsr Out),栈具有**后进先出**的特性.\n \t\n 2. **栈的顺序存储结构**\n \t栈的顺序存储结构可利用数组来实现,规定数组的第一个元素为栈底,定义一个变量存放栈顶元素所占用数组分量的下标,这个变量为**栈顶指针TOP** C语言中规定Top=-1表示空栈,当栈元素占据了数组的所有分量,也就是Top为数组的最大下标,我们称之为**栈满**\n \t\n 3. **栈的链式存储结构**\n \t栈的链式存储结构可以用链栈来实现,链栈操作受限,插入和删除仅限于表头进行.Top同样作为链栈的栈顶指针,Count记录当前元素的个数\n \t\n 4. **队列的定义**\n \t队列:它是一种受限的线性表,限定线性表的插入只能在表头位置进行,而删除只能在表尾进行,又把队列叫做FIFO(First In First Out),具有**先进先出**的特征.\n \t\n 5. **队列的顺序存储结构**\n\t可用数组模拟实现,两个变量记录队头和队尾,队头指针和队尾指针.\n\t首尾相连的数组环叫做**循环队列**,循环队列由于Front Rear 两个指针相等无法区分队列是空还是满,有两种方法来判断:需要设置另一个标志位来区分;约定队列头指针在环状队列的尾指针前一个位置时作为队列满的标志.两种方法各有千秋,前一种浪费一个空间,速度快,第二种在入队,出队频繁时,速度较慢.\n\t\n 6. **队列的链式存储结构**\n \t队列的链式存储用链式队列,链表表示的队列,限制在表头删除和表尾插入的单链表;\n \t队尾指针指向队首节点,构成一个循环链队列\n \t\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/101124657](https://blog.csdn.net/qq_20340547/article/details/101124657)\n\n \n \t","source":"_posts/book/2019-11-26-20.md","raw":"---\ntitle: 数据结构与算法书摘-3栈和队列\ndate: 2019-09-21 22:24:12\ntags: Data structure and algorithm\ncategories: 看书摘记\n---\n栈(Stack):又叫堆栈,它是一种操作受限的线性表,其限制是在仅允许在表的一端进行插入和删除操作,又把栈叫做LIFO表(Last In Firsr Out),栈具有**后进先出**的特性...\n<!--more-->\n1. **栈的定义**\n \t栈(Stack):又叫堆栈,它是一种操作受限的线性表,其限制是在仅允许在表的一端进行插入和删除操作,又把栈叫做LIFO表(Last In Firsr Out),栈具有**后进先出**的特性.\n \t\n 2. **栈的顺序存储结构**\n \t栈的顺序存储结构可利用数组来实现,规定数组的第一个元素为栈底,定义一个变量存放栈顶元素所占用数组分量的下标,这个变量为**栈顶指针TOP** C语言中规定Top=-1表示空栈,当栈元素占据了数组的所有分量,也就是Top为数组的最大下标,我们称之为**栈满**\n \t\n 3. **栈的链式存储结构**\n \t栈的链式存储结构可以用链栈来实现,链栈操作受限,插入和删除仅限于表头进行.Top同样作为链栈的栈顶指针,Count记录当前元素的个数\n \t\n 4. **队列的定义**\n \t队列:它是一种受限的线性表,限定线性表的插入只能在表头位置进行,而删除只能在表尾进行,又把队列叫做FIFO(First In First Out),具有**先进先出**的特征.\n \t\n 5. **队列的顺序存储结构**\n\t可用数组模拟实现,两个变量记录队头和队尾,队头指针和队尾指针.\n\t首尾相连的数组环叫做**循环队列**,循环队列由于Front Rear 两个指针相等无法区分队列是空还是满,有两种方法来判断:需要设置另一个标志位来区分;约定队列头指针在环状队列的尾指针前一个位置时作为队列满的标志.两种方法各有千秋,前一种浪费一个空间,速度快,第二种在入队,出队频繁时,速度较慢.\n\t\n 6. **队列的链式存储结构**\n \t队列的链式存储用链式队列,链表表示的队列,限制在表头删除和表尾插入的单链表;\n \t队尾指针指向队首节点,构成一个循环链队列\n \t\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/101124657](https://blog.csdn.net/qq_20340547/article/details/101124657)\n\n \n \t","slug":"book/2019-11-26-20","published":1,"updated":"2019-12-15T07:17:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue1w0009bcvzf3cs7t6w","content":"<p>栈(Stack):又叫堆栈,它是一种操作受限的线性表,其限制是在仅允许在表的一端进行插入和删除操作,又把栈叫做LIFO表(Last In Firsr Out),栈具有<strong>后进先出</strong>的特性…</p>\n<a id=\"more\"></a>\n<ol>\n<li><p><strong>栈的定义</strong><br>  栈(Stack):又叫堆栈,它是一种操作受限的线性表,其限制是在仅允许在表的一端进行插入和删除操作,又把栈叫做LIFO表(Last In Firsr Out),栈具有<strong>后进先出</strong>的特性.</p>\n<ol start=\"2\">\n<li><p><strong>栈的顺序存储结构</strong><br>栈的顺序存储结构可利用数组来实现,规定数组的第一个元素为栈底,定义一个变量存放栈顶元素所占用数组分量的下标,这个变量为<strong>栈顶指针TOP</strong> C语言中规定Top=-1表示空栈,当栈元素占据了数组的所有分量,也就是Top为数组的最大下标,我们称之为<strong>栈满</strong></p>\n</li>\n<li><p><strong>栈的链式存储结构</strong><br>栈的链式存储结构可以用链栈来实现,链栈操作受限,插入和删除仅限于表头进行.Top同样作为链栈的栈顶指针,Count记录当前元素的个数</p>\n</li>\n<li><p><strong>队列的定义</strong><br>队列:它是一种受限的线性表,限定线性表的插入只能在表头位置进行,而删除只能在表尾进行,又把队列叫做FIFO(First In First Out),具有<strong>先进先出</strong>的特征.</p>\n</li>\n<li><p><strong>队列的顺序存储结构</strong><br>可用数组模拟实现,两个变量记录队头和队尾,队头指针和队尾指针.<br>首尾相连的数组环叫做<strong>循环队列</strong>,循环队列由于Front Rear 两个指针相等无法区分队列是空还是满,有两种方法来判断:需要设置另一个标志位来区分;约定队列头指针在环状队列的尾指针前一个位置时作为队列满的标志.两种方法各有千秋,前一种浪费一个空间,速度快,第二种在入队,出队频繁时,速度较慢.</p>\n</li>\n<li><p><strong>队列的链式存储结构</strong><br>队列的链式存储用链式队列,链表表示的队列,限制在表头删除和表尾插入的单链表;<br>队尾指针指向队首节点,构成一个循环链队列</p>\n</li>\n</ol>\n</li>\n</ol>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/101124657\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/101124657</a></p>\n","site":{"data":{}},"excerpt":"<p>栈(Stack):又叫堆栈,它是一种操作受限的线性表,其限制是在仅允许在表的一端进行插入和删除操作,又把栈叫做LIFO表(Last In Firsr Out),栈具有<strong>后进先出</strong>的特性…</p>","more":"<ol>\n<li><p><strong>栈的定义</strong><br>  栈(Stack):又叫堆栈,它是一种操作受限的线性表,其限制是在仅允许在表的一端进行插入和删除操作,又把栈叫做LIFO表(Last In Firsr Out),栈具有<strong>后进先出</strong>的特性.</p>\n<ol start=\"2\">\n<li><p><strong>栈的顺序存储结构</strong><br>栈的顺序存储结构可利用数组来实现,规定数组的第一个元素为栈底,定义一个变量存放栈顶元素所占用数组分量的下标,这个变量为<strong>栈顶指针TOP</strong> C语言中规定Top=-1表示空栈,当栈元素占据了数组的所有分量,也就是Top为数组的最大下标,我们称之为<strong>栈满</strong></p>\n</li>\n<li><p><strong>栈的链式存储结构</strong><br>栈的链式存储结构可以用链栈来实现,链栈操作受限,插入和删除仅限于表头进行.Top同样作为链栈的栈顶指针,Count记录当前元素的个数</p>\n</li>\n<li><p><strong>队列的定义</strong><br>队列:它是一种受限的线性表,限定线性表的插入只能在表头位置进行,而删除只能在表尾进行,又把队列叫做FIFO(First In First Out),具有<strong>先进先出</strong>的特征.</p>\n</li>\n<li><p><strong>队列的顺序存储结构</strong><br>可用数组模拟实现,两个变量记录队头和队尾,队头指针和队尾指针.<br>首尾相连的数组环叫做<strong>循环队列</strong>,循环队列由于Front Rear 两个指针相等无法区分队列是空还是满,有两种方法来判断:需要设置另一个标志位来区分;约定队列头指针在环状队列的尾指针前一个位置时作为队列满的标志.两种方法各有千秋,前一种浪费一个空间,速度快,第二种在入队,出队频繁时,速度较慢.</p>\n</li>\n<li><p><strong>队列的链式存储结构</strong><br>队列的链式存储用链式队列,链表表示的队列,限制在表头删除和表尾插入的单链表;<br>队尾指针指向队首节点,构成一个循环链队列</p>\n</li>\n</ol>\n</li>\n</ol>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/101124657\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/101124657</a></p>"},{"title":"数据结构与算法书摘-4串和数组","date":"2019-09-22T14:24:12.000Z","_content":"串(String):**是由n(n>=0)个字符组成的有限序列**,字符串简称串,是一种特殊的线性表,串中的数据元素都是单个字符\n \t**s=\"c1c2..cn\"\t(n>=0)** ...\n<!--more-->\n1. **串的基本概念**\n \t**串(String):****是由n(n>=0)个字符组成的有限序列**,字符串简称串,是一种特殊的线性表,串中的数据元素都是单个字符\n \t**s=\"c1c2..cn\"\t(n>=0)**\n \ts是**串名**,双引号是串的**定界符**,引起来的事**串值**,n为串的长度,n=0称为**空串(Empty String)**,一个或者多个空格组成的串称为**空格串(Blank String)**\n \t串中任意个连续的字符组成的子序列称为该串的**子串(Substring)**,空串是任何串的字串,一个串除本身外,它的其他字串称为**真子串**,字串的第一个字符在主串中的位置叫**子串的位置**,两个串的长度相等并且对应的位置字符都相等,则**两个串相等**\n \t\n2. **串的顺序存储结构**\n \t串的顺序结构就是用连续的存储单元来存储串.以一组连续的存储单元放字符串的字符序列,也叫顺序串\n \t顺序串按存储分配不同分为两类:**静态分配存储,动态分配存储**\n \t静态分配存储又称为**定长顺序存储**\n \t\n3. **串的链式存储结构**\n \t串的链式存储结构就是单链表,节点的数据域是存放字符的,对于最后一个节点数据域未被字符占满的情况,可以添加特殊字符来填补,由此我们可以定义串的块链存储表示,除了定义链表的头指针外,还添加一个尾指针指示链表中最后一个节点,以便处理该节点中的信息.\n \t\n4. **数组的基本概念**\n \t**数组(Array)**:是一组相同数据类型的数据元素的有限序列,在一组地址连续的存储单元中,数组元素按先后次序存放,数组元素在数组中的位置称为**数组下标**,数组下标的个数称为**数组的维数**,通过地址计算取得数据元素地址的存储结构称为**随机存储结构**\n \t二维数组存放方式:行序为主序,以列序为主序\n \t矩阵使人们研究的数学对象,通常用来组织数据,其中就包含数组的应用,其中特殊矩阵,稀疏矩阵等\n\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/101156543](https://blog.csdn.net/qq_20340547/article/details/101156543)","source":"_posts/book/2019-11-26-21.md","raw":"---\ntitle: 数据结构与算法书摘-4串和数组\ndate: 2019-09-22 22:24:12\ntags: Data structure and algorithm\ncategories: 看书摘记\n---\n串(String):**是由n(n>=0)个字符组成的有限序列**,字符串简称串,是一种特殊的线性表,串中的数据元素都是单个字符\n \t**s=\"c1c2..cn\"\t(n>=0)** ...\n<!--more-->\n1. **串的基本概念**\n \t**串(String):****是由n(n>=0)个字符组成的有限序列**,字符串简称串,是一种特殊的线性表,串中的数据元素都是单个字符\n \t**s=\"c1c2..cn\"\t(n>=0)**\n \ts是**串名**,双引号是串的**定界符**,引起来的事**串值**,n为串的长度,n=0称为**空串(Empty String)**,一个或者多个空格组成的串称为**空格串(Blank String)**\n \t串中任意个连续的字符组成的子序列称为该串的**子串(Substring)**,空串是任何串的字串,一个串除本身外,它的其他字串称为**真子串**,字串的第一个字符在主串中的位置叫**子串的位置**,两个串的长度相等并且对应的位置字符都相等,则**两个串相等**\n \t\n2. **串的顺序存储结构**\n \t串的顺序结构就是用连续的存储单元来存储串.以一组连续的存储单元放字符串的字符序列,也叫顺序串\n \t顺序串按存储分配不同分为两类:**静态分配存储,动态分配存储**\n \t静态分配存储又称为**定长顺序存储**\n \t\n3. **串的链式存储结构**\n \t串的链式存储结构就是单链表,节点的数据域是存放字符的,对于最后一个节点数据域未被字符占满的情况,可以添加特殊字符来填补,由此我们可以定义串的块链存储表示,除了定义链表的头指针外,还添加一个尾指针指示链表中最后一个节点,以便处理该节点中的信息.\n \t\n4. **数组的基本概念**\n \t**数组(Array)**:是一组相同数据类型的数据元素的有限序列,在一组地址连续的存储单元中,数组元素按先后次序存放,数组元素在数组中的位置称为**数组下标**,数组下标的个数称为**数组的维数**,通过地址计算取得数据元素地址的存储结构称为**随机存储结构**\n \t二维数组存放方式:行序为主序,以列序为主序\n \t矩阵使人们研究的数学对象,通常用来组织数据,其中就包含数组的应用,其中特殊矩阵,稀疏矩阵等\n\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/101156543](https://blog.csdn.net/qq_20340547/article/details/101156543)","slug":"book/2019-11-26-21","published":1,"updated":"2019-12-15T07:17:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue1y000abcvzbbekcf56","content":"<p>串(String):<strong>是由n(n&gt;=0)个字符组成的有限序列</strong>,字符串简称串,是一种特殊的线性表,串中的数据元素都是单个字符<br>     <strong>s=”c1c2..cn”    (n&gt;=0)</strong> …</p>\n<a id=\"more\"></a>\n<ol>\n<li><p><strong>串的基本概念</strong><br>  <strong>串(String):**</strong>是由n(n&gt;=0)个字符组成的有限序列**,字符串简称串,是一种特殊的线性表,串中的数据元素都是单个字符<br>  <strong>s=”c1c2..cn”    (n&gt;=0)</strong><br>  s是<strong>串名</strong>,双引号是串的<strong>定界符</strong>,引起来的事<strong>串值</strong>,n为串的长度,n=0称为<strong>空串(Empty String)</strong>,一个或者多个空格组成的串称为<strong>空格串(Blank String)</strong><br>  串中任意个连续的字符组成的子序列称为该串的<strong>子串(Substring)</strong>,空串是任何串的字串,一个串除本身外,它的其他字串称为<strong>真子串</strong>,字串的第一个字符在主串中的位置叫<strong>子串的位置</strong>,两个串的长度相等并且对应的位置字符都相等,则<strong>两个串相等</strong></p>\n</li>\n<li><p><strong>串的顺序存储结构</strong><br>  串的顺序结构就是用连续的存储单元来存储串.以一组连续的存储单元放字符串的字符序列,也叫顺序串<br>  顺序串按存储分配不同分为两类:<strong>静态分配存储,动态分配存储</strong><br>  静态分配存储又称为<strong>定长顺序存储</strong></p>\n</li>\n<li><p><strong>串的链式存储结构</strong><br>  串的链式存储结构就是单链表,节点的数据域是存放字符的,对于最后一个节点数据域未被字符占满的情况,可以添加特殊字符来填补,由此我们可以定义串的块链存储表示,除了定义链表的头指针外,还添加一个尾指针指示链表中最后一个节点,以便处理该节点中的信息.</p>\n</li>\n<li><p><strong>数组的基本概念</strong><br>  <strong>数组(Array)</strong>:是一组相同数据类型的数据元素的有限序列,在一组地址连续的存储单元中,数组元素按先后次序存放,数组元素在数组中的位置称为<strong>数组下标</strong>,数组下标的个数称为<strong>数组的维数</strong>,通过地址计算取得数据元素地址的存储结构称为<strong>随机存储结构</strong><br>  二维数组存放方式:行序为主序,以列序为主序<br>  矩阵使人们研究的数学对象,通常用来组织数据,其中就包含数组的应用,其中特殊矩阵,稀疏矩阵等</p>\n</li>\n</ol>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/101156543\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/101156543</a></p>\n","site":{"data":{}},"excerpt":"<p>串(String):<strong>是由n(n&gt;=0)个字符组成的有限序列</strong>,字符串简称串,是一种特殊的线性表,串中的数据元素都是单个字符<br>     <strong>s=”c1c2..cn”    (n&gt;=0)</strong> …</p>","more":"<ol>\n<li><p><strong>串的基本概念</strong><br>  <strong>串(String):**</strong>是由n(n&gt;=0)个字符组成的有限序列**,字符串简称串,是一种特殊的线性表,串中的数据元素都是单个字符<br>  <strong>s=”c1c2..cn”    (n&gt;=0)</strong><br>  s是<strong>串名</strong>,双引号是串的<strong>定界符</strong>,引起来的事<strong>串值</strong>,n为串的长度,n=0称为<strong>空串(Empty String)</strong>,一个或者多个空格组成的串称为<strong>空格串(Blank String)</strong><br>  串中任意个连续的字符组成的子序列称为该串的<strong>子串(Substring)</strong>,空串是任何串的字串,一个串除本身外,它的其他字串称为<strong>真子串</strong>,字串的第一个字符在主串中的位置叫<strong>子串的位置</strong>,两个串的长度相等并且对应的位置字符都相等,则<strong>两个串相等</strong></p>\n</li>\n<li><p><strong>串的顺序存储结构</strong><br>  串的顺序结构就是用连续的存储单元来存储串.以一组连续的存储单元放字符串的字符序列,也叫顺序串<br>  顺序串按存储分配不同分为两类:<strong>静态分配存储,动态分配存储</strong><br>  静态分配存储又称为<strong>定长顺序存储</strong></p>\n</li>\n<li><p><strong>串的链式存储结构</strong><br>  串的链式存储结构就是单链表,节点的数据域是存放字符的,对于最后一个节点数据域未被字符占满的情况,可以添加特殊字符来填补,由此我们可以定义串的块链存储表示,除了定义链表的头指针外,还添加一个尾指针指示链表中最后一个节点,以便处理该节点中的信息.</p>\n</li>\n<li><p><strong>数组的基本概念</strong><br>  <strong>数组(Array)</strong>:是一组相同数据类型的数据元素的有限序列,在一组地址连续的存储单元中,数组元素按先后次序存放,数组元素在数组中的位置称为<strong>数组下标</strong>,数组下标的个数称为<strong>数组的维数</strong>,通过地址计算取得数据元素地址的存储结构称为<strong>随机存储结构</strong><br>  二维数组存放方式:行序为主序,以列序为主序<br>  矩阵使人们研究的数学对象,通常用来组织数据,其中就包含数组的应用,其中特殊矩阵,稀疏矩阵等</p>\n</li>\n</ol>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/101156543\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/101156543</a></p>"},{"title":"linux常用命令","date":"2017-05-23T11:05:48.000Z","_content":"日常能用到的一些linux常用命令,linux常用目录的作用...\n<!--more-->\n**1:linux常用目录的作用**\n\t/:根目录\n\t/bin:命令保存目录(普通用户就可以读取的命令)\n\t/boot:启动目录,启动相关文件\n\t/dev:设备文件保存目录\n\t/etc:配置文件保存目录\n\t/home:普通用户的家目录\n\t/lib:系统库保存目录\n\t/mnt:系统挂载目录\n\t/media:挂载目录\n\t/proc和/sys:不能直接操作,保存的是内存的过载点\n\t/temp:临时目录\n\t/sbin:命令保存目录(超级用户才能使用的目录)\n\t/usr:系统软件资源目录\n\t\t/usr/bin/系统命令(普通用户)\n\t\t/usr/sbin系统命令(超级用户)\n\t/var:系统相关文档内容\n\n**2:文件处理命令**\n\t\n\t2.1:目录处理命令和文件处理命令:\n\t\t建立目录:mkdir -p [目录名]\n\t\t选项:-p 递归创建\n\t\t命令英文原意:make directories\t\n\t\t\n\t\t切换所在目录:cd [目录]\n\t\t选项: ~ 进入当前用户的家目录(直接cd是一样的效果)\n    \t\t - 进入上次目录\n\t\t     .. 进入上一级目录\n\t\t     . 进入当前目录\n\t\t命令英文原意:change directory\t \n\t\t\n\t\t查询所在目录位置:pwd\n\t\t命令英文原意:print working directory\n\t\t\n\t\t删除空目录:rmdir [目录名]\n\t\t命令英文原意:remove empty directories\n\t\n\t\t删除文件或目录:rm -rf [文件或目录]\n\t\t选项: -r 删除目录\n\t\t      -f 强制\n\t\t命令英文原意:remove\n\t\t\n\t\t复制命令:cp [选项] [源文件或目录] [目标目录]\n\t\t选项: -r 复制目录\n\t\t      -p 连带文件属性复制\n\t\t      -d 若源文件是链接文件,则复制链接属性\n\t\t      -a 相当于 -pdr(复制的文件与源文件的属性完全一样)\n\t\t命令英文原意:copy\n\n\t\t显示文件信息:ls [选项] [文件或目录]\n\t\t选项:-a 显示所有文件,包括隐藏的文件\n\t     \t-l 显示详细信息(等同于ll)\n\t     \t-d 查看目录属性\n\t    \t-h 人性化显示(变成人类看的懂的)\n\t     \t-i 显示inode(带文件号)\n\n\t\t剪切或改名:mv [源文件或目录] [目标目录]\n\t\t命令英文原意:move\n\n\t\n\t2.2:链接命令:\n\t\ta:链接命令:ln -s [源文件] [目标文件]\n\t\t选项: -s 创建软链接(类似于快捷方式)\n\t\t命令英文原意:link\n\t\t功能描述:生成链接文件\n\n**3:文件搜索命令**\n\t\n\t3.1:文件搜索命令locate与find(locate比find效率高):\n\t\tlocate 文件名\n\t\t功能描述:在后台数据库(/var/lib/mlocate 这个文件存放的locate命令所搜索的后台数据库,每天更新  一次,新建文件无法看到,强制更新数据库命令:updatedb)按文件名搜索,搜索速度更快\n\n\t3.2:命令搜索命令whereis与which:\n\t\t搜索系统命令命令: whereis 命令名\n\t\t选项:-b 只查找可执行文件\n\t\t     -m 只查找帮助文件\t\n\n\t\t搜索系统命令命令:which 文件名\n\t\t功能描述:搜索命令所在的目录以及别名\n\n\t\tPATH环境变量:定义的是系统搜索命令的路径\n\t\t\n\t3.3:字符串搜索命令grep:\n\t\t搜索字符串命令:grep [选项] 字符串 文件名\n\t\t功能描述:在文件当中匹配符合条件的字符串\n\t\t选项: -i 忽略大小写\n\t\t      -v 排除指定字符串\n\n\t3.4:find命令与grep命令的区别:\n\t\tfind [搜索范围] [搜索条件]\n\t\t功能描述:搜索文件(避免大范围搜索,非常耗资源,find是系统当中搜索符合条件的文件名,如果需要匹配,使用通配符匹配,通配符是完全匹配,通配符 * 匹配任意内容,? 匹配任意字符 [] 匹配任意一个中括号内的字符)\n\t\tfind [搜索范围] -user :按照所有者搜索\n\t\tfind [搜索范围] -nouser :查找没有所有者的文件\n\n**4:帮助命令**\n\t\n\t4.1:帮助命令man: \n\t\tman 命令 \n\t\t功能描述:获取指定命令的帮助\n\t\tman的级别: 1:查看命令的帮助\n\t\t\t\t  2:查看可被内核调用的函数的帮助\n\t\t\t\t  3:查看函数和函数库的帮助\n\t\t\t\t  4:查看特殊文件的帮助(主要是/dev目录下的文件)\n\t\t\t\t  5:查看配置文件的帮助\n\t\t\t\t  6:查看游戏的帮助\n\t\t\t\t  7:查看其他杂项的帮助\n\t\t\t\t  8:查看系统管理员可用命令的帮助\n\t\t\t\t  9:查看和内核相关文件的帮助\t\n\t\t\t\t  \n\t\tman -f 命令\n\t\t功能描述:查看命令拥有什么级别的帮助(等同于 whatis 命令)\n\n\t\tman -k 命令\n\t\t功能描述:查看和命令相关的所有帮助(等同于apropos)\n\t\t\n\t\tman ls \n\t\t功能描述:查看ls的帮助\n\t\n\t4.2:其他帮助命令:\n\t\t命令 --help\n\t\t功能描述:获取命令选项的帮助\n\n\t\thelp sheel内部命令\n\t\t功能描述:获取shell内部命令的帮助\n\t\t\n\t\t详细命令帮助info:info 命令\n\t\t选项:-回车 进入子帮助页面\n\t\t     -u   进入上层页面\n\t\t     -n   进入下一个帮助小节\n\t\t     -p   进入上一个帮助小节\n\t\t     -q   退出\n\t\t\n\n**5:压缩与解压缩命令**\n\t\n\t\t5.1:压缩命令:\n\t\t常用压缩格式: .zip .gz .bz2 .tar.gz .tar.bz2\n\t\t\tzip 压缩文件名 源文件\n\t\t\t功能描述:压缩文件\n\t\t\t\n\t\t\tzip -r 压缩文件名 源目录\n\t\t\t功能描述:压缩目录\n\n\t\t\t.gz格式压缩:gzip 源文件\n\t\t\t功能描述:压缩为.gz格式的压缩文件,源文件会消失\n\t\t\n\t\t\t.gz格式压缩:gzip -c 源文件 >压缩文件\n\t\t\t功能描述:压缩为.gz格式,源文件保留\n\t\t\n\t\t\t.gz格式压缩:gzip -r 目录\n\t\t\t功能描述:压缩目录下所有的子文件,但是不能压缩目录\n\n\t\t\t.bz2格式压缩:bzip2 源文件\n\t\t\t功能描述:压缩为.bz2格式的压缩文件,不保留原文件\n\n\t\t\t.bz2格式压缩:bzip2 -k 源文件\n\t\t\t功能描述:压缩为.bz2格式的压缩文件,保留原文件(bz2不能压缩目录)\n\n\t\t\t.tar打包命令:tar -cvf 打包文件名 源文件\n\t\t\t选项:  -c 打包\n\t\t\t      -v 显示过程\n\t\t\t      -f 指定打包后的文件名\n\t\t\t      -z 压缩为.tar.gz格式\n\t\t\t      -j 压缩为.tar.bz2格式\n\n\t\t5.2:解压缩命令:\n\t\t\t常用解压缩格式: unzip .gz .bz2 .tar.gz .tar.bz2\n\t\t\tunzip 压缩文件\n\t\t\t功能描述:解压缩.zip文件\n\t\t\n\t\t\t.gz格式解压缩\n\t\t\tgzip -d 压缩文件\n\t\t\t功能描述:解压缩文件\n\t\t\n\t\t\tgunzip 压缩文件\n\t\t\t功能描述:解压缩文件\n\t\n\t\t\t.bz2格式解压缩\n\t\t\tbzip2 -d 压缩文件\n\t\t\t功能描述:解压缩,-k保留压缩文件\n\t\n\t\t\tbunzip2 压缩文件\n\t\t\t功能描述:解压缩,-k保留压缩文件\n\n\t\t\t.tar解压缩命令:tar -xvf 打包文件名 \n\t\t\t选项:-x 解打包\n\t\t     -z 压缩为.tar.gz格式\n\t\t      \n\n**6:关机与重启命令**\n\t\n\t6.1:shutdown命令:\n\tshutdown [选项] 时间\n\t选项: -c 取消前一个关机命令\n\t      -h 关机\n\t      -r 重启\n\t      \n\t6.2:其他关机命令:\n\thalt\n\tpoweroff\n\tinit 0\n\t这三个不太安全\n\tC:其他重启命令\n\treboot\n\tinit 6\n\tinit 后面数字的含义:\n\t\t0:关机\n\t\t1:单用户\n\t\t2:不完全多用户,不含NFS服务\n\t\t3:完全多用户\n\t\t4:未分配\n\t\t5:图形界面\n\t\t6:重启\n\trunlevel命令查询当前系统运行级别 结果显示的是前一个字符为原先的级别,后一个字符为当前的级别\n\t\t\n\tlogout 退出登陆命令\n\t\n\n**7:其他常用命令**\n\t\t\n\t7.1:挂载命令:\n\t\t查询与自动挂载:mount\n\t\t功能描述:查询系统中已经挂载的设备\n\t\t\n\t\tmount -a\n\t\t功能描述:依据配置文件/etc/fstab的内容,自动挂载\n\n\t\t挂载命令格式:mount [-t 文件系统] [-o 特殊选项] 设备文件名 挂载点\n\t\t选项:-t 文件系统 加入文件系统类型来指定挂载的类型,可以ext3,ext4,iso9660等文件系统\n\t\t     -o 特殊选项 可以指定挂载的额外选项\n\n\t\t挂载光盘:第一步放入光盘,第二步建立挂载(空目录)点,mkdir /mnt/cdrom/,第三部执行挂载命令\n\n\t\t卸载命令:umount 设备文件名或挂载点\n\t\t\n\t\t挂载U盘:第一步查看已挂载设备名命令 fdisk -l\n\t\t\t  第二步执行挂载命令\n\n\n\t7.2:用户登陆查看命令:\n\t\tw 用户名\n\t\t功能描述:查看用户登陆信息\n\t\t命令输出:USER 登陆的用户名\n\t\t\t TTY 登陆终端\n\t\t\t FROM 从哪个IP地址登陆\n\t\t\t LOGIN@ 登录时间\n\t\t\t IDLE 用户闲置时间\n\t\t\t JCPU 和该终端链接的所有进程占用的时间,这个时间里不包括过去的后台作业时间,但包括当前正在运行的后台作业所占用的时间\n\t\t\t PCPU 当前进程所占用的时间\n\t\t\t WHAT 当前正在运行的命令\t\t\n\t\t\t \n\t\twho \n\t\t功能描述:查看用户登陆信息\n\t\t命令输出:用户名 登陆终端 登陆时间(登陆来源IP地址)\n\n\t\tlast \n\t\t功能描述:查看当前登陆用户信息和过去登陆用户信息(last命令默认读取/var/log/wtmp文件数据)\n\t\t命令输出:用户名 登陆终端 登陆时间(登陆来源IP地址) 登录时间 退出时间(在线时间)\n\n\t\tlastlog\n\t\t功能描述:查看所有用户的最后一次登录时间(lastlog命令默认读取/var/log/lastlog文件数据)\n\t\t命令输出:用户名 登陆终端 登陆来源IP地址 最后一次登录时间\n\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/72654901](https://blog.csdn.net/qq_20340547/article/details/72654901)","source":"_posts/summary/2019-11-26.md","raw":"---\ntitle: linux常用命令\ndate: 2017-05-23 19:05:48\ntags: linux\ncategories: 日常总结\n---\n日常能用到的一些linux常用命令,linux常用目录的作用...\n<!--more-->\n**1:linux常用目录的作用**\n\t/:根目录\n\t/bin:命令保存目录(普通用户就可以读取的命令)\n\t/boot:启动目录,启动相关文件\n\t/dev:设备文件保存目录\n\t/etc:配置文件保存目录\n\t/home:普通用户的家目录\n\t/lib:系统库保存目录\n\t/mnt:系统挂载目录\n\t/media:挂载目录\n\t/proc和/sys:不能直接操作,保存的是内存的过载点\n\t/temp:临时目录\n\t/sbin:命令保存目录(超级用户才能使用的目录)\n\t/usr:系统软件资源目录\n\t\t/usr/bin/系统命令(普通用户)\n\t\t/usr/sbin系统命令(超级用户)\n\t/var:系统相关文档内容\n\n**2:文件处理命令**\n\t\n\t2.1:目录处理命令和文件处理命令:\n\t\t建立目录:mkdir -p [目录名]\n\t\t选项:-p 递归创建\n\t\t命令英文原意:make directories\t\n\t\t\n\t\t切换所在目录:cd [目录]\n\t\t选项: ~ 进入当前用户的家目录(直接cd是一样的效果)\n    \t\t - 进入上次目录\n\t\t     .. 进入上一级目录\n\t\t     . 进入当前目录\n\t\t命令英文原意:change directory\t \n\t\t\n\t\t查询所在目录位置:pwd\n\t\t命令英文原意:print working directory\n\t\t\n\t\t删除空目录:rmdir [目录名]\n\t\t命令英文原意:remove empty directories\n\t\n\t\t删除文件或目录:rm -rf [文件或目录]\n\t\t选项: -r 删除目录\n\t\t      -f 强制\n\t\t命令英文原意:remove\n\t\t\n\t\t复制命令:cp [选项] [源文件或目录] [目标目录]\n\t\t选项: -r 复制目录\n\t\t      -p 连带文件属性复制\n\t\t      -d 若源文件是链接文件,则复制链接属性\n\t\t      -a 相当于 -pdr(复制的文件与源文件的属性完全一样)\n\t\t命令英文原意:copy\n\n\t\t显示文件信息:ls [选项] [文件或目录]\n\t\t选项:-a 显示所有文件,包括隐藏的文件\n\t     \t-l 显示详细信息(等同于ll)\n\t     \t-d 查看目录属性\n\t    \t-h 人性化显示(变成人类看的懂的)\n\t     \t-i 显示inode(带文件号)\n\n\t\t剪切或改名:mv [源文件或目录] [目标目录]\n\t\t命令英文原意:move\n\n\t\n\t2.2:链接命令:\n\t\ta:链接命令:ln -s [源文件] [目标文件]\n\t\t选项: -s 创建软链接(类似于快捷方式)\n\t\t命令英文原意:link\n\t\t功能描述:生成链接文件\n\n**3:文件搜索命令**\n\t\n\t3.1:文件搜索命令locate与find(locate比find效率高):\n\t\tlocate 文件名\n\t\t功能描述:在后台数据库(/var/lib/mlocate 这个文件存放的locate命令所搜索的后台数据库,每天更新  一次,新建文件无法看到,强制更新数据库命令:updatedb)按文件名搜索,搜索速度更快\n\n\t3.2:命令搜索命令whereis与which:\n\t\t搜索系统命令命令: whereis 命令名\n\t\t选项:-b 只查找可执行文件\n\t\t     -m 只查找帮助文件\t\n\n\t\t搜索系统命令命令:which 文件名\n\t\t功能描述:搜索命令所在的目录以及别名\n\n\t\tPATH环境变量:定义的是系统搜索命令的路径\n\t\t\n\t3.3:字符串搜索命令grep:\n\t\t搜索字符串命令:grep [选项] 字符串 文件名\n\t\t功能描述:在文件当中匹配符合条件的字符串\n\t\t选项: -i 忽略大小写\n\t\t      -v 排除指定字符串\n\n\t3.4:find命令与grep命令的区别:\n\t\tfind [搜索范围] [搜索条件]\n\t\t功能描述:搜索文件(避免大范围搜索,非常耗资源,find是系统当中搜索符合条件的文件名,如果需要匹配,使用通配符匹配,通配符是完全匹配,通配符 * 匹配任意内容,? 匹配任意字符 [] 匹配任意一个中括号内的字符)\n\t\tfind [搜索范围] -user :按照所有者搜索\n\t\tfind [搜索范围] -nouser :查找没有所有者的文件\n\n**4:帮助命令**\n\t\n\t4.1:帮助命令man: \n\t\tman 命令 \n\t\t功能描述:获取指定命令的帮助\n\t\tman的级别: 1:查看命令的帮助\n\t\t\t\t  2:查看可被内核调用的函数的帮助\n\t\t\t\t  3:查看函数和函数库的帮助\n\t\t\t\t  4:查看特殊文件的帮助(主要是/dev目录下的文件)\n\t\t\t\t  5:查看配置文件的帮助\n\t\t\t\t  6:查看游戏的帮助\n\t\t\t\t  7:查看其他杂项的帮助\n\t\t\t\t  8:查看系统管理员可用命令的帮助\n\t\t\t\t  9:查看和内核相关文件的帮助\t\n\t\t\t\t  \n\t\tman -f 命令\n\t\t功能描述:查看命令拥有什么级别的帮助(等同于 whatis 命令)\n\n\t\tman -k 命令\n\t\t功能描述:查看和命令相关的所有帮助(等同于apropos)\n\t\t\n\t\tman ls \n\t\t功能描述:查看ls的帮助\n\t\n\t4.2:其他帮助命令:\n\t\t命令 --help\n\t\t功能描述:获取命令选项的帮助\n\n\t\thelp sheel内部命令\n\t\t功能描述:获取shell内部命令的帮助\n\t\t\n\t\t详细命令帮助info:info 命令\n\t\t选项:-回车 进入子帮助页面\n\t\t     -u   进入上层页面\n\t\t     -n   进入下一个帮助小节\n\t\t     -p   进入上一个帮助小节\n\t\t     -q   退出\n\t\t\n\n**5:压缩与解压缩命令**\n\t\n\t\t5.1:压缩命令:\n\t\t常用压缩格式: .zip .gz .bz2 .tar.gz .tar.bz2\n\t\t\tzip 压缩文件名 源文件\n\t\t\t功能描述:压缩文件\n\t\t\t\n\t\t\tzip -r 压缩文件名 源目录\n\t\t\t功能描述:压缩目录\n\n\t\t\t.gz格式压缩:gzip 源文件\n\t\t\t功能描述:压缩为.gz格式的压缩文件,源文件会消失\n\t\t\n\t\t\t.gz格式压缩:gzip -c 源文件 >压缩文件\n\t\t\t功能描述:压缩为.gz格式,源文件保留\n\t\t\n\t\t\t.gz格式压缩:gzip -r 目录\n\t\t\t功能描述:压缩目录下所有的子文件,但是不能压缩目录\n\n\t\t\t.bz2格式压缩:bzip2 源文件\n\t\t\t功能描述:压缩为.bz2格式的压缩文件,不保留原文件\n\n\t\t\t.bz2格式压缩:bzip2 -k 源文件\n\t\t\t功能描述:压缩为.bz2格式的压缩文件,保留原文件(bz2不能压缩目录)\n\n\t\t\t.tar打包命令:tar -cvf 打包文件名 源文件\n\t\t\t选项:  -c 打包\n\t\t\t      -v 显示过程\n\t\t\t      -f 指定打包后的文件名\n\t\t\t      -z 压缩为.tar.gz格式\n\t\t\t      -j 压缩为.tar.bz2格式\n\n\t\t5.2:解压缩命令:\n\t\t\t常用解压缩格式: unzip .gz .bz2 .tar.gz .tar.bz2\n\t\t\tunzip 压缩文件\n\t\t\t功能描述:解压缩.zip文件\n\t\t\n\t\t\t.gz格式解压缩\n\t\t\tgzip -d 压缩文件\n\t\t\t功能描述:解压缩文件\n\t\t\n\t\t\tgunzip 压缩文件\n\t\t\t功能描述:解压缩文件\n\t\n\t\t\t.bz2格式解压缩\n\t\t\tbzip2 -d 压缩文件\n\t\t\t功能描述:解压缩,-k保留压缩文件\n\t\n\t\t\tbunzip2 压缩文件\n\t\t\t功能描述:解压缩,-k保留压缩文件\n\n\t\t\t.tar解压缩命令:tar -xvf 打包文件名 \n\t\t\t选项:-x 解打包\n\t\t     -z 压缩为.tar.gz格式\n\t\t      \n\n**6:关机与重启命令**\n\t\n\t6.1:shutdown命令:\n\tshutdown [选项] 时间\n\t选项: -c 取消前一个关机命令\n\t      -h 关机\n\t      -r 重启\n\t      \n\t6.2:其他关机命令:\n\thalt\n\tpoweroff\n\tinit 0\n\t这三个不太安全\n\tC:其他重启命令\n\treboot\n\tinit 6\n\tinit 后面数字的含义:\n\t\t0:关机\n\t\t1:单用户\n\t\t2:不完全多用户,不含NFS服务\n\t\t3:完全多用户\n\t\t4:未分配\n\t\t5:图形界面\n\t\t6:重启\n\trunlevel命令查询当前系统运行级别 结果显示的是前一个字符为原先的级别,后一个字符为当前的级别\n\t\t\n\tlogout 退出登陆命令\n\t\n\n**7:其他常用命令**\n\t\t\n\t7.1:挂载命令:\n\t\t查询与自动挂载:mount\n\t\t功能描述:查询系统中已经挂载的设备\n\t\t\n\t\tmount -a\n\t\t功能描述:依据配置文件/etc/fstab的内容,自动挂载\n\n\t\t挂载命令格式:mount [-t 文件系统] [-o 特殊选项] 设备文件名 挂载点\n\t\t选项:-t 文件系统 加入文件系统类型来指定挂载的类型,可以ext3,ext4,iso9660等文件系统\n\t\t     -o 特殊选项 可以指定挂载的额外选项\n\n\t\t挂载光盘:第一步放入光盘,第二步建立挂载(空目录)点,mkdir /mnt/cdrom/,第三部执行挂载命令\n\n\t\t卸载命令:umount 设备文件名或挂载点\n\t\t\n\t\t挂载U盘:第一步查看已挂载设备名命令 fdisk -l\n\t\t\t  第二步执行挂载命令\n\n\n\t7.2:用户登陆查看命令:\n\t\tw 用户名\n\t\t功能描述:查看用户登陆信息\n\t\t命令输出:USER 登陆的用户名\n\t\t\t TTY 登陆终端\n\t\t\t FROM 从哪个IP地址登陆\n\t\t\t LOGIN@ 登录时间\n\t\t\t IDLE 用户闲置时间\n\t\t\t JCPU 和该终端链接的所有进程占用的时间,这个时间里不包括过去的后台作业时间,但包括当前正在运行的后台作业所占用的时间\n\t\t\t PCPU 当前进程所占用的时间\n\t\t\t WHAT 当前正在运行的命令\t\t\n\t\t\t \n\t\twho \n\t\t功能描述:查看用户登陆信息\n\t\t命令输出:用户名 登陆终端 登陆时间(登陆来源IP地址)\n\n\t\tlast \n\t\t功能描述:查看当前登陆用户信息和过去登陆用户信息(last命令默认读取/var/log/wtmp文件数据)\n\t\t命令输出:用户名 登陆终端 登陆时间(登陆来源IP地址) 登录时间 退出时间(在线时间)\n\n\t\tlastlog\n\t\t功能描述:查看所有用户的最后一次登录时间(lastlog命令默认读取/var/log/lastlog文件数据)\n\t\t命令输出:用户名 登陆终端 登陆来源IP地址 最后一次登录时间\n\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/72654901](https://blog.csdn.net/qq_20340547/article/details/72654901)","slug":"summary/2019-11-26","published":1,"updated":"2019-12-15T07:17:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue1z000bbcvzen4n3ide","content":"<p>日常能用到的一些linux常用命令,linux常用目录的作用…</p>\n<a id=\"more\"></a>\n<p><strong>1:linux常用目录的作用</strong><br>    /:根目录<br>    /bin:命令保存目录(普通用户就可以读取的命令)<br>    /boot:启动目录,启动相关文件<br>    /dev:设备文件保存目录<br>    /etc:配置文件保存目录<br>    /home:普通用户的家目录<br>    /lib:系统库保存目录<br>    /mnt:系统挂载目录<br>    /media:挂载目录<br>    /proc和/sys:不能直接操作,保存的是内存的过载点<br>    /temp:临时目录<br>    /sbin:命令保存目录(超级用户才能使用的目录)<br>    /usr:系统软件资源目录<br>        /usr/bin/系统命令(普通用户)<br>        /usr/sbin系统命令(超级用户)<br>    /var:系统相关文档内容</p>\n<p><strong>2:文件处理命令</strong></p>\n<pre><code>2.1:目录处理命令和文件处理命令:\n    建立目录:mkdir -p [目录名]\n    选项:-p 递归创建\n    命令英文原意:make directories    \n\n    切换所在目录:cd [目录]\n    选项: ~ 进入当前用户的家目录(直接cd是一样的效果)\n         - 进入上次目录\n         .. 进入上一级目录\n         . 进入当前目录\n    命令英文原意:change directory     \n\n    查询所在目录位置:pwd\n    命令英文原意:print working directory\n\n    删除空目录:rmdir [目录名]\n    命令英文原意:remove empty directories\n\n    删除文件或目录:rm -rf [文件或目录]\n    选项: -r 删除目录\n          -f 强制\n    命令英文原意:remove\n\n    复制命令:cp [选项] [源文件或目录] [目标目录]\n    选项: -r 复制目录\n          -p 连带文件属性复制\n          -d 若源文件是链接文件,则复制链接属性\n          -a 相当于 -pdr(复制的文件与源文件的属性完全一样)\n    命令英文原意:copy\n\n    显示文件信息:ls [选项] [文件或目录]\n    选项:-a 显示所有文件,包括隐藏的文件\n         -l 显示详细信息(等同于ll)\n         -d 查看目录属性\n        -h 人性化显示(变成人类看的懂的)\n         -i 显示inode(带文件号)\n\n    剪切或改名:mv [源文件或目录] [目标目录]\n    命令英文原意:move\n\n\n2.2:链接命令:\n    a:链接命令:ln -s [源文件] [目标文件]\n    选项: -s 创建软链接(类似于快捷方式)\n    命令英文原意:link\n    功能描述:生成链接文件</code></pre>\n<p><strong>3:文件搜索命令</strong></p>\n<pre><code>3.1:文件搜索命令locate与find(locate比find效率高):\n    locate 文件名\n    功能描述:在后台数据库(/var/lib/mlocate 这个文件存放的locate命令所搜索的后台数据库,每天更新  一次,新建文件无法看到,强制更新数据库命令:updatedb)按文件名搜索,搜索速度更快\n\n3.2:命令搜索命令whereis与which:\n    搜索系统命令命令: whereis 命令名\n    选项:-b 只查找可执行文件\n         -m 只查找帮助文件    \n\n    搜索系统命令命令:which 文件名\n    功能描述:搜索命令所在的目录以及别名\n\n    PATH环境变量:定义的是系统搜索命令的路径\n\n3.3:字符串搜索命令grep:\n    搜索字符串命令:grep [选项] 字符串 文件名\n    功能描述:在文件当中匹配符合条件的字符串\n    选项: -i 忽略大小写\n          -v 排除指定字符串\n\n3.4:find命令与grep命令的区别:\n    find [搜索范围] [搜索条件]\n    功能描述:搜索文件(避免大范围搜索,非常耗资源,find是系统当中搜索符合条件的文件名,如果需要匹配,使用通配符匹配,通配符是完全匹配,通配符 * 匹配任意内容,? 匹配任意字符 [] 匹配任意一个中括号内的字符)\n    find [搜索范围] -user :按照所有者搜索\n    find [搜索范围] -nouser :查找没有所有者的文件</code></pre>\n<p><strong>4:帮助命令</strong></p>\n<pre><code>4.1:帮助命令man: \n    man 命令 \n    功能描述:获取指定命令的帮助\n    man的级别: 1:查看命令的帮助\n              2:查看可被内核调用的函数的帮助\n              3:查看函数和函数库的帮助\n              4:查看特殊文件的帮助(主要是/dev目录下的文件)\n              5:查看配置文件的帮助\n              6:查看游戏的帮助\n              7:查看其他杂项的帮助\n              8:查看系统管理员可用命令的帮助\n              9:查看和内核相关文件的帮助    \n\n    man -f 命令\n    功能描述:查看命令拥有什么级别的帮助(等同于 whatis 命令)\n\n    man -k 命令\n    功能描述:查看和命令相关的所有帮助(等同于apropos)\n\n    man ls \n    功能描述:查看ls的帮助\n\n4.2:其他帮助命令:\n    命令 --help\n    功能描述:获取命令选项的帮助\n\n    help sheel内部命令\n    功能描述:获取shell内部命令的帮助\n\n    详细命令帮助info:info 命令\n    选项:-回车 进入子帮助页面\n         -u   进入上层页面\n         -n   进入下一个帮助小节\n         -p   进入上一个帮助小节\n         -q   退出</code></pre>\n<p><strong>5:压缩与解压缩命令</strong></p>\n<pre><code>    5.1:压缩命令:\n    常用压缩格式: .zip .gz .bz2 .tar.gz .tar.bz2\n        zip 压缩文件名 源文件\n        功能描述:压缩文件\n\n        zip -r 压缩文件名 源目录\n        功能描述:压缩目录\n\n        .gz格式压缩:gzip 源文件\n        功能描述:压缩为.gz格式的压缩文件,源文件会消失\n\n        .gz格式压缩:gzip -c 源文件 &gt;压缩文件\n        功能描述:压缩为.gz格式,源文件保留\n\n        .gz格式压缩:gzip -r 目录\n        功能描述:压缩目录下所有的子文件,但是不能压缩目录\n\n        .bz2格式压缩:bzip2 源文件\n        功能描述:压缩为.bz2格式的压缩文件,不保留原文件\n\n        .bz2格式压缩:bzip2 -k 源文件\n        功能描述:压缩为.bz2格式的压缩文件,保留原文件(bz2不能压缩目录)\n\n        .tar打包命令:tar -cvf 打包文件名 源文件\n        选项:  -c 打包\n              -v 显示过程\n              -f 指定打包后的文件名\n              -z 压缩为.tar.gz格式\n              -j 压缩为.tar.bz2格式\n\n    5.2:解压缩命令:\n        常用解压缩格式: unzip .gz .bz2 .tar.gz .tar.bz2\n        unzip 压缩文件\n        功能描述:解压缩.zip文件\n\n        .gz格式解压缩\n        gzip -d 压缩文件\n        功能描述:解压缩文件\n\n        gunzip 压缩文件\n        功能描述:解压缩文件\n\n        .bz2格式解压缩\n        bzip2 -d 压缩文件\n        功能描述:解压缩,-k保留压缩文件\n\n        bunzip2 压缩文件\n        功能描述:解压缩,-k保留压缩文件\n\n        .tar解压缩命令:tar -xvf 打包文件名 \n        选项:-x 解打包\n         -z 压缩为.tar.gz格式</code></pre>\n<p><strong>6:关机与重启命令</strong></p>\n<pre><code>6.1:shutdown命令:\nshutdown [选项] 时间\n选项: -c 取消前一个关机命令\n      -h 关机\n      -r 重启\n\n6.2:其他关机命令:\nhalt\npoweroff\ninit 0\n这三个不太安全\nC:其他重启命令\nreboot\ninit 6\ninit 后面数字的含义:\n    0:关机\n    1:单用户\n    2:不完全多用户,不含NFS服务\n    3:完全多用户\n    4:未分配\n    5:图形界面\n    6:重启\nrunlevel命令查询当前系统运行级别 结果显示的是前一个字符为原先的级别,后一个字符为当前的级别\n\nlogout 退出登陆命令</code></pre>\n<p><strong>7:其他常用命令</strong></p>\n<pre><code>7.1:挂载命令:\n    查询与自动挂载:mount\n    功能描述:查询系统中已经挂载的设备\n\n    mount -a\n    功能描述:依据配置文件/etc/fstab的内容,自动挂载\n\n    挂载命令格式:mount [-t 文件系统] [-o 特殊选项] 设备文件名 挂载点\n    选项:-t 文件系统 加入文件系统类型来指定挂载的类型,可以ext3,ext4,iso9660等文件系统\n         -o 特殊选项 可以指定挂载的额外选项\n\n    挂载光盘:第一步放入光盘,第二步建立挂载(空目录)点,mkdir /mnt/cdrom/,第三部执行挂载命令\n\n    卸载命令:umount 设备文件名或挂载点\n\n    挂载U盘:第一步查看已挂载设备名命令 fdisk -l\n          第二步执行挂载命令\n\n\n7.2:用户登陆查看命令:\n    w 用户名\n    功能描述:查看用户登陆信息\n    命令输出:USER 登陆的用户名\n         TTY 登陆终端\n         FROM 从哪个IP地址登陆\n         LOGIN@ 登录时间\n         IDLE 用户闲置时间\n         JCPU 和该终端链接的所有进程占用的时间,这个时间里不包括过去的后台作业时间,但包括当前正在运行的后台作业所占用的时间\n         PCPU 当前进程所占用的时间\n         WHAT 当前正在运行的命令        \n\n    who \n    功能描述:查看用户登陆信息\n    命令输出:用户名 登陆终端 登陆时间(登陆来源IP地址)\n\n    last \n    功能描述:查看当前登陆用户信息和过去登陆用户信息(last命令默认读取/var/log/wtmp文件数据)\n    命令输出:用户名 登陆终端 登陆时间(登陆来源IP地址) 登录时间 退出时间(在线时间)\n\n    lastlog\n    功能描述:查看所有用户的最后一次登录时间(lastlog命令默认读取/var/log/lastlog文件数据)\n    命令输出:用户名 登陆终端 登陆来源IP地址 最后一次登录时间</code></pre>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/72654901\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/72654901</a></p>\n","site":{"data":{}},"excerpt":"<p>日常能用到的一些linux常用命令,linux常用目录的作用…</p>","more":"<p><strong>1:linux常用目录的作用</strong><br>    /:根目录<br>    /bin:命令保存目录(普通用户就可以读取的命令)<br>    /boot:启动目录,启动相关文件<br>    /dev:设备文件保存目录<br>    /etc:配置文件保存目录<br>    /home:普通用户的家目录<br>    /lib:系统库保存目录<br>    /mnt:系统挂载目录<br>    /media:挂载目录<br>    /proc和/sys:不能直接操作,保存的是内存的过载点<br>    /temp:临时目录<br>    /sbin:命令保存目录(超级用户才能使用的目录)<br>    /usr:系统软件资源目录<br>        /usr/bin/系统命令(普通用户)<br>        /usr/sbin系统命令(超级用户)<br>    /var:系统相关文档内容</p>\n<p><strong>2:文件处理命令</strong></p>\n<pre><code>2.1:目录处理命令和文件处理命令:\n    建立目录:mkdir -p [目录名]\n    选项:-p 递归创建\n    命令英文原意:make directories    \n\n    切换所在目录:cd [目录]\n    选项: ~ 进入当前用户的家目录(直接cd是一样的效果)\n         - 进入上次目录\n         .. 进入上一级目录\n         . 进入当前目录\n    命令英文原意:change directory     \n\n    查询所在目录位置:pwd\n    命令英文原意:print working directory\n\n    删除空目录:rmdir [目录名]\n    命令英文原意:remove empty directories\n\n    删除文件或目录:rm -rf [文件或目录]\n    选项: -r 删除目录\n          -f 强制\n    命令英文原意:remove\n\n    复制命令:cp [选项] [源文件或目录] [目标目录]\n    选项: -r 复制目录\n          -p 连带文件属性复制\n          -d 若源文件是链接文件,则复制链接属性\n          -a 相当于 -pdr(复制的文件与源文件的属性完全一样)\n    命令英文原意:copy\n\n    显示文件信息:ls [选项] [文件或目录]\n    选项:-a 显示所有文件,包括隐藏的文件\n         -l 显示详细信息(等同于ll)\n         -d 查看目录属性\n        -h 人性化显示(变成人类看的懂的)\n         -i 显示inode(带文件号)\n\n    剪切或改名:mv [源文件或目录] [目标目录]\n    命令英文原意:move\n\n\n2.2:链接命令:\n    a:链接命令:ln -s [源文件] [目标文件]\n    选项: -s 创建软链接(类似于快捷方式)\n    命令英文原意:link\n    功能描述:生成链接文件</code></pre>\n<p><strong>3:文件搜索命令</strong></p>\n<pre><code>3.1:文件搜索命令locate与find(locate比find效率高):\n    locate 文件名\n    功能描述:在后台数据库(/var/lib/mlocate 这个文件存放的locate命令所搜索的后台数据库,每天更新  一次,新建文件无法看到,强制更新数据库命令:updatedb)按文件名搜索,搜索速度更快\n\n3.2:命令搜索命令whereis与which:\n    搜索系统命令命令: whereis 命令名\n    选项:-b 只查找可执行文件\n         -m 只查找帮助文件    \n\n    搜索系统命令命令:which 文件名\n    功能描述:搜索命令所在的目录以及别名\n\n    PATH环境变量:定义的是系统搜索命令的路径\n\n3.3:字符串搜索命令grep:\n    搜索字符串命令:grep [选项] 字符串 文件名\n    功能描述:在文件当中匹配符合条件的字符串\n    选项: -i 忽略大小写\n          -v 排除指定字符串\n\n3.4:find命令与grep命令的区别:\n    find [搜索范围] [搜索条件]\n    功能描述:搜索文件(避免大范围搜索,非常耗资源,find是系统当中搜索符合条件的文件名,如果需要匹配,使用通配符匹配,通配符是完全匹配,通配符 * 匹配任意内容,? 匹配任意字符 [] 匹配任意一个中括号内的字符)\n    find [搜索范围] -user :按照所有者搜索\n    find [搜索范围] -nouser :查找没有所有者的文件</code></pre>\n<p><strong>4:帮助命令</strong></p>\n<pre><code>4.1:帮助命令man: \n    man 命令 \n    功能描述:获取指定命令的帮助\n    man的级别: 1:查看命令的帮助\n              2:查看可被内核调用的函数的帮助\n              3:查看函数和函数库的帮助\n              4:查看特殊文件的帮助(主要是/dev目录下的文件)\n              5:查看配置文件的帮助\n              6:查看游戏的帮助\n              7:查看其他杂项的帮助\n              8:查看系统管理员可用命令的帮助\n              9:查看和内核相关文件的帮助    \n\n    man -f 命令\n    功能描述:查看命令拥有什么级别的帮助(等同于 whatis 命令)\n\n    man -k 命令\n    功能描述:查看和命令相关的所有帮助(等同于apropos)\n\n    man ls \n    功能描述:查看ls的帮助\n\n4.2:其他帮助命令:\n    命令 --help\n    功能描述:获取命令选项的帮助\n\n    help sheel内部命令\n    功能描述:获取shell内部命令的帮助\n\n    详细命令帮助info:info 命令\n    选项:-回车 进入子帮助页面\n         -u   进入上层页面\n         -n   进入下一个帮助小节\n         -p   进入上一个帮助小节\n         -q   退出</code></pre>\n<p><strong>5:压缩与解压缩命令</strong></p>\n<pre><code>    5.1:压缩命令:\n    常用压缩格式: .zip .gz .bz2 .tar.gz .tar.bz2\n        zip 压缩文件名 源文件\n        功能描述:压缩文件\n\n        zip -r 压缩文件名 源目录\n        功能描述:压缩目录\n\n        .gz格式压缩:gzip 源文件\n        功能描述:压缩为.gz格式的压缩文件,源文件会消失\n\n        .gz格式压缩:gzip -c 源文件 &gt;压缩文件\n        功能描述:压缩为.gz格式,源文件保留\n\n        .gz格式压缩:gzip -r 目录\n        功能描述:压缩目录下所有的子文件,但是不能压缩目录\n\n        .bz2格式压缩:bzip2 源文件\n        功能描述:压缩为.bz2格式的压缩文件,不保留原文件\n\n        .bz2格式压缩:bzip2 -k 源文件\n        功能描述:压缩为.bz2格式的压缩文件,保留原文件(bz2不能压缩目录)\n\n        .tar打包命令:tar -cvf 打包文件名 源文件\n        选项:  -c 打包\n              -v 显示过程\n              -f 指定打包后的文件名\n              -z 压缩为.tar.gz格式\n              -j 压缩为.tar.bz2格式\n\n    5.2:解压缩命令:\n        常用解压缩格式: unzip .gz .bz2 .tar.gz .tar.bz2\n        unzip 压缩文件\n        功能描述:解压缩.zip文件\n\n        .gz格式解压缩\n        gzip -d 压缩文件\n        功能描述:解压缩文件\n\n        gunzip 压缩文件\n        功能描述:解压缩文件\n\n        .bz2格式解压缩\n        bzip2 -d 压缩文件\n        功能描述:解压缩,-k保留压缩文件\n\n        bunzip2 压缩文件\n        功能描述:解压缩,-k保留压缩文件\n\n        .tar解压缩命令:tar -xvf 打包文件名 \n        选项:-x 解打包\n         -z 压缩为.tar.gz格式</code></pre>\n<p><strong>6:关机与重启命令</strong></p>\n<pre><code>6.1:shutdown命令:\nshutdown [选项] 时间\n选项: -c 取消前一个关机命令\n      -h 关机\n      -r 重启\n\n6.2:其他关机命令:\nhalt\npoweroff\ninit 0\n这三个不太安全\nC:其他重启命令\nreboot\ninit 6\ninit 后面数字的含义:\n    0:关机\n    1:单用户\n    2:不完全多用户,不含NFS服务\n    3:完全多用户\n    4:未分配\n    5:图形界面\n    6:重启\nrunlevel命令查询当前系统运行级别 结果显示的是前一个字符为原先的级别,后一个字符为当前的级别\n\nlogout 退出登陆命令</code></pre>\n<p><strong>7:其他常用命令</strong></p>\n<pre><code>7.1:挂载命令:\n    查询与自动挂载:mount\n    功能描述:查询系统中已经挂载的设备\n\n    mount -a\n    功能描述:依据配置文件/etc/fstab的内容,自动挂载\n\n    挂载命令格式:mount [-t 文件系统] [-o 特殊选项] 设备文件名 挂载点\n    选项:-t 文件系统 加入文件系统类型来指定挂载的类型,可以ext3,ext4,iso9660等文件系统\n         -o 特殊选项 可以指定挂载的额外选项\n\n    挂载光盘:第一步放入光盘,第二步建立挂载(空目录)点,mkdir /mnt/cdrom/,第三部执行挂载命令\n\n    卸载命令:umount 设备文件名或挂载点\n\n    挂载U盘:第一步查看已挂载设备名命令 fdisk -l\n          第二步执行挂载命令\n\n\n7.2:用户登陆查看命令:\n    w 用户名\n    功能描述:查看用户登陆信息\n    命令输出:USER 登陆的用户名\n         TTY 登陆终端\n         FROM 从哪个IP地址登陆\n         LOGIN@ 登录时间\n         IDLE 用户闲置时间\n         JCPU 和该终端链接的所有进程占用的时间,这个时间里不包括过去的后台作业时间,但包括当前正在运行的后台作业所占用的时间\n         PCPU 当前进程所占用的时间\n         WHAT 当前正在运行的命令        \n\n    who \n    功能描述:查看用户登陆信息\n    命令输出:用户名 登陆终端 登陆时间(登陆来源IP地址)\n\n    last \n    功能描述:查看当前登陆用户信息和过去登陆用户信息(last命令默认读取/var/log/wtmp文件数据)\n    命令输出:用户名 登陆终端 登陆时间(登陆来源IP地址) 登录时间 退出时间(在线时间)\n\n    lastlog\n    功能描述:查看所有用户的最后一次登录时间(lastlog命令默认读取/var/log/lastlog文件数据)\n    命令输出:用户名 登陆终端 登陆来源IP地址 最后一次登录时间</code></pre>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/72654901\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/72654901</a></p>"},{"title":"Java注解以及自定义注解总结","date":"2019-12-15T07:54:01.000Z","_content":"注解以及自定义注解的相关知识(代码层还带有一个自实现简单的orm demo)\n<!--more-->\n#  custom_annotations(自定义注解)\n\n## 知识点\n注解以及自定义注解的相关知识(代码层还带有一个自实现简单的orm demo)\n\n## 注解知识点\n\n### Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法(Java反射)。\n\n### java 1.5引入注解其中Java SE5内置了三种标准注解：\n\n     @Override，表示当前的方法定义将覆盖超类中的方法。\n\n     @Deprecated，使用了注解为它的元素编译器将发出警告，因为注解@Deprecated是不赞成使用的代码，被弃用的代码。\n\n     @SuppressWarnings，关闭不当编译器警告信息。\n \n\n### 元注解\n\n    \n    @Target 表示该注解可以用于什么地方，可能的ElementType参数有：\n            1.CONSTRUCTOR：构造器的声明 \n            2.FIELD：域声明（包括enum实例）\n            3.LOCAL_VARIABLE：局部变量声明 \n            4.METHOD：方法声明 \n            5.PACKAGE：包声明 \n            6.PARAMETER 参数声明 \n            7.TYPE：类、接口（包括注解类型）或enum声明 \n\n    @Retention  表示需要在什么级别保存该注解信息。可选的RetentionPolicy参数包括：\n                1.SOURCE：注解将被编译器丢弃 \n                2.CLASS：注解在class文件中可用，但会被VM丢弃 \n                3.RUNTIME：VM将在运行期间保留注解，因此可以通过反射机制读取注解的信息\n    \n    @Document 将注解包含在Javadoc中 \n    \n    @Inherited 允许子类继承父类中的注解 \n\n\n### 自定义注解\n![自定义注解语法](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDMyNi8xNjA0MjdfMWZkOWFjYzJfMTYzNTc3NC5qcGVn?x-oss-process=image/format,png)\n## 自定义注解项目github地址:[https://github.com/ArnoldShu/custom_annotations](https://github.com/ArnoldShu/custom_annotations)\n## 自定义注解项目gitee地址:[https://gitee.com/ArnoldSu/custom_annotations](https://gitee.com/ArnoldSu/custom_annotations)\n[本文CSDN链接地址](https://blog.csdn.net/qq_20340547/article/details/103549373)","source":"_posts/summary/2019-12-15-15.md","raw":"---\ntitle: Java注解以及自定义注解总结\ndate: 2019-12-15 15:54:01\ntags: [java, annotations]\ncategories: 日常总结\n---\n注解以及自定义注解的相关知识(代码层还带有一个自实现简单的orm demo)\n<!--more-->\n#  custom_annotations(自定义注解)\n\n## 知识点\n注解以及自定义注解的相关知识(代码层还带有一个自实现简单的orm demo)\n\n## 注解知识点\n\n### Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法(Java反射)。\n\n### java 1.5引入注解其中Java SE5内置了三种标准注解：\n\n     @Override，表示当前的方法定义将覆盖超类中的方法。\n\n     @Deprecated，使用了注解为它的元素编译器将发出警告，因为注解@Deprecated是不赞成使用的代码，被弃用的代码。\n\n     @SuppressWarnings，关闭不当编译器警告信息。\n \n\n### 元注解\n\n    \n    @Target 表示该注解可以用于什么地方，可能的ElementType参数有：\n            1.CONSTRUCTOR：构造器的声明 \n            2.FIELD：域声明（包括enum实例）\n            3.LOCAL_VARIABLE：局部变量声明 \n            4.METHOD：方法声明 \n            5.PACKAGE：包声明 \n            6.PARAMETER 参数声明 \n            7.TYPE：类、接口（包括注解类型）或enum声明 \n\n    @Retention  表示需要在什么级别保存该注解信息。可选的RetentionPolicy参数包括：\n                1.SOURCE：注解将被编译器丢弃 \n                2.CLASS：注解在class文件中可用，但会被VM丢弃 \n                3.RUNTIME：VM将在运行期间保留注解，因此可以通过反射机制读取注解的信息\n    \n    @Document 将注解包含在Javadoc中 \n    \n    @Inherited 允许子类继承父类中的注解 \n\n\n### 自定义注解\n![自定义注解语法](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDMyNi8xNjA0MjdfMWZkOWFjYzJfMTYzNTc3NC5qcGVn?x-oss-process=image/format,png)\n## 自定义注解项目github地址:[https://github.com/ArnoldShu/custom_annotations](https://github.com/ArnoldShu/custom_annotations)\n## 自定义注解项目gitee地址:[https://gitee.com/ArnoldSu/custom_annotations](https://gitee.com/ArnoldSu/custom_annotations)\n[本文CSDN链接地址](https://blog.csdn.net/qq_20340547/article/details/103549373)","slug":"summary/2019-12-15-15","published":1,"updated":"2019-12-15T07:59:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue22000fbcvz4hs22rt5","content":"<p>注解以及自定义注解的相关知识(代码层还带有一个自实现简单的orm demo)</p>\n<a id=\"more\"></a>\n<h1 id=\"custom-annotations-自定义注解\"><a href=\"#custom-annotations-自定义注解\" class=\"headerlink\" title=\"custom_annotations(自定义注解)\"></a>custom_annotations(自定义注解)</h1><h2 id=\"知识点\"><a href=\"#知识点\" class=\"headerlink\" title=\"知识点\"></a>知识点</h2><p>注解以及自定义注解的相关知识(代码层还带有一个自实现简单的orm demo)</p>\n<h2 id=\"注解知识点\"><a href=\"#注解知识点\" class=\"headerlink\" title=\"注解知识点\"></a>注解知识点</h2><h3 id=\"Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法-Java反射-。\"><a href=\"#Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法-Java反射-。\" class=\"headerlink\" title=\"Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法(Java反射)。\"></a>Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法(Java反射)。</h3><h3 id=\"java-1-5引入注解其中Java-SE5内置了三种标准注解：\"><a href=\"#java-1-5引入注解其中Java-SE5内置了三种标准注解：\" class=\"headerlink\" title=\"java 1.5引入注解其中Java SE5内置了三种标准注解：\"></a>java 1.5引入注解其中Java SE5内置了三种标准注解：</h3><pre><code> @Override，表示当前的方法定义将覆盖超类中的方法。\n\n @Deprecated，使用了注解为它的元素编译器将发出警告，因为注解@Deprecated是不赞成使用的代码，被弃用的代码。\n\n @SuppressWarnings，关闭不当编译器警告信息。</code></pre>\n<h3 id=\"元注解\"><a href=\"#元注解\" class=\"headerlink\" title=\"元注解\"></a>元注解</h3><pre><code>@Target 表示该注解可以用于什么地方，可能的ElementType参数有：\n        1.CONSTRUCTOR：构造器的声明 \n        2.FIELD：域声明（包括enum实例）\n        3.LOCAL_VARIABLE：局部变量声明 \n        4.METHOD：方法声明 \n        5.PACKAGE：包声明 \n        6.PARAMETER 参数声明 \n        7.TYPE：类、接口（包括注解类型）或enum声明 \n\n@Retention  表示需要在什么级别保存该注解信息。可选的RetentionPolicy参数包括：\n            1.SOURCE：注解将被编译器丢弃 \n            2.CLASS：注解在class文件中可用，但会被VM丢弃 \n            3.RUNTIME：VM将在运行期间保留注解，因此可以通过反射机制读取注解的信息\n\n@Document 将注解包含在Javadoc中 \n\n@Inherited 允许子类继承父类中的注解 </code></pre>\n<h3 id=\"自定义注解\"><a href=\"#自定义注解\" class=\"headerlink\" title=\"自定义注解\"></a>自定义注解</h3><p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDMyNi8xNjA0MjdfMWZkOWFjYzJfMTYzNTc3NC5qcGVn?x-oss-process=image/format,png\" alt=\"自定义注解语法\"></p>\n<h2 id=\"自定义注解项目github地址-https-github-com-ArnoldShu-custom-annotations\"><a href=\"#自定义注解项目github地址-https-github-com-ArnoldShu-custom-annotations\" class=\"headerlink\" title=\"自定义注解项目github地址:https://github.com/ArnoldShu/custom_annotations\"></a>自定义注解项目github地址:<a href=\"https://github.com/ArnoldShu/custom_annotations\">https://github.com/ArnoldShu/custom_annotations</a></h2><h2 id=\"自定义注解项目gitee地址-https-gitee-com-ArnoldSu-custom-annotations\"><a href=\"#自定义注解项目gitee地址-https-gitee-com-ArnoldSu-custom-annotations\" class=\"headerlink\" title=\"自定义注解项目gitee地址:https://gitee.com/ArnoldSu/custom_annotations\"></a>自定义注解项目gitee地址:<a href=\"https://gitee.com/ArnoldSu/custom_annotations\">https://gitee.com/ArnoldSu/custom_annotations</a></h2><p><a href=\"https://blog.csdn.net/qq_20340547/article/details/103549373\">本文CSDN链接地址</a></p>\n","site":{"data":{}},"excerpt":"<p>注解以及自定义注解的相关知识(代码层还带有一个自实现简单的orm demo)</p>","more":"<h1 id=\"custom-annotations-自定义注解\"><a href=\"#custom-annotations-自定义注解\" class=\"headerlink\" title=\"custom_annotations(自定义注解)\"></a>custom_annotations(自定义注解)</h1><h2 id=\"知识点\"><a href=\"#知识点\" class=\"headerlink\" title=\"知识点\"></a>知识点</h2><p>注解以及自定义注解的相关知识(代码层还带有一个自实现简单的orm demo)</p>\n<h2 id=\"注解知识点\"><a href=\"#注解知识点\" class=\"headerlink\" title=\"注解知识点\"></a>注解知识点</h2><h3 id=\"Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法-Java反射-。\"><a href=\"#Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法-Java反射-。\" class=\"headerlink\" title=\"Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法(Java反射)。\"></a>Java提供了一种原程序中的元素关联任何信息和任何元数据的途径和方法(Java反射)。</h3><h3 id=\"java-1-5引入注解其中Java-SE5内置了三种标准注解：\"><a href=\"#java-1-5引入注解其中Java-SE5内置了三种标准注解：\" class=\"headerlink\" title=\"java 1.5引入注解其中Java SE5内置了三种标准注解：\"></a>java 1.5引入注解其中Java SE5内置了三种标准注解：</h3><pre><code> @Override，表示当前的方法定义将覆盖超类中的方法。\n\n @Deprecated，使用了注解为它的元素编译器将发出警告，因为注解@Deprecated是不赞成使用的代码，被弃用的代码。\n\n @SuppressWarnings，关闭不当编译器警告信息。</code></pre>\n<h3 id=\"元注解\"><a href=\"#元注解\" class=\"headerlink\" title=\"元注解\"></a>元注解</h3><pre><code>@Target 表示该注解可以用于什么地方，可能的ElementType参数有：\n        1.CONSTRUCTOR：构造器的声明 \n        2.FIELD：域声明（包括enum实例）\n        3.LOCAL_VARIABLE：局部变量声明 \n        4.METHOD：方法声明 \n        5.PACKAGE：包声明 \n        6.PARAMETER 参数声明 \n        7.TYPE：类、接口（包括注解类型）或enum声明 \n\n@Retention  表示需要在什么级别保存该注解信息。可选的RetentionPolicy参数包括：\n            1.SOURCE：注解将被编译器丢弃 \n            2.CLASS：注解在class文件中可用，但会被VM丢弃 \n            3.RUNTIME：VM将在运行期间保留注解，因此可以通过反射机制读取注解的信息\n\n@Document 将注解包含在Javadoc中 \n\n@Inherited 允许子类继承父类中的注解 </code></pre>\n<h3 id=\"自定义注解\"><a href=\"#自定义注解\" class=\"headerlink\" title=\"自定义注解\"></a>自定义注解</h3><p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDMyNi8xNjA0MjdfMWZkOWFjYzJfMTYzNTc3NC5qcGVn?x-oss-process=image/format,png\" alt=\"自定义注解语法\"></p>\n<h2 id=\"自定义注解项目github地址-https-github-com-ArnoldShu-custom-annotations\"><a href=\"#自定义注解项目github地址-https-github-com-ArnoldShu-custom-annotations\" class=\"headerlink\" title=\"自定义注解项目github地址:https://github.com/ArnoldShu/custom_annotations\"></a>自定义注解项目github地址:<a href=\"https://github.com/ArnoldShu/custom_annotations\">https://github.com/ArnoldShu/custom_annotations</a></h2><h2 id=\"自定义注解项目gitee地址-https-gitee-com-ArnoldSu-custom-annotations\"><a href=\"#自定义注解项目gitee地址-https-gitee-com-ArnoldSu-custom-annotations\" class=\"headerlink\" title=\"自定义注解项目gitee地址:https://gitee.com/ArnoldSu/custom_annotations\"></a>自定义注解项目gitee地址:<a href=\"https://gitee.com/ArnoldSu/custom_annotations\">https://gitee.com/ArnoldSu/custom_annotations</a></h2><p><a href=\"https://blog.csdn.net/qq_20340547/article/details/103549373\">本文CSDN链接地址</a></p>"},{"title":"Zookeeper学习记录及简单上手代码展示","date":"2020-02-29T17:04:42.000Z","_content":"zookeeper:定义是一个开源的分布式,为分布式应用提供协调服务的Apache的项目\n<!--more-->\n# zookeeper\nzookeeper:定义是一个开源的分布式,为分布式应用提供协调服务的Apache的项目\nzookeeper是一个基于观察者模式设计的**分布式服务管理框架**,负责存储和管理大家的关心的数据,然后接受观察者注册,一旦数据的状态发生变化,zookeeper将负责通知已经在zookeeper上注册的那些观察者做出相应的反应\t\n**zookeep= 文件系统+通知机制** \n\t\n**特点**\t\t\n\n **1. 一个leader ,多个follower组成的集群\n 2. 集群中只要半数以上的节点存活,zookeeper集群就能正常服务\n 3. 全局数据一致,每个server保存一份相同的数据副本,client无论链接那个server,数据都是一致的\n 4. 更新请求顺序进行,来自同一个client的更新请求按其发送顺序依次执行\n 5. 数据更新原子性,要么成功要么失败\n 6. 实时性,一定时间范围内,client能读到最新数据**\n\n## zookeeper的数据结构\n\n数据模型的结构与Unix文件系统很相似,整体上可以看作是一个树,每个节点称作一个ZNode,每个ZNode默认能够存储1mb的数据,每个ZNode都可以通过其路径唯一标识\n\t\t\n**zookeeper应用场景**\n**统一命名服务:**\n分布式环境下,经常需要对应用/服务进行统一命名,便于识别(例如:ip不容易识别,域名容易记住)\n**统一配置管理:**\n分布式环境下配置文件同步非常常见(集群中所有节点的配置信息是一致的.例如Kafka集群,配置文件修改后,希望能够快速同步到各个节点,配置管理可交由zookeeper,可将配置信息写入zookeeper上的一个Znode,各个客户端服务器监听这个Znode,一旦Znode中的数据被修改,Zookeeper将通知各个客户端服务器)\n**统一集群管理:**\t\t\t\n分布式环境下,实时掌握各个节点的状态(可根据节点实时状态做出一些调整,实时监控节点状态变化,可将节点信息写入Znode,监听这个Znode可获取它的实时状态变化)\n**服务器节点动态上下线:**\n实时洞察服务器的上下线\n**软负载均衡等:**\n记录每台服务器的访问数,让访问数最少的服务器去处理最新的客户端请求\n\t\t\t\n\n## 下载地址:[http://archive.apache.org/dist/zookeeper/](http://archive.apache.org/dist/zookeeper/)\n\n\n## 本地模式安装zookeeper\n\n\t\n\n 1. 安装jdk\n 2. 下载zookeeper包到linux你指定的目录,并解压\n 3. 配置修改\n\t解压文件的conf文件夹下zoo_sample.cfg 文件修改为zoo.cfg \n\t修改zoo.cfg 修改dataDir路径(存储数据路径)\n\tzoo.cfg 配置参数\n\t\t\t\t\n\n```bash\n# The number of milliseconds of each tick 心跳包时间间隔\ntickTime=2000 \n# The number of ticks that the initial 初始化最大时延tickTime*initLimit,leader与follower超过这个时间就断掉,通讯机制\n# synchronization phase can take\ninitLimit=10 \n# The number of ticks that can pass between\n# sending a request and getting an acknowledgement 启动完成之后的最大时延tickTime*syncLimit,leader与follower超过这个时间就断掉,通讯机制\nsyncLimit=5\n# the directory where the snapshot is stored.\n# do not use /tmp for storage, /tmp here is just 存储数据的地方\n# example sakes.\ndataDir=/home/zookeeper/zkdata\n# the port at which the clients will connect 客户端端口号\nclientPort=2181\n# the maximum number of client connections.\n# increase this if you need to handle more clients 客户端最大连接数 \n#maxClientCnxns=60\n#\n# Be sure to read the maintenance section of the\n# administrator guide before turning on autopurge.\n#\n# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance\n#\n```\n\n\t\t\t\n\n## 启动zookeeper\n\nbin目录下\nzkCleanup.sh\nzkCli.cmd 客户端\nzkCli.sh 客户端\n\t回车无参启动 \n\tquit 退出客户端\n\t\nzkEnv.cmd\nzkEnv.sh\nzkServer.cmd 服务端\nzkServer.sh 服务端\n\tstart 启动\n\tstatus 状态\n\tstop 关闭\n\t\n\t\n\n## zookeeper内部原理\n\n**半数机制:集群中只要半数以上机器存活,集群可用,集群适合奇数台服务器\nserver启动没有历史数据的情况下,先自投,选举状态一直是looking,集群相互交换选举信息,所以后加的server票数更多,超过半数以上的投票作为leader ,其他为follower**\n## 节点类型\n持久(Persistent) 客户端和服务端断开后.节点不删除\n临时(Ephemeral) 客户端和服务端断开后.节点自删除\n\n## zookeeper集群搭建\n\n 1. 首先单机zookeeper装好\n 2. 集群环境善于利用xsync脚本同步文件数据\n 3. 在相应的指定目录线面创建节点信息,zkdata在节点下\t创建一个myid文件其中的就是对应相应的server唯一标识,创建后同步到进群信息中并修改成相应的机器的唯一标识\n 4. 修改zoo.cfg文件dataDir文件路径到指定目录,添加集群配置\n\t\tserver.A=B:C:D \n\t\tA对应一个服务器的你在myid里面配置的唯一标识 \tB是一个ip或者主机名  C是本服务器与集群中的leader服务器交换信息的端口 D 是集群中的leader挂掉之后,从新选举通信的端口\n\t\t**特别注意,集群检验需要把所有集群机器启动**\n\n## zookeeper shell\n\n```bash\n客户端命令\nhelp 显示所有操作命令\n\nls  显示当前znode所包含的数据内容  eg:ls /\n\nls2 / 显示当前节点节点的详细数据 eg: ls2 /\n\ncreate \n创建节点(如果不写入数据,则无法创建相应节点) eg:create /master \"master\"\n创建短暂节点 eg:create -e /master1 \"master1\"\n创建带序号的节点 eg:create -s /master3 \"master3\"\n\n\nget 获得节点的值 eg:get /master \n\n显示结构体的字段属性 \n23134234\ncZxid = 0x100000002\t\t\t创建节点的事务zxid \nctime = Wed Feb 26 23:39:12 CST 2020\t\t\tznode创建的毫秒数\nmZxid = 0x10000000e\t\t\tznode最后更新事务的zxid\nmtime = Thu Feb 27 00:25:55 CST 2020 最后修改的毫秒数 \npZxid = 0x100000002\t\t\t最后更新子节点的zxid\ncversion = 0\t\t\tznode子节点的变化号,znode子节点的修改次数\ndataVersion = 2\t\t\tznode数据变化号\naclVersion = 0\t\t\tznode访问控制列表的变化号\nephemeralOwner = 0x0\t\t\t如果是临时节点,这是znode拥有者得session_id,如果不是则是0\ndataLength = 8\t\t\t\tznode数据长度 \nnumChildren = 0\t\t\t\tznode子节点的数量\n\n\nset 修改节点的值 eg:set /master1 \"master111111\"\n\nwatch 监听节点值变化 eg:get /master watch  一次有效\n\ndelete \n删除节点 eg:delete /master\n递归删除节点 eg:rmr /master \n\nstat 查看节点状态 stat /master \n\nquit 退出客户端\n```\n## zookeeper监听器原理\n\n **1. 创建一个main线程\n 2. 其中在main线程中创建一个zookeeper的客户端,同时这个客户端拥有两个线程,一个负责网络通信(connection)一个负责监听(listener)\n 3. 通过connection将注册的监听事件发送给zookeeper\n 4. 在zookeeper的注册监听器列表将注册的监听事件添加到列表中\n 5. zookeeper监听到数据或者路径变化,就会将这个消息告诉给listener线程\n 6. listener就会调用相应的process()方法处理**\n\n## 常见的监听\n\n监听节点的数据变化\n**get path [watch]**\n\t\n监听子节点的增减变化\n**ls path [watch]**\n\t\n\t\n\n## 面试主要考察点\n**zookeeper的选举机制,半数投票机制\nzookeeper的监听原理\nzookeeper的部署方式(单机,集群,伪集群),集群中的角色(leader,follower),集群至少三台服务器\nzookeeper的常用命令**\n## 上手代码地址:[https://gitee.com/ArnoldSu/zookeeper](https://gitee.com/ArnoldSu/zookeeper)","source":"_posts/summary/2020-03-07.md","raw":"---\ntitle: Zookeeper学习记录及简单上手代码展示\ndate: 2020-03-01 01:04:42\ntags: [大数据, zookeeper]\ncategories: 日常总结\n---\nzookeeper:定义是一个开源的分布式,为分布式应用提供协调服务的Apache的项目\n<!--more-->\n# zookeeper\nzookeeper:定义是一个开源的分布式,为分布式应用提供协调服务的Apache的项目\nzookeeper是一个基于观察者模式设计的**分布式服务管理框架**,负责存储和管理大家的关心的数据,然后接受观察者注册,一旦数据的状态发生变化,zookeeper将负责通知已经在zookeeper上注册的那些观察者做出相应的反应\t\n**zookeep= 文件系统+通知机制** \n\t\n**特点**\t\t\n\n **1. 一个leader ,多个follower组成的集群\n 2. 集群中只要半数以上的节点存活,zookeeper集群就能正常服务\n 3. 全局数据一致,每个server保存一份相同的数据副本,client无论链接那个server,数据都是一致的\n 4. 更新请求顺序进行,来自同一个client的更新请求按其发送顺序依次执行\n 5. 数据更新原子性,要么成功要么失败\n 6. 实时性,一定时间范围内,client能读到最新数据**\n\n## zookeeper的数据结构\n\n数据模型的结构与Unix文件系统很相似,整体上可以看作是一个树,每个节点称作一个ZNode,每个ZNode默认能够存储1mb的数据,每个ZNode都可以通过其路径唯一标识\n\t\t\n**zookeeper应用场景**\n**统一命名服务:**\n分布式环境下,经常需要对应用/服务进行统一命名,便于识别(例如:ip不容易识别,域名容易记住)\n**统一配置管理:**\n分布式环境下配置文件同步非常常见(集群中所有节点的配置信息是一致的.例如Kafka集群,配置文件修改后,希望能够快速同步到各个节点,配置管理可交由zookeeper,可将配置信息写入zookeeper上的一个Znode,各个客户端服务器监听这个Znode,一旦Znode中的数据被修改,Zookeeper将通知各个客户端服务器)\n**统一集群管理:**\t\t\t\n分布式环境下,实时掌握各个节点的状态(可根据节点实时状态做出一些调整,实时监控节点状态变化,可将节点信息写入Znode,监听这个Znode可获取它的实时状态变化)\n**服务器节点动态上下线:**\n实时洞察服务器的上下线\n**软负载均衡等:**\n记录每台服务器的访问数,让访问数最少的服务器去处理最新的客户端请求\n\t\t\t\n\n## 下载地址:[http://archive.apache.org/dist/zookeeper/](http://archive.apache.org/dist/zookeeper/)\n\n\n## 本地模式安装zookeeper\n\n\t\n\n 1. 安装jdk\n 2. 下载zookeeper包到linux你指定的目录,并解压\n 3. 配置修改\n\t解压文件的conf文件夹下zoo_sample.cfg 文件修改为zoo.cfg \n\t修改zoo.cfg 修改dataDir路径(存储数据路径)\n\tzoo.cfg 配置参数\n\t\t\t\t\n\n```bash\n# The number of milliseconds of each tick 心跳包时间间隔\ntickTime=2000 \n# The number of ticks that the initial 初始化最大时延tickTime*initLimit,leader与follower超过这个时间就断掉,通讯机制\n# synchronization phase can take\ninitLimit=10 \n# The number of ticks that can pass between\n# sending a request and getting an acknowledgement 启动完成之后的最大时延tickTime*syncLimit,leader与follower超过这个时间就断掉,通讯机制\nsyncLimit=5\n# the directory where the snapshot is stored.\n# do not use /tmp for storage, /tmp here is just 存储数据的地方\n# example sakes.\ndataDir=/home/zookeeper/zkdata\n# the port at which the clients will connect 客户端端口号\nclientPort=2181\n# the maximum number of client connections.\n# increase this if you need to handle more clients 客户端最大连接数 \n#maxClientCnxns=60\n#\n# Be sure to read the maintenance section of the\n# administrator guide before turning on autopurge.\n#\n# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance\n#\n```\n\n\t\t\t\n\n## 启动zookeeper\n\nbin目录下\nzkCleanup.sh\nzkCli.cmd 客户端\nzkCli.sh 客户端\n\t回车无参启动 \n\tquit 退出客户端\n\t\nzkEnv.cmd\nzkEnv.sh\nzkServer.cmd 服务端\nzkServer.sh 服务端\n\tstart 启动\n\tstatus 状态\n\tstop 关闭\n\t\n\t\n\n## zookeeper内部原理\n\n**半数机制:集群中只要半数以上机器存活,集群可用,集群适合奇数台服务器\nserver启动没有历史数据的情况下,先自投,选举状态一直是looking,集群相互交换选举信息,所以后加的server票数更多,超过半数以上的投票作为leader ,其他为follower**\n## 节点类型\n持久(Persistent) 客户端和服务端断开后.节点不删除\n临时(Ephemeral) 客户端和服务端断开后.节点自删除\n\n## zookeeper集群搭建\n\n 1. 首先单机zookeeper装好\n 2. 集群环境善于利用xsync脚本同步文件数据\n 3. 在相应的指定目录线面创建节点信息,zkdata在节点下\t创建一个myid文件其中的就是对应相应的server唯一标识,创建后同步到进群信息中并修改成相应的机器的唯一标识\n 4. 修改zoo.cfg文件dataDir文件路径到指定目录,添加集群配置\n\t\tserver.A=B:C:D \n\t\tA对应一个服务器的你在myid里面配置的唯一标识 \tB是一个ip或者主机名  C是本服务器与集群中的leader服务器交换信息的端口 D 是集群中的leader挂掉之后,从新选举通信的端口\n\t\t**特别注意,集群检验需要把所有集群机器启动**\n\n## zookeeper shell\n\n```bash\n客户端命令\nhelp 显示所有操作命令\n\nls  显示当前znode所包含的数据内容  eg:ls /\n\nls2 / 显示当前节点节点的详细数据 eg: ls2 /\n\ncreate \n创建节点(如果不写入数据,则无法创建相应节点) eg:create /master \"master\"\n创建短暂节点 eg:create -e /master1 \"master1\"\n创建带序号的节点 eg:create -s /master3 \"master3\"\n\n\nget 获得节点的值 eg:get /master \n\n显示结构体的字段属性 \n23134234\ncZxid = 0x100000002\t\t\t创建节点的事务zxid \nctime = Wed Feb 26 23:39:12 CST 2020\t\t\tznode创建的毫秒数\nmZxid = 0x10000000e\t\t\tznode最后更新事务的zxid\nmtime = Thu Feb 27 00:25:55 CST 2020 最后修改的毫秒数 \npZxid = 0x100000002\t\t\t最后更新子节点的zxid\ncversion = 0\t\t\tznode子节点的变化号,znode子节点的修改次数\ndataVersion = 2\t\t\tznode数据变化号\naclVersion = 0\t\t\tznode访问控制列表的变化号\nephemeralOwner = 0x0\t\t\t如果是临时节点,这是znode拥有者得session_id,如果不是则是0\ndataLength = 8\t\t\t\tznode数据长度 \nnumChildren = 0\t\t\t\tznode子节点的数量\n\n\nset 修改节点的值 eg:set /master1 \"master111111\"\n\nwatch 监听节点值变化 eg:get /master watch  一次有效\n\ndelete \n删除节点 eg:delete /master\n递归删除节点 eg:rmr /master \n\nstat 查看节点状态 stat /master \n\nquit 退出客户端\n```\n## zookeeper监听器原理\n\n **1. 创建一个main线程\n 2. 其中在main线程中创建一个zookeeper的客户端,同时这个客户端拥有两个线程,一个负责网络通信(connection)一个负责监听(listener)\n 3. 通过connection将注册的监听事件发送给zookeeper\n 4. 在zookeeper的注册监听器列表将注册的监听事件添加到列表中\n 5. zookeeper监听到数据或者路径变化,就会将这个消息告诉给listener线程\n 6. listener就会调用相应的process()方法处理**\n\n## 常见的监听\n\n监听节点的数据变化\n**get path [watch]**\n\t\n监听子节点的增减变化\n**ls path [watch]**\n\t\n\t\n\n## 面试主要考察点\n**zookeeper的选举机制,半数投票机制\nzookeeper的监听原理\nzookeeper的部署方式(单机,集群,伪集群),集群中的角色(leader,follower),集群至少三台服务器\nzookeeper的常用命令**\n## 上手代码地址:[https://gitee.com/ArnoldSu/zookeeper](https://gitee.com/ArnoldSu/zookeeper)","slug":"summary/2020-03-07","published":1,"updated":"2020-03-08T09:31:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue28000hbcvz6rhk1js3","content":"<p>zookeeper:定义是一个开源的分布式,为分布式应用提供协调服务的Apache的项目</p>\n<a id=\"more\"></a>\n<h1 id=\"zookeeper\"><a href=\"#zookeeper\" class=\"headerlink\" title=\"zookeeper\"></a>zookeeper</h1><p>zookeeper:定义是一个开源的分布式,为分布式应用提供协调服务的Apache的项目<br>zookeeper是一个基于观察者模式设计的<strong>分布式服务管理框架</strong>,负责存储和管理大家的关心的数据,然后接受观察者注册,一旦数据的状态发生变化,zookeeper将负责通知已经在zookeeper上注册的那些观察者做出相应的反应<br><strong>zookeep= 文件系统+通知机制</strong> </p>\n<p><strong>特点</strong>        </p>\n<p> <strong>1. 一个leader ,多个follower组成的集群<br> 2. 集群中只要半数以上的节点存活,zookeeper集群就能正常服务<br> 3. 全局数据一致,每个server保存一份相同的数据副本,client无论链接那个server,数据都是一致的<br> 4. 更新请求顺序进行,来自同一个client的更新请求按其发送顺序依次执行<br> 5. 数据更新原子性,要么成功要么失败<br> 6. 实时性,一定时间范围内,client能读到最新数据</strong></p>\n<h2 id=\"zookeeper的数据结构\"><a href=\"#zookeeper的数据结构\" class=\"headerlink\" title=\"zookeeper的数据结构\"></a>zookeeper的数据结构</h2><p>数据模型的结构与Unix文件系统很相似,整体上可以看作是一个树,每个节点称作一个ZNode,每个ZNode默认能够存储1mb的数据,每个ZNode都可以通过其路径唯一标识</p>\n<p><strong>zookeeper应用场景</strong><br><strong>统一命名服务:</strong><br>分布式环境下,经常需要对应用/服务进行统一命名,便于识别(例如:ip不容易识别,域名容易记住)<br><strong>统一配置管理:</strong><br>分布式环境下配置文件同步非常常见(集群中所有节点的配置信息是一致的.例如Kafka集群,配置文件修改后,希望能够快速同步到各个节点,配置管理可交由zookeeper,可将配置信息写入zookeeper上的一个Znode,各个客户端服务器监听这个Znode,一旦Znode中的数据被修改,Zookeeper将通知各个客户端服务器)<br><strong>统一集群管理:</strong><br>分布式环境下,实时掌握各个节点的状态(可根据节点实时状态做出一些调整,实时监控节点状态变化,可将节点信息写入Znode,监听这个Znode可获取它的实时状态变化)<br><strong>服务器节点动态上下线:</strong><br>实时洞察服务器的上下线<br><strong>软负载均衡等:</strong><br>记录每台服务器的访问数,让访问数最少的服务器去处理最新的客户端请求</p>\n<h2 id=\"下载地址-http-archive-apache-org-dist-zookeeper\"><a href=\"#下载地址-http-archive-apache-org-dist-zookeeper\" class=\"headerlink\" title=\"下载地址:http://archive.apache.org/dist/zookeeper/\"></a>下载地址:<a href=\"http://archive.apache.org/dist/zookeeper/\">http://archive.apache.org/dist/zookeeper/</a></h2><h2 id=\"本地模式安装zookeeper\"><a href=\"#本地模式安装zookeeper\" class=\"headerlink\" title=\"本地模式安装zookeeper\"></a>本地模式安装zookeeper</h2><ol>\n<li>安装jdk</li>\n<li>下载zookeeper包到linux你指定的目录,并解压</li>\n<li>配置修改<br>解压文件的conf文件夹下zoo_sample.cfg 文件修改为zoo.cfg<br>修改zoo.cfg 修改dataDir路径(存储数据路径)<br>zoo.cfg 配置参数</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># The number of milliseconds of each tick 心跳包时间间隔</span></span><br><span class=\"line\">tickTime=2000 </span><br><span class=\"line\"><span class=\"comment\"># The number of ticks that the initial 初始化最大时延tickTime*initLimit,leader与follower超过这个时间就断掉,通讯机制</span></span><br><span class=\"line\"><span class=\"comment\"># synchronization phase can take</span></span><br><span class=\"line\">initLimit=10 </span><br><span class=\"line\"><span class=\"comment\"># The number of ticks that can pass between</span></span><br><span class=\"line\"><span class=\"comment\"># sending a request and getting an acknowledgement 启动完成之后的最大时延tickTime*syncLimit,leader与follower超过这个时间就断掉,通讯机制</span></span><br><span class=\"line\">syncLimit=5</span><br><span class=\"line\"><span class=\"comment\"># the directory where the snapshot is stored.</span></span><br><span class=\"line\"><span class=\"comment\"># do not use /tmp for storage, /tmp here is just 存储数据的地方</span></span><br><span class=\"line\"><span class=\"comment\"># example sakes.</span></span><br><span class=\"line\">dataDir=/home/zookeeper/zkdata</span><br><span class=\"line\"><span class=\"comment\"># the port at which the clients will connect 客户端端口号</span></span><br><span class=\"line\">clientPort=2181</span><br><span class=\"line\"><span class=\"comment\"># the maximum number of client connections.</span></span><br><span class=\"line\"><span class=\"comment\"># increase this if you need to handle more clients 客户端最大连接数 </span></span><br><span class=\"line\"><span class=\"comment\">#maxClientCnxns=60</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Be sure to read the maintenance section of the</span></span><br><span class=\"line\"><span class=\"comment\"># administrator guide before turning on autopurge.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"启动zookeeper\"><a href=\"#启动zookeeper\" class=\"headerlink\" title=\"启动zookeeper\"></a>启动zookeeper</h2><p>bin目录下<br>zkCleanup.sh<br>zkCli.cmd 客户端<br>zkCli.sh 客户端<br>    回车无参启动<br>    quit 退出客户端</p>\n<p>zkEnv.cmd<br>zkEnv.sh<br>zkServer.cmd 服务端<br>zkServer.sh 服务端<br>    start 启动<br>    status 状态<br>    stop 关闭</p>\n<h2 id=\"zookeeper内部原理\"><a href=\"#zookeeper内部原理\" class=\"headerlink\" title=\"zookeeper内部原理\"></a>zookeeper内部原理</h2><p><strong>半数机制:集群中只要半数以上机器存活,集群可用,集群适合奇数台服务器<br>server启动没有历史数据的情况下,先自投,选举状态一直是looking,集群相互交换选举信息,所以后加的server票数更多,超过半数以上的投票作为leader ,其他为follower</strong></p>\n<h2 id=\"节点类型\"><a href=\"#节点类型\" class=\"headerlink\" title=\"节点类型\"></a>节点类型</h2><p>持久(Persistent) 客户端和服务端断开后.节点不删除<br>临时(Ephemeral) 客户端和服务端断开后.节点自删除</p>\n<h2 id=\"zookeeper集群搭建\"><a href=\"#zookeeper集群搭建\" class=\"headerlink\" title=\"zookeeper集群搭建\"></a>zookeeper集群搭建</h2><ol>\n<li>首先单机zookeeper装好</li>\n<li>集群环境善于利用xsync脚本同步文件数据</li>\n<li>在相应的指定目录线面创建节点信息,zkdata在节点下    创建一个myid文件其中的就是对应相应的server唯一标识,创建后同步到进群信息中并修改成相应的机器的唯一标识</li>\n<li>修改zoo.cfg文件dataDir文件路径到指定目录,添加集群配置<pre><code>server.A=B:C:D \nA对应一个服务器的你在myid里面配置的唯一标识     B是一个ip或者主机名  C是本服务器与集群中的leader服务器交换信息的端口 D 是集群中的leader挂掉之后,从新选举通信的端口\n**特别注意,集群检验需要把所有集群机器启动**</code></pre>\n</li>\n</ol>\n<h2 id=\"zookeeper-shell\"><a href=\"#zookeeper-shell\" class=\"headerlink\" title=\"zookeeper shell\"></a>zookeeper shell</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">客户端命令</span><br><span class=\"line\"><span class=\"built_in\">help</span> 显示所有操作命令</span><br><span class=\"line\"></span><br><span class=\"line\">ls  显示当前znode所包含的数据内容  eg:ls /</span><br><span class=\"line\"></span><br><span class=\"line\">ls2 / 显示当前节点节点的详细数据 eg: ls2 /</span><br><span class=\"line\"></span><br><span class=\"line\">create </span><br><span class=\"line\">创建节点(如果不写入数据,则无法创建相应节点) eg:create /master <span class=\"string\">&quot;master&quot;</span></span><br><span class=\"line\">创建短暂节点 eg:create -e /master1 <span class=\"string\">&quot;master1&quot;</span></span><br><span class=\"line\">创建带序号的节点 eg:create -s /master3 <span class=\"string\">&quot;master3&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">get 获得节点的值 eg:get /master </span><br><span class=\"line\"></span><br><span class=\"line\">显示结构体的字段属性 </span><br><span class=\"line\">23134234</span><br><span class=\"line\">cZxid = 0x100000002\t\t\t创建节点的事务zxid </span><br><span class=\"line\">ctime = Wed Feb 26 23:39:12 CST 2020\t\t\tznode创建的毫秒数</span><br><span class=\"line\">mZxid = 0x10000000e\t\t\tznode最后更新事务的zxid</span><br><span class=\"line\">mtime = Thu Feb 27 00:25:55 CST 2020 最后修改的毫秒数 </span><br><span class=\"line\">pZxid = 0x100000002\t\t\t最后更新子节点的zxid</span><br><span class=\"line\">cversion = 0\t\t\tznode子节点的变化号,znode子节点的修改次数</span><br><span class=\"line\">dataVersion = 2\t\t\tznode数据变化号</span><br><span class=\"line\">aclVersion = 0\t\t\tznode访问控制列表的变化号</span><br><span class=\"line\">ephemeralOwner = 0x0\t\t\t如果是临时节点,这是znode拥有者得session_id,如果不是则是0</span><br><span class=\"line\">dataLength = 8\t\t\t\tznode数据长度 </span><br><span class=\"line\">numChildren = 0\t\t\t\tznode子节点的数量</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">set</span> 修改节点的值 eg:<span class=\"built_in\">set</span> /master1 <span class=\"string\">&quot;master111111&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">watch 监听节点值变化 eg:get /master watch  一次有效</span><br><span class=\"line\"></span><br><span class=\"line\">delete </span><br><span class=\"line\">删除节点 eg:delete /master</span><br><span class=\"line\">递归删除节点 eg:rmr /master </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">stat</span> 查看节点状态 <span class=\"built_in\">stat</span> /master </span><br><span class=\"line\"></span><br><span class=\"line\">quit 退出客户端</span><br></pre></td></tr></table></figure>\n<h2 id=\"zookeeper监听器原理\"><a href=\"#zookeeper监听器原理\" class=\"headerlink\" title=\"zookeeper监听器原理\"></a>zookeeper监听器原理</h2><p> <strong>1. 创建一个main线程<br> 2. 其中在main线程中创建一个zookeeper的客户端,同时这个客户端拥有两个线程,一个负责网络通信(connection)一个负责监听(listener)<br> 3. 通过connection将注册的监听事件发送给zookeeper<br> 4. 在zookeeper的注册监听器列表将注册的监听事件添加到列表中<br> 5. zookeeper监听到数据或者路径变化,就会将这个消息告诉给listener线程<br> 6. listener就会调用相应的process()方法处理</strong></p>\n<h2 id=\"常见的监听\"><a href=\"#常见的监听\" class=\"headerlink\" title=\"常见的监听\"></a>常见的监听</h2><p>监听节点的数据变化<br><strong>get path [watch]</strong></p>\n<p>监听子节点的增减变化<br><strong>ls path [watch]</strong></p>\n<h2 id=\"面试主要考察点\"><a href=\"#面试主要考察点\" class=\"headerlink\" title=\"面试主要考察点\"></a>面试主要考察点</h2><p><strong>zookeeper的选举机制,半数投票机制<br>zookeeper的监听原理<br>zookeeper的部署方式(单机,集群,伪集群),集群中的角色(leader,follower),集群至少三台服务器<br>zookeeper的常用命令</strong></p>\n<h2 id=\"上手代码地址-https-gitee-com-ArnoldSu-zookeeper\"><a href=\"#上手代码地址-https-gitee-com-ArnoldSu-zookeeper\" class=\"headerlink\" title=\"上手代码地址:https://gitee.com/ArnoldSu/zookeeper\"></a>上手代码地址:<a href=\"https://gitee.com/ArnoldSu/zookeeper\">https://gitee.com/ArnoldSu/zookeeper</a></h2>","site":{"data":{}},"excerpt":"<p>zookeeper:定义是一个开源的分布式,为分布式应用提供协调服务的Apache的项目</p>","more":"<h1 id=\"zookeeper\"><a href=\"#zookeeper\" class=\"headerlink\" title=\"zookeeper\"></a>zookeeper</h1><p>zookeeper:定义是一个开源的分布式,为分布式应用提供协调服务的Apache的项目<br>zookeeper是一个基于观察者模式设计的<strong>分布式服务管理框架</strong>,负责存储和管理大家的关心的数据,然后接受观察者注册,一旦数据的状态发生变化,zookeeper将负责通知已经在zookeeper上注册的那些观察者做出相应的反应<br><strong>zookeep= 文件系统+通知机制</strong> </p>\n<p><strong>特点</strong>        </p>\n<p> <strong>1. 一个leader ,多个follower组成的集群<br> 2. 集群中只要半数以上的节点存活,zookeeper集群就能正常服务<br> 3. 全局数据一致,每个server保存一份相同的数据副本,client无论链接那个server,数据都是一致的<br> 4. 更新请求顺序进行,来自同一个client的更新请求按其发送顺序依次执行<br> 5. 数据更新原子性,要么成功要么失败<br> 6. 实时性,一定时间范围内,client能读到最新数据</strong></p>\n<h2 id=\"zookeeper的数据结构\"><a href=\"#zookeeper的数据结构\" class=\"headerlink\" title=\"zookeeper的数据结构\"></a>zookeeper的数据结构</h2><p>数据模型的结构与Unix文件系统很相似,整体上可以看作是一个树,每个节点称作一个ZNode,每个ZNode默认能够存储1mb的数据,每个ZNode都可以通过其路径唯一标识</p>\n<p><strong>zookeeper应用场景</strong><br><strong>统一命名服务:</strong><br>分布式环境下,经常需要对应用/服务进行统一命名,便于识别(例如:ip不容易识别,域名容易记住)<br><strong>统一配置管理:</strong><br>分布式环境下配置文件同步非常常见(集群中所有节点的配置信息是一致的.例如Kafka集群,配置文件修改后,希望能够快速同步到各个节点,配置管理可交由zookeeper,可将配置信息写入zookeeper上的一个Znode,各个客户端服务器监听这个Znode,一旦Znode中的数据被修改,Zookeeper将通知各个客户端服务器)<br><strong>统一集群管理:</strong><br>分布式环境下,实时掌握各个节点的状态(可根据节点实时状态做出一些调整,实时监控节点状态变化,可将节点信息写入Znode,监听这个Znode可获取它的实时状态变化)<br><strong>服务器节点动态上下线:</strong><br>实时洞察服务器的上下线<br><strong>软负载均衡等:</strong><br>记录每台服务器的访问数,让访问数最少的服务器去处理最新的客户端请求</p>\n<h2 id=\"下载地址-http-archive-apache-org-dist-zookeeper\"><a href=\"#下载地址-http-archive-apache-org-dist-zookeeper\" class=\"headerlink\" title=\"下载地址:http://archive.apache.org/dist/zookeeper/\"></a>下载地址:<a href=\"http://archive.apache.org/dist/zookeeper/\">http://archive.apache.org/dist/zookeeper/</a></h2><h2 id=\"本地模式安装zookeeper\"><a href=\"#本地模式安装zookeeper\" class=\"headerlink\" title=\"本地模式安装zookeeper\"></a>本地模式安装zookeeper</h2><ol>\n<li>安装jdk</li>\n<li>下载zookeeper包到linux你指定的目录,并解压</li>\n<li>配置修改<br>解压文件的conf文件夹下zoo_sample.cfg 文件修改为zoo.cfg<br>修改zoo.cfg 修改dataDir路径(存储数据路径)<br>zoo.cfg 配置参数</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># The number of milliseconds of each tick 心跳包时间间隔</span></span><br><span class=\"line\">tickTime=2000 </span><br><span class=\"line\"><span class=\"comment\"># The number of ticks that the initial 初始化最大时延tickTime*initLimit,leader与follower超过这个时间就断掉,通讯机制</span></span><br><span class=\"line\"><span class=\"comment\"># synchronization phase can take</span></span><br><span class=\"line\">initLimit=10 </span><br><span class=\"line\"><span class=\"comment\"># The number of ticks that can pass between</span></span><br><span class=\"line\"><span class=\"comment\"># sending a request and getting an acknowledgement 启动完成之后的最大时延tickTime*syncLimit,leader与follower超过这个时间就断掉,通讯机制</span></span><br><span class=\"line\">syncLimit=5</span><br><span class=\"line\"><span class=\"comment\"># the directory where the snapshot is stored.</span></span><br><span class=\"line\"><span class=\"comment\"># do not use /tmp for storage, /tmp here is just 存储数据的地方</span></span><br><span class=\"line\"><span class=\"comment\"># example sakes.</span></span><br><span class=\"line\">dataDir=/home/zookeeper/zkdata</span><br><span class=\"line\"><span class=\"comment\"># the port at which the clients will connect 客户端端口号</span></span><br><span class=\"line\">clientPort=2181</span><br><span class=\"line\"><span class=\"comment\"># the maximum number of client connections.</span></span><br><span class=\"line\"><span class=\"comment\"># increase this if you need to handle more clients 客户端最大连接数 </span></span><br><span class=\"line\"><span class=\"comment\">#maxClientCnxns=60</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Be sure to read the maintenance section of the</span></span><br><span class=\"line\"><span class=\"comment\"># administrator guide before turning on autopurge.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"启动zookeeper\"><a href=\"#启动zookeeper\" class=\"headerlink\" title=\"启动zookeeper\"></a>启动zookeeper</h2><p>bin目录下<br>zkCleanup.sh<br>zkCli.cmd 客户端<br>zkCli.sh 客户端<br>    回车无参启动<br>    quit 退出客户端</p>\n<p>zkEnv.cmd<br>zkEnv.sh<br>zkServer.cmd 服务端<br>zkServer.sh 服务端<br>    start 启动<br>    status 状态<br>    stop 关闭</p>\n<h2 id=\"zookeeper内部原理\"><a href=\"#zookeeper内部原理\" class=\"headerlink\" title=\"zookeeper内部原理\"></a>zookeeper内部原理</h2><p><strong>半数机制:集群中只要半数以上机器存活,集群可用,集群适合奇数台服务器<br>server启动没有历史数据的情况下,先自投,选举状态一直是looking,集群相互交换选举信息,所以后加的server票数更多,超过半数以上的投票作为leader ,其他为follower</strong></p>\n<h2 id=\"节点类型\"><a href=\"#节点类型\" class=\"headerlink\" title=\"节点类型\"></a>节点类型</h2><p>持久(Persistent) 客户端和服务端断开后.节点不删除<br>临时(Ephemeral) 客户端和服务端断开后.节点自删除</p>\n<h2 id=\"zookeeper集群搭建\"><a href=\"#zookeeper集群搭建\" class=\"headerlink\" title=\"zookeeper集群搭建\"></a>zookeeper集群搭建</h2><ol>\n<li>首先单机zookeeper装好</li>\n<li>集群环境善于利用xsync脚本同步文件数据</li>\n<li>在相应的指定目录线面创建节点信息,zkdata在节点下    创建一个myid文件其中的就是对应相应的server唯一标识,创建后同步到进群信息中并修改成相应的机器的唯一标识</li>\n<li>修改zoo.cfg文件dataDir文件路径到指定目录,添加集群配置<pre><code>server.A=B:C:D \nA对应一个服务器的你在myid里面配置的唯一标识     B是一个ip或者主机名  C是本服务器与集群中的leader服务器交换信息的端口 D 是集群中的leader挂掉之后,从新选举通信的端口\n**特别注意,集群检验需要把所有集群机器启动**</code></pre>\n</li>\n</ol>\n<h2 id=\"zookeeper-shell\"><a href=\"#zookeeper-shell\" class=\"headerlink\" title=\"zookeeper shell\"></a>zookeeper shell</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">客户端命令</span><br><span class=\"line\"><span class=\"built_in\">help</span> 显示所有操作命令</span><br><span class=\"line\"></span><br><span class=\"line\">ls  显示当前znode所包含的数据内容  eg:ls /</span><br><span class=\"line\"></span><br><span class=\"line\">ls2 / 显示当前节点节点的详细数据 eg: ls2 /</span><br><span class=\"line\"></span><br><span class=\"line\">create </span><br><span class=\"line\">创建节点(如果不写入数据,则无法创建相应节点) eg:create /master <span class=\"string\">&quot;master&quot;</span></span><br><span class=\"line\">创建短暂节点 eg:create -e /master1 <span class=\"string\">&quot;master1&quot;</span></span><br><span class=\"line\">创建带序号的节点 eg:create -s /master3 <span class=\"string\">&quot;master3&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">get 获得节点的值 eg:get /master </span><br><span class=\"line\"></span><br><span class=\"line\">显示结构体的字段属性 </span><br><span class=\"line\">23134234</span><br><span class=\"line\">cZxid = 0x100000002\t\t\t创建节点的事务zxid </span><br><span class=\"line\">ctime = Wed Feb 26 23:39:12 CST 2020\t\t\tznode创建的毫秒数</span><br><span class=\"line\">mZxid = 0x10000000e\t\t\tznode最后更新事务的zxid</span><br><span class=\"line\">mtime = Thu Feb 27 00:25:55 CST 2020 最后修改的毫秒数 </span><br><span class=\"line\">pZxid = 0x100000002\t\t\t最后更新子节点的zxid</span><br><span class=\"line\">cversion = 0\t\t\tznode子节点的变化号,znode子节点的修改次数</span><br><span class=\"line\">dataVersion = 2\t\t\tznode数据变化号</span><br><span class=\"line\">aclVersion = 0\t\t\tznode访问控制列表的变化号</span><br><span class=\"line\">ephemeralOwner = 0x0\t\t\t如果是临时节点,这是znode拥有者得session_id,如果不是则是0</span><br><span class=\"line\">dataLength = 8\t\t\t\tznode数据长度 </span><br><span class=\"line\">numChildren = 0\t\t\t\tznode子节点的数量</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">set</span> 修改节点的值 eg:<span class=\"built_in\">set</span> /master1 <span class=\"string\">&quot;master111111&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">watch 监听节点值变化 eg:get /master watch  一次有效</span><br><span class=\"line\"></span><br><span class=\"line\">delete </span><br><span class=\"line\">删除节点 eg:delete /master</span><br><span class=\"line\">递归删除节点 eg:rmr /master </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">stat</span> 查看节点状态 <span class=\"built_in\">stat</span> /master </span><br><span class=\"line\"></span><br><span class=\"line\">quit 退出客户端</span><br></pre></td></tr></table></figure>\n<h2 id=\"zookeeper监听器原理\"><a href=\"#zookeeper监听器原理\" class=\"headerlink\" title=\"zookeeper监听器原理\"></a>zookeeper监听器原理</h2><p> <strong>1. 创建一个main线程<br> 2. 其中在main线程中创建一个zookeeper的客户端,同时这个客户端拥有两个线程,一个负责网络通信(connection)一个负责监听(listener)<br> 3. 通过connection将注册的监听事件发送给zookeeper<br> 4. 在zookeeper的注册监听器列表将注册的监听事件添加到列表中<br> 5. zookeeper监听到数据或者路径变化,就会将这个消息告诉给listener线程<br> 6. listener就会调用相应的process()方法处理</strong></p>\n<h2 id=\"常见的监听\"><a href=\"#常见的监听\" class=\"headerlink\" title=\"常见的监听\"></a>常见的监听</h2><p>监听节点的数据变化<br><strong>get path [watch]</strong></p>\n<p>监听子节点的增减变化<br><strong>ls path [watch]</strong></p>\n<h2 id=\"面试主要考察点\"><a href=\"#面试主要考察点\" class=\"headerlink\" title=\"面试主要考察点\"></a>面试主要考察点</h2><p><strong>zookeeper的选举机制,半数投票机制<br>zookeeper的监听原理<br>zookeeper的部署方式(单机,集群,伪集群),集群中的角色(leader,follower),集群至少三台服务器<br>zookeeper的常用命令</strong></p>\n<h2 id=\"上手代码地址-https-gitee-com-ArnoldSu-zookeeper\"><a href=\"#上手代码地址-https-gitee-com-ArnoldSu-zookeeper\" class=\"headerlink\" title=\"上手代码地址:https://gitee.com/ArnoldSu/zookeeper\"></a>上手代码地址:<a href=\"https://gitee.com/ArnoldSu/zookeeper\">https://gitee.com/ArnoldSu/zookeeper</a></h2>"},{"title":"Kafka学习记录及简单上手代码","date":"2020-03-08T09:16:35.000Z","_content":"kafka是一个开源的消息系统,由Scala语言写成,由apache基金会开发\n<!--more-->\n# kafka\n\n## 为什么需要消息队列?\n\n**解耦**:允许独立的拓展或修该双方逻辑交互过程程序,只要保证保证双方的遵守同样的接口约束\n**冗余**:保证数据多个副本不至于数据丢失以及数据重复\n**拓展性**:可添加相应的额外处理过程\n**灵活性&峰值处理能力**:突发流量访问激增,仍然能够保证程序稳定运行\n**可恢复性**:消息队列降低了进程间的耦合性,一个消息队列处理进程挂掉,加入队列的消息任然可以在系统恢复后被处理\n**顺序保证**:到部分消息队列都要保证处理消息的顺序性(kafka保证一个partition内的消息的有序性)\n**缓冲**:加快数据处理速度\n**异步通信**:减少程序等待,提高程序处理速度\n\n## kafka定义\n\nkafka是一个开源的消息系统,由Scala语言写成,由apache基金会开发\nkafka是一个分布式消息队列,kafka对消息保存时根据Topic进行归类,发送消息者称为producer,消息接收者为consumer,kafka集群中存在多个kafka实例,每个实例(server)称为broker\nkafka集群依赖zookeeper里面的meta信息\n\n## kafka的架构流程\n\n流程中的角色\n**producer消息生产者**,指消息kafka broker发送数据的客户端\n**consumer消息消费者**,向kafka broker 取数据的客户端\n**topic** 主题,可理解为一个队列\n**cocnsumer group** 消费者组,多个消费者共同消费一个topic消息\n**broker** 就是一台kafka服务器,一个集群中有多个broker,一个broker有多个topic\n**partition** 一个topic可以分为多个partition,每个partition是一个有序队列,partition中的消息都有一个有序的**id(offset)**,kafka只保证一个partition中的消息的有序性,不能保证一个topic或者多个partition中消息的有序性\n**offset** 存储文件按照offset.kafka来命名,用offset命名的好处是方便查找\n\n## kafka处理流程步奏\n\n**producer生产数据到kafuka集群,消息发送到集群中的相应的broker 的topic 以及partition中\n其中各个topic 和partition都在不同的broker中存在副本,并且各个broker存在leader,follower两种类型,kafka读写数据只存在于leader服务器上,follow只做副本以及当leader挂掉之后可做为新的leader\nconsumer消费集群中的数据,当数据量较大的时候就让多个消费者消费数据提高消费能力,就有了cocnsumer group,同一个消费者组数据共享,多个消费者消费部分数据\nzookeeper存放kafka的meta集群信息以及消费者消费队列的信息(消费偏移量offset)**\n\n## kafka下载地址:[http://kafka.apache.org/downloads](http://kafka.apache.org/downloads)\n\n## kafka集群安装\n\n 1. 下载kafka安装到指定目录,这里我放在/opt/module/kafka下,解压安装\n 2. 创建一个logs日志文件夹(因为kafka存储的日志数据可做其他用途)\n 3. 修改配置文件安装目录下的config/server.properties\n 4. 配置环境变量profile(为了在任何路径都可执行kafka命令,这一步可省略)\n\t\n\n```bash\n#kafka home \n\texport KAFKA_HOME=/opt/module/kafka\n\texport PATH=$PATH:$KAFKA_HOME/bin\n```\n\n 5. 分发安装包xsync\n 6. 启动集群bin/kafka-server-start.sh config/server.properties &\n\t后台启动不打日志,守护线程启动 nohup  bin/kafka-server-start.sh -daemons config/server.properties  &\n\t\n\n server.properties配置文件\n\n```bash\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# see kafka.server.KafkaConfig for additional details and defaults\n\n############################# Server Basics #############################\n \n# The id of the broker. This must be set to a unique integer for each broker.  服务器唯一ID \nbroker.id=0\n\n# Switch to enable topic deletion or not, default value is false \t 删除topic功能开关\n#delete.topic.enable=true\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. It will get the value returned from \n# java.net.InetAddress.getCanonicalHostName() if not configured.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Hostname and port the broker will advertise to producers and consumers. If not set, \n# it uses the value for \"listeners\" if configured.  Otherwise, it will use the value\n# returned from java.net.InetAddress.getCanonicalHostName().\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network 处理网络请求的的线程数\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O 处理磁盘io的线程数量\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server  发送套接字的缓冲区大小\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server  接收套接字的缓冲区大小\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)  请求套接字的缓冲区大小\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma seperated list of directories under which to store log files kafka运行日志存放的路径\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across  topic在当前broker上的分区个数\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.    恢复和清理data下数据的线程数量\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age    segment文件保留的最长时间,超时将删除\t\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log as long as the remaining\n# segments don't drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\nlog.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.   配置链接zookeeper集群地址\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=6000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n```\n\n## kafka命令行操作\n\n关闭集群\n\n```bash\nbin/kafka-server-stop.sh stop \n```\n\n查看当前服务中的所有topic\n\n```bash\nbin/kafka-topics.sh --zookeeper hadoop1:2181 --list\n```\n\n创建topics\n\n```bash\nbin/kafka-topics.sh --zookeeper hadoop1:2181 --create --topic hadoop1 --partitions 3 --replication-factor 3\n参数说明\n--topic 定义topic名\n--replication-factor 定义副本数\n--partitions 定义分区数\n```\n\n查看topic信息\n\n```bash\nbin/kafka-topics.sh --zookeeper hadoop1:2181 --describe --topic hadoop1\n```\n\n删除topic\n\n```bash\nbin/kafka-topics.sh --zookeeper hadoop1:2181 --delete --topic hadoop1\n```\n\n发送消息\n\n```bash\nbin/kafka-console-producer.sh --broker-list hadoop1:9092 --topic hadoop1\n```\n\n单个消费者启动\n\n```bash\nbin/kafka-console-consumer.sh --zookeeper hadoop1:2181 --from-beginning --topic hadoop1\n配置消费者组的模式(修改consumer.properties文件,group.id=test-consumer-group)\nbin/kafka-console-consumer.sh --zookeeper hadoop1:2181  --topic hadoop1 --consumer.config config/consumer.properties\nbin/kafka-console-consumer.sh --bootstrap-server hadoop1:2181  --topic hadoop1 --consumer.config config/consumer.properties\n```\n\n查看消费者组信息\n\n```bash\nbin/kafka-consumer-offset-checker.sh --zookeeper hadoop1:2181 --group kafka-group\n```\n\n副本再平衡\n\n```bash\nbin/kafka-preferred-replica-election.sh --zookeeper hadoop1:2181\n```\n\n## kafka生产过程分析\n\nproducer采用推(push)模式将消息发布到broker,每条消息都被追加(append)到分区(patition)中,属于顺序写磁盘(**顺序写磁盘效率比随机写内存高,零拷贝,kafka分段日志(segment),kafka预读(read ahead),后写(Write behind)保障kafka吞吐率**)\n\n**分区**(partition)消息发送时都被发送到一个topic,其本质就是一个目录,而topic是由一些partition logs(分区日志)组成,每个partition中俄消息都是有序的,生产的消息被不断追加到partition log 上,其中每一个消息都被赋予一个offset\n\n**分区的原因**\n方便集群拓展;\n提高并发以partition\t为单位读写\n**分区的原则**\n指定partition;\n未指定partition但指定key,通过key的value进行hash出一个partition;\npartition和key都未指定,使用轮询选出一个partition\n\n**副本(replication)**\n同一个partition可以有多个副本,如果没有副本,一旦broker宕机,其上所有partition的数据都不能被消费同时producer也不能将数据存储在其partition,引入replication,同一个partition可能会有多个副本,而这时需要在其副本中选出leader,生产者和消费者\n**只与leader交互,其他replication作为follower从leader中复制数据**\n**ack应答机制**\n**0:producer发送数据给leader,不管是否leader收到,效率最高\n1(kafka默认):producer发送数据给leader,leader存放在log之后,producer就发送新的数据,这一段时间不管follower是否向leader同步成功,数据较为安全\n-1(all):producer发送数据给leader,leader存放在log之后,等待所有follower同步成功之后,producer才能发送下一条数据,数据最安全,性能非常差**\n\n\n## kafka消费过程分析\n\n**consumer链接zookeeper获取kafka集群的相关信息(主要是消费数据的offset值保存在zookeeper,在后期版本之后offset可放在集群中不用放在zookeeper)\n消费者pull拉取kafka集群中指定的topic分区的信息消费,分批次取数据(缓冲数据多条数据),一个分区只能一个消费者消费,但是一个消费者可以消费多个分区,group consumer(消费者组)中包含的多个消费者里面的offset统一管理同组消费者成员消费\n后期添加消费者消费,集群可做再平衡,消费者组从新从zookeeper获取集群信息,再平衡在kafka集群中进行**\n\n**zookeeper存储kafka主要节点属性**\n**cluster kafka**集群信息(集群id)\n**controller** 集群控制器(leader broker作为整个集群的控制器)\n**controller_epoch** 轮值(leader竞选次数)\n**brokers** 单个服务器信息(ids,topics,seqid)\n**consumers** 消费者组信息(ids,owners)\n\n## kafka面试要点\n\n 1. kafka的吞吐量高的原因:顺写日志,零拷贝(zero-cooy),kafka分段日志(segment),kafka预读(read ahead),后写(Write behind),批处理,压缩(byte)保障kafka吞吐率\n 2. kafka的偏移量offset存放位置:早前版本zookeeper,后期版本放在cluster版本中(_consumer_offset),自定义维护offset(eg:redis里面,数据库都可以)\n 3. kafka消费方式:poll,拉取方式\n 4. 防止kafka数据丢失的的措施:同步发送数据,ack=1(all)\n 5. 重复消费:维护offset避免重复消费(低级api)\n 6. kafka元数据存放:zookeeper(/cluster,/controller,/controller_epoch,/brokers,/consumers)\n 7. kafka选举机制:/controller 不同机器同时去zookeeper注册/controller节点,先到先得,成功之后从isr列表选取leader,全挂等待副本\n 8. kafka的消费速度:增加分区和消费者,增加poll数量,增大批处理大小\n\n## 上手代码地址:[https://gitee.com/ArnoldSu/kafka](https://gitee.com/ArnoldSu/kafka)","source":"_posts/summary/2020-03-08.md","raw":"---\ntitle: Kafka学习记录及简单上手代码\ndate: 2020-03-08 17:16:35\ntags: [java, 中间件,kafka]\ncategories: 日常总结\n---\nkafka是一个开源的消息系统,由Scala语言写成,由apache基金会开发\n<!--more-->\n# kafka\n\n## 为什么需要消息队列?\n\n**解耦**:允许独立的拓展或修该双方逻辑交互过程程序,只要保证保证双方的遵守同样的接口约束\n**冗余**:保证数据多个副本不至于数据丢失以及数据重复\n**拓展性**:可添加相应的额外处理过程\n**灵活性&峰值处理能力**:突发流量访问激增,仍然能够保证程序稳定运行\n**可恢复性**:消息队列降低了进程间的耦合性,一个消息队列处理进程挂掉,加入队列的消息任然可以在系统恢复后被处理\n**顺序保证**:到部分消息队列都要保证处理消息的顺序性(kafka保证一个partition内的消息的有序性)\n**缓冲**:加快数据处理速度\n**异步通信**:减少程序等待,提高程序处理速度\n\n## kafka定义\n\nkafka是一个开源的消息系统,由Scala语言写成,由apache基金会开发\nkafka是一个分布式消息队列,kafka对消息保存时根据Topic进行归类,发送消息者称为producer,消息接收者为consumer,kafka集群中存在多个kafka实例,每个实例(server)称为broker\nkafka集群依赖zookeeper里面的meta信息\n\n## kafka的架构流程\n\n流程中的角色\n**producer消息生产者**,指消息kafka broker发送数据的客户端\n**consumer消息消费者**,向kafka broker 取数据的客户端\n**topic** 主题,可理解为一个队列\n**cocnsumer group** 消费者组,多个消费者共同消费一个topic消息\n**broker** 就是一台kafka服务器,一个集群中有多个broker,一个broker有多个topic\n**partition** 一个topic可以分为多个partition,每个partition是一个有序队列,partition中的消息都有一个有序的**id(offset)**,kafka只保证一个partition中的消息的有序性,不能保证一个topic或者多个partition中消息的有序性\n**offset** 存储文件按照offset.kafka来命名,用offset命名的好处是方便查找\n\n## kafka处理流程步奏\n\n**producer生产数据到kafuka集群,消息发送到集群中的相应的broker 的topic 以及partition中\n其中各个topic 和partition都在不同的broker中存在副本,并且各个broker存在leader,follower两种类型,kafka读写数据只存在于leader服务器上,follow只做副本以及当leader挂掉之后可做为新的leader\nconsumer消费集群中的数据,当数据量较大的时候就让多个消费者消费数据提高消费能力,就有了cocnsumer group,同一个消费者组数据共享,多个消费者消费部分数据\nzookeeper存放kafka的meta集群信息以及消费者消费队列的信息(消费偏移量offset)**\n\n## kafka下载地址:[http://kafka.apache.org/downloads](http://kafka.apache.org/downloads)\n\n## kafka集群安装\n\n 1. 下载kafka安装到指定目录,这里我放在/opt/module/kafka下,解压安装\n 2. 创建一个logs日志文件夹(因为kafka存储的日志数据可做其他用途)\n 3. 修改配置文件安装目录下的config/server.properties\n 4. 配置环境变量profile(为了在任何路径都可执行kafka命令,这一步可省略)\n\t\n\n```bash\n#kafka home \n\texport KAFKA_HOME=/opt/module/kafka\n\texport PATH=$PATH:$KAFKA_HOME/bin\n```\n\n 5. 分发安装包xsync\n 6. 启动集群bin/kafka-server-start.sh config/server.properties &\n\t后台启动不打日志,守护线程启动 nohup  bin/kafka-server-start.sh -daemons config/server.properties  &\n\t\n\n server.properties配置文件\n\n```bash\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# see kafka.server.KafkaConfig for additional details and defaults\n\n############################# Server Basics #############################\n \n# The id of the broker. This must be set to a unique integer for each broker.  服务器唯一ID \nbroker.id=0\n\n# Switch to enable topic deletion or not, default value is false \t 删除topic功能开关\n#delete.topic.enable=true\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. It will get the value returned from \n# java.net.InetAddress.getCanonicalHostName() if not configured.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Hostname and port the broker will advertise to producers and consumers. If not set, \n# it uses the value for \"listeners\" if configured.  Otherwise, it will use the value\n# returned from java.net.InetAddress.getCanonicalHostName().\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network 处理网络请求的的线程数\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O 处理磁盘io的线程数量\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server  发送套接字的缓冲区大小\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server  接收套接字的缓冲区大小\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)  请求套接字的缓冲区大小\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma seperated list of directories under which to store log files kafka运行日志存放的路径\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across  topic在当前broker上的分区个数\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.    恢复和清理data下数据的线程数量\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age    segment文件保留的最长时间,超时将删除\t\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log as long as the remaining\n# segments don't drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\nlog.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.   配置链接zookeeper集群地址\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=6000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n```\n\n## kafka命令行操作\n\n关闭集群\n\n```bash\nbin/kafka-server-stop.sh stop \n```\n\n查看当前服务中的所有topic\n\n```bash\nbin/kafka-topics.sh --zookeeper hadoop1:2181 --list\n```\n\n创建topics\n\n```bash\nbin/kafka-topics.sh --zookeeper hadoop1:2181 --create --topic hadoop1 --partitions 3 --replication-factor 3\n参数说明\n--topic 定义topic名\n--replication-factor 定义副本数\n--partitions 定义分区数\n```\n\n查看topic信息\n\n```bash\nbin/kafka-topics.sh --zookeeper hadoop1:2181 --describe --topic hadoop1\n```\n\n删除topic\n\n```bash\nbin/kafka-topics.sh --zookeeper hadoop1:2181 --delete --topic hadoop1\n```\n\n发送消息\n\n```bash\nbin/kafka-console-producer.sh --broker-list hadoop1:9092 --topic hadoop1\n```\n\n单个消费者启动\n\n```bash\nbin/kafka-console-consumer.sh --zookeeper hadoop1:2181 --from-beginning --topic hadoop1\n配置消费者组的模式(修改consumer.properties文件,group.id=test-consumer-group)\nbin/kafka-console-consumer.sh --zookeeper hadoop1:2181  --topic hadoop1 --consumer.config config/consumer.properties\nbin/kafka-console-consumer.sh --bootstrap-server hadoop1:2181  --topic hadoop1 --consumer.config config/consumer.properties\n```\n\n查看消费者组信息\n\n```bash\nbin/kafka-consumer-offset-checker.sh --zookeeper hadoop1:2181 --group kafka-group\n```\n\n副本再平衡\n\n```bash\nbin/kafka-preferred-replica-election.sh --zookeeper hadoop1:2181\n```\n\n## kafka生产过程分析\n\nproducer采用推(push)模式将消息发布到broker,每条消息都被追加(append)到分区(patition)中,属于顺序写磁盘(**顺序写磁盘效率比随机写内存高,零拷贝,kafka分段日志(segment),kafka预读(read ahead),后写(Write behind)保障kafka吞吐率**)\n\n**分区**(partition)消息发送时都被发送到一个topic,其本质就是一个目录,而topic是由一些partition logs(分区日志)组成,每个partition中俄消息都是有序的,生产的消息被不断追加到partition log 上,其中每一个消息都被赋予一个offset\n\n**分区的原因**\n方便集群拓展;\n提高并发以partition\t为单位读写\n**分区的原则**\n指定partition;\n未指定partition但指定key,通过key的value进行hash出一个partition;\npartition和key都未指定,使用轮询选出一个partition\n\n**副本(replication)**\n同一个partition可以有多个副本,如果没有副本,一旦broker宕机,其上所有partition的数据都不能被消费同时producer也不能将数据存储在其partition,引入replication,同一个partition可能会有多个副本,而这时需要在其副本中选出leader,生产者和消费者\n**只与leader交互,其他replication作为follower从leader中复制数据**\n**ack应答机制**\n**0:producer发送数据给leader,不管是否leader收到,效率最高\n1(kafka默认):producer发送数据给leader,leader存放在log之后,producer就发送新的数据,这一段时间不管follower是否向leader同步成功,数据较为安全\n-1(all):producer发送数据给leader,leader存放在log之后,等待所有follower同步成功之后,producer才能发送下一条数据,数据最安全,性能非常差**\n\n\n## kafka消费过程分析\n\n**consumer链接zookeeper获取kafka集群的相关信息(主要是消费数据的offset值保存在zookeeper,在后期版本之后offset可放在集群中不用放在zookeeper)\n消费者pull拉取kafka集群中指定的topic分区的信息消费,分批次取数据(缓冲数据多条数据),一个分区只能一个消费者消费,但是一个消费者可以消费多个分区,group consumer(消费者组)中包含的多个消费者里面的offset统一管理同组消费者成员消费\n后期添加消费者消费,集群可做再平衡,消费者组从新从zookeeper获取集群信息,再平衡在kafka集群中进行**\n\n**zookeeper存储kafka主要节点属性**\n**cluster kafka**集群信息(集群id)\n**controller** 集群控制器(leader broker作为整个集群的控制器)\n**controller_epoch** 轮值(leader竞选次数)\n**brokers** 单个服务器信息(ids,topics,seqid)\n**consumers** 消费者组信息(ids,owners)\n\n## kafka面试要点\n\n 1. kafka的吞吐量高的原因:顺写日志,零拷贝(zero-cooy),kafka分段日志(segment),kafka预读(read ahead),后写(Write behind),批处理,压缩(byte)保障kafka吞吐率\n 2. kafka的偏移量offset存放位置:早前版本zookeeper,后期版本放在cluster版本中(_consumer_offset),自定义维护offset(eg:redis里面,数据库都可以)\n 3. kafka消费方式:poll,拉取方式\n 4. 防止kafka数据丢失的的措施:同步发送数据,ack=1(all)\n 5. 重复消费:维护offset避免重复消费(低级api)\n 6. kafka元数据存放:zookeeper(/cluster,/controller,/controller_epoch,/brokers,/consumers)\n 7. kafka选举机制:/controller 不同机器同时去zookeeper注册/controller节点,先到先得,成功之后从isr列表选取leader,全挂等待副本\n 8. kafka的消费速度:增加分区和消费者,增加poll数量,增大批处理大小\n\n## 上手代码地址:[https://gitee.com/ArnoldSu/kafka](https://gitee.com/ArnoldSu/kafka)","slug":"summary/2020-03-08","published":1,"updated":"2020-03-08T09:33:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue2a000mbcvzavpnc3yp","content":"<p>kafka是一个开源的消息系统,由Scala语言写成,由apache基金会开发</p>\n<a id=\"more\"></a>\n<h1 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h1><h2 id=\"为什么需要消息队列\"><a href=\"#为什么需要消息队列\" class=\"headerlink\" title=\"为什么需要消息队列?\"></a>为什么需要消息队列?</h2><p><strong>解耦</strong>:允许独立的拓展或修该双方逻辑交互过程程序,只要保证保证双方的遵守同样的接口约束<br><strong>冗余</strong>:保证数据多个副本不至于数据丢失以及数据重复<br><strong>拓展性</strong>:可添加相应的额外处理过程<br><strong>灵活性&amp;峰值处理能力</strong>:突发流量访问激增,仍然能够保证程序稳定运行<br><strong>可恢复性</strong>:消息队列降低了进程间的耦合性,一个消息队列处理进程挂掉,加入队列的消息任然可以在系统恢复后被处理<br><strong>顺序保证</strong>:到部分消息队列都要保证处理消息的顺序性(kafka保证一个partition内的消息的有序性)<br><strong>缓冲</strong>:加快数据处理速度<br><strong>异步通信</strong>:减少程序等待,提高程序处理速度</p>\n<h2 id=\"kafka定义\"><a href=\"#kafka定义\" class=\"headerlink\" title=\"kafka定义\"></a>kafka定义</h2><p>kafka是一个开源的消息系统,由Scala语言写成,由apache基金会开发<br>kafka是一个分布式消息队列,kafka对消息保存时根据Topic进行归类,发送消息者称为producer,消息接收者为consumer,kafka集群中存在多个kafka实例,每个实例(server)称为broker<br>kafka集群依赖zookeeper里面的meta信息</p>\n<h2 id=\"kafka的架构流程\"><a href=\"#kafka的架构流程\" class=\"headerlink\" title=\"kafka的架构流程\"></a>kafka的架构流程</h2><p>流程中的角色<br><strong>producer消息生产者</strong>,指消息kafka broker发送数据的客户端<br><strong>consumer消息消费者</strong>,向kafka broker 取数据的客户端<br><strong>topic</strong> 主题,可理解为一个队列<br><strong>cocnsumer group</strong> 消费者组,多个消费者共同消费一个topic消息<br><strong>broker</strong> 就是一台kafka服务器,一个集群中有多个broker,一个broker有多个topic<br><strong>partition</strong> 一个topic可以分为多个partition,每个partition是一个有序队列,partition中的消息都有一个有序的<strong>id(offset)</strong>,kafka只保证一个partition中的消息的有序性,不能保证一个topic或者多个partition中消息的有序性<br><strong>offset</strong> 存储文件按照offset.kafka来命名,用offset命名的好处是方便查找</p>\n<h2 id=\"kafka处理流程步奏\"><a href=\"#kafka处理流程步奏\" class=\"headerlink\" title=\"kafka处理流程步奏\"></a>kafka处理流程步奏</h2><p><strong>producer生产数据到kafuka集群,消息发送到集群中的相应的broker 的topic 以及partition中<br>其中各个topic 和partition都在不同的broker中存在副本,并且各个broker存在leader,follower两种类型,kafka读写数据只存在于leader服务器上,follow只做副本以及当leader挂掉之后可做为新的leader<br>consumer消费集群中的数据,当数据量较大的时候就让多个消费者消费数据提高消费能力,就有了cocnsumer group,同一个消费者组数据共享,多个消费者消费部分数据<br>zookeeper存放kafka的meta集群信息以及消费者消费队列的信息(消费偏移量offset)</strong></p>\n<h2 id=\"kafka下载地址-http-kafka-apache-org-downloads\"><a href=\"#kafka下载地址-http-kafka-apache-org-downloads\" class=\"headerlink\" title=\"kafka下载地址:http://kafka.apache.org/downloads\"></a>kafka下载地址:<a href=\"http://kafka.apache.org/downloads\">http://kafka.apache.org/downloads</a></h2><h2 id=\"kafka集群安装\"><a href=\"#kafka集群安装\" class=\"headerlink\" title=\"kafka集群安装\"></a>kafka集群安装</h2><ol>\n<li>下载kafka安装到指定目录,这里我放在/opt/module/kafka下,解压安装</li>\n<li>创建一个logs日志文件夹(因为kafka存储的日志数据可做其他用途)</li>\n<li>修改配置文件安装目录下的config/server.properties</li>\n<li>配置环境变量profile(为了在任何路径都可执行kafka命令,这一步可省略)</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#kafka home </span></span><br><span class=\"line\">\t<span class=\"built_in\">export</span> KAFKA_HOME=/opt/module/kafka</span><br><span class=\"line\">\t<span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$KAFKA_HOME</span>/bin</span><br></pre></td></tr></table></figure>\n\n<ol start=\"5\">\n<li>分发安装包xsync</li>\n<li>启动集群bin/kafka-server-start.sh config/server.properties &amp;<br>后台启动不打日志,守护线程启动 nohup  bin/kafka-server-start.sh -daemons config/server.properties  &amp;</li>\n</ol>\n<p> server.properties配置文件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class=\"line\"><span class=\"comment\"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class=\"line\"><span class=\"comment\"># this work for additional information regarding copyright ownership.</span></span><br><span class=\"line\"><span class=\"comment\"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class=\"line\"><span class=\"comment\"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class=\"line\"><span class=\"comment\"># the License.  You may obtain a copy of the License at</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class=\"line\"><span class=\"comment\"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class=\"line\"><span class=\"comment\"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class=\"line\"><span class=\"comment\"># See the License for the specific language governing permissions and</span></span><br><span class=\"line\"><span class=\"comment\"># limitations under the License.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># see kafka.server.KafkaConfig for additional details and defaults</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Server Basics #############################</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># The id of the broker. This must be set to a unique integer for each broker.  服务器唯一ID </span></span><br><span class=\"line\">broker.id=0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Switch to enable topic deletion or not, default value is false \t 删除topic功能开关</span></span><br><span class=\"line\"><span class=\"comment\">#delete.topic.enable=true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Socket Server Settings #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The address the socket server listens on. It will get the value returned from </span></span><br><span class=\"line\"><span class=\"comment\"># java.net.InetAddress.getCanonicalHostName() if not configured.</span></span><br><span class=\"line\"><span class=\"comment\">#   FORMAT:</span></span><br><span class=\"line\"><span class=\"comment\">#     listeners = listener_name://host_name:port</span></span><br><span class=\"line\"><span class=\"comment\">#   EXAMPLE:</span></span><br><span class=\"line\"><span class=\"comment\">#     listeners = PLAINTEXT://your.host.name:9092</span></span><br><span class=\"line\"><span class=\"comment\">#listeners=PLAINTEXT://:9092</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Hostname and port the broker will advertise to producers and consumers. If not set, </span></span><br><span class=\"line\"><span class=\"comment\"># it uses the value for &quot;listeners&quot; if configured.  Otherwise, it will use the value</span></span><br><span class=\"line\"><span class=\"comment\"># returned from java.net.InetAddress.getCanonicalHostName().</span></span><br><span class=\"line\"><span class=\"comment\">#advertised.listeners=PLAINTEXT://your.host.name:9092</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details</span></span><br><span class=\"line\"><span class=\"comment\">#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The number of threads that the server uses for receiving requests from the network and sending responses to the network 处理网络请求的的线程数</span></span><br><span class=\"line\">num.network.threads=3</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The number of threads that the server uses for processing requests, which may include disk I/O 处理磁盘io的线程数量</span></span><br><span class=\"line\">num.io.threads=8</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The send buffer (SO_SNDBUF) used by the socket server  发送套接字的缓冲区大小</span></span><br><span class=\"line\">socket.send.buffer.bytes=102400</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The receive buffer (SO_RCVBUF) used by the socket server  接收套接字的缓冲区大小</span></span><br><span class=\"line\">socket.receive.buffer.bytes=102400</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The maximum size of a request that the socket server will accept (protection against OOM)  请求套接字的缓冲区大小</span></span><br><span class=\"line\">socket.request.max.bytes=104857600</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Log Basics #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># A comma seperated list of directories under which to store log files kafka运行日志存放的路径</span></span><br><span class=\"line\">log.dirs=/tmp/kafka-logs</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The default number of log partitions per topic. More partitions allow greater</span></span><br><span class=\"line\"><span class=\"comment\"># parallelism for consumption, but this will also result in more files across  topic在当前broker上的分区个数</span></span><br><span class=\"line\"><span class=\"comment\"># the brokers.</span></span><br><span class=\"line\">num.partitions=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.</span></span><br><span class=\"line\"><span class=\"comment\"># This value is recommended to be increased for installations with data dirs located in RAID array.    恢复和清理data下数据的线程数量</span></span><br><span class=\"line\">num.recovery.threads.per.data.dir=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Internal Topic Settings  #############################</span></span><br><span class=\"line\"><span class=\"comment\"># The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.</span></span><br><span class=\"line\">offsets.topic.replication.factor=1</span><br><span class=\"line\">transaction.state.log.replication.factor=1</span><br><span class=\"line\">transaction.state.log.min.isr=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Log Flush Policy #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Messages are immediately written to the filesystem but by default we only fsync() to sync</span></span><br><span class=\"line\"><span class=\"comment\"># the OS cache lazily. The following configurations control the flush of data to disk.</span></span><br><span class=\"line\"><span class=\"comment\"># There are a few important trade-offs here:</span></span><br><span class=\"line\"><span class=\"comment\">#    1. Durability: Unflushed data may be lost if you are not using replication.</span></span><br><span class=\"line\"><span class=\"comment\">#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.</span></span><br><span class=\"line\"><span class=\"comment\">#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.</span></span><br><span class=\"line\"><span class=\"comment\"># The settings below allow one to configure the flush policy to flush data after a period of time or</span></span><br><span class=\"line\"><span class=\"comment\"># every N messages (or both). This can be done globally and overridden on a per-topic basis.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The number of messages to accept before forcing a flush of data to disk</span></span><br><span class=\"line\"><span class=\"comment\">#log.flush.interval.messages=10000</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The maximum amount of time a message can sit in a log before we force a flush</span></span><br><span class=\"line\"><span class=\"comment\">#log.flush.interval.ms=1000</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Log Retention Policy #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The following configurations control the disposal of log segments. The policy can</span></span><br><span class=\"line\"><span class=\"comment\"># be set to delete segments after a period of time, or after a given size has accumulated.</span></span><br><span class=\"line\"><span class=\"comment\"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span></span><br><span class=\"line\"><span class=\"comment\"># from the end of the log.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The minimum age of a log file to be eligible for deletion due to age    segment文件保留的最长时间,超时将删除\t</span></span><br><span class=\"line\">log.retention.hours=168</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># A size-based retention policy for logs. Segments are pruned from the log as long as the remaining</span></span><br><span class=\"line\"><span class=\"comment\"># segments don&#x27;t drop below log.retention.bytes. Functions independently of log.retention.hours.</span></span><br><span class=\"line\"><span class=\"comment\">#log.retention.bytes=1073741824</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></span><br><span class=\"line\">log.segment.bytes=1073741824</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The interval at which log segments are checked to see if they can be deleted according</span></span><br><span class=\"line\"><span class=\"comment\"># to the retention policies</span></span><br><span class=\"line\">log.retention.check.interval.ms=300000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Zookeeper #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Zookeeper connection string (see zookeeper docs for details).</span></span><br><span class=\"line\"><span class=\"comment\"># This is a comma separated host:port pairs, each corresponding to a zk</span></span><br><span class=\"line\"><span class=\"comment\"># server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.</span></span><br><span class=\"line\"><span class=\"comment\"># You can also append an optional chroot string to the urls to specify the</span></span><br><span class=\"line\"><span class=\"comment\"># root directory for all kafka znodes.   配置链接zookeeper集群地址</span></span><br><span class=\"line\">zookeeper.connect=localhost:2181</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Timeout in ms for connecting to zookeeper</span></span><br><span class=\"line\">zookeeper.connection.timeout.ms=6000</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Group Coordinator Settings #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.</span></span><br><span class=\"line\"><span class=\"comment\"># The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.</span></span><br><span class=\"line\"><span class=\"comment\"># The default value for this is 3 seconds.</span></span><br><span class=\"line\"><span class=\"comment\"># We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.</span></span><br><span class=\"line\"><span class=\"comment\"># However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.</span></span><br><span class=\"line\">group.initial.rebalance.delay.ms=0</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"kafka命令行操作\"><a href=\"#kafka命令行操作\" class=\"headerlink\" title=\"kafka命令行操作\"></a>kafka命令行操作</h2><p>关闭集群</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-server-stop.sh stop </span><br></pre></td></tr></table></figure>\n\n<p>查看当前服务中的所有topic</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-topics.sh --zookeeper hadoop1:2181 --list</span><br></pre></td></tr></table></figure>\n\n<p>创建topics</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-topics.sh --zookeeper hadoop1:2181 --create --topic hadoop1 --partitions 3 --replication-factor 3</span><br><span class=\"line\">参数说明</span><br><span class=\"line\">--topic 定义topic名</span><br><span class=\"line\">--replication-factor 定义副本数</span><br><span class=\"line\">--partitions 定义分区数</span><br></pre></td></tr></table></figure>\n\n<p>查看topic信息</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-topics.sh --zookeeper hadoop1:2181 --describe --topic hadoop1</span><br></pre></td></tr></table></figure>\n\n<p>删除topic</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-topics.sh --zookeeper hadoop1:2181 --delete --topic hadoop1</span><br></pre></td></tr></table></figure>\n\n<p>发送消息</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-console-producer.sh --broker-list hadoop1:9092 --topic hadoop1</span><br></pre></td></tr></table></figure>\n\n<p>单个消费者启动</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-console-consumer.sh --zookeeper hadoop1:2181 --from-beginning --topic hadoop1</span><br><span class=\"line\">配置消费者组的模式(修改consumer.properties文件,group.id=test-consumer-group)</span><br><span class=\"line\">bin/kafka-console-consumer.sh --zookeeper hadoop1:2181  --topic hadoop1 --consumer.config config/consumer.properties</span><br><span class=\"line\">bin/kafka-console-consumer.sh --bootstrap-server hadoop1:2181  --topic hadoop1 --consumer.config config/consumer.properties</span><br></pre></td></tr></table></figure>\n\n<p>查看消费者组信息</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-consumer-offset-checker.sh --zookeeper hadoop1:2181 --group kafka-group</span><br></pre></td></tr></table></figure>\n\n<p>副本再平衡</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-preferred-replica-election.sh --zookeeper hadoop1:2181</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"kafka生产过程分析\"><a href=\"#kafka生产过程分析\" class=\"headerlink\" title=\"kafka生产过程分析\"></a>kafka生产过程分析</h2><p>producer采用推(push)模式将消息发布到broker,每条消息都被追加(append)到分区(patition)中,属于顺序写磁盘(<strong>顺序写磁盘效率比随机写内存高,零拷贝,kafka分段日志(segment),kafka预读(read ahead),后写(Write behind)保障kafka吞吐率</strong>)</p>\n<p><strong>分区</strong>(partition)消息发送时都被发送到一个topic,其本质就是一个目录,而topic是由一些partition logs(分区日志)组成,每个partition中俄消息都是有序的,生产的消息被不断追加到partition log 上,其中每一个消息都被赋予一个offset</p>\n<p><strong>分区的原因</strong><br>方便集群拓展;<br>提高并发以partition    为单位读写<br><strong>分区的原则</strong><br>指定partition;<br>未指定partition但指定key,通过key的value进行hash出一个partition;<br>partition和key都未指定,使用轮询选出一个partition</p>\n<p><strong>副本(replication)</strong><br>同一个partition可以有多个副本,如果没有副本,一旦broker宕机,其上所有partition的数据都不能被消费同时producer也不能将数据存储在其partition,引入replication,同一个partition可能会有多个副本,而这时需要在其副本中选出leader,生产者和消费者<br><strong>只与leader交互,其他replication作为follower从leader中复制数据</strong><br><strong>ack应答机制</strong><br><strong>0:producer发送数据给leader,不管是否leader收到,效率最高<br>1(kafka默认):producer发送数据给leader,leader存放在log之后,producer就发送新的数据,这一段时间不管follower是否向leader同步成功,数据较为安全<br>-1(all):producer发送数据给leader,leader存放在log之后,等待所有follower同步成功之后,producer才能发送下一条数据,数据最安全,性能非常差</strong></p>\n<h2 id=\"kafka消费过程分析\"><a href=\"#kafka消费过程分析\" class=\"headerlink\" title=\"kafka消费过程分析\"></a>kafka消费过程分析</h2><p><strong>consumer链接zookeeper获取kafka集群的相关信息(主要是消费数据的offset值保存在zookeeper,在后期版本之后offset可放在集群中不用放在zookeeper)<br>消费者pull拉取kafka集群中指定的topic分区的信息消费,分批次取数据(缓冲数据多条数据),一个分区只能一个消费者消费,但是一个消费者可以消费多个分区,group consumer(消费者组)中包含的多个消费者里面的offset统一管理同组消费者成员消费<br>后期添加消费者消费,集群可做再平衡,消费者组从新从zookeeper获取集群信息,再平衡在kafka集群中进行</strong></p>\n<p><strong>zookeeper存储kafka主要节点属性</strong><br><strong>cluster kafka</strong>集群信息(集群id)<br><strong>controller</strong> 集群控制器(leader broker作为整个集群的控制器)<br><strong>controller_epoch</strong> 轮值(leader竞选次数)<br><strong>brokers</strong> 单个服务器信息(ids,topics,seqid)<br><strong>consumers</strong> 消费者组信息(ids,owners)</p>\n<h2 id=\"kafka面试要点\"><a href=\"#kafka面试要点\" class=\"headerlink\" title=\"kafka面试要点\"></a>kafka面试要点</h2><ol>\n<li>kafka的吞吐量高的原因:顺写日志,零拷贝(zero-cooy),kafka分段日志(segment),kafka预读(read ahead),后写(Write behind),批处理,压缩(byte)保障kafka吞吐率</li>\n<li>kafka的偏移量offset存放位置:早前版本zookeeper,后期版本放在cluster版本中(_consumer_offset),自定义维护offset(eg:redis里面,数据库都可以)</li>\n<li>kafka消费方式:poll,拉取方式</li>\n<li>防止kafka数据丢失的的措施:同步发送数据,ack=1(all)</li>\n<li>重复消费:维护offset避免重复消费(低级api)</li>\n<li>kafka元数据存放:zookeeper(/cluster,/controller,/controller_epoch,/brokers,/consumers)</li>\n<li>kafka选举机制:/controller 不同机器同时去zookeeper注册/controller节点,先到先得,成功之后从isr列表选取leader,全挂等待副本</li>\n<li>kafka的消费速度:增加分区和消费者,增加poll数量,增大批处理大小</li>\n</ol>\n<h2 id=\"上手代码地址-https-gitee-com-ArnoldSu-kafka\"><a href=\"#上手代码地址-https-gitee-com-ArnoldSu-kafka\" class=\"headerlink\" title=\"上手代码地址:https://gitee.com/ArnoldSu/kafka\"></a>上手代码地址:<a href=\"https://gitee.com/ArnoldSu/kafka\">https://gitee.com/ArnoldSu/kafka</a></h2>","site":{"data":{}},"excerpt":"<p>kafka是一个开源的消息系统,由Scala语言写成,由apache基金会开发</p>","more":"<h1 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h1><h2 id=\"为什么需要消息队列\"><a href=\"#为什么需要消息队列\" class=\"headerlink\" title=\"为什么需要消息队列?\"></a>为什么需要消息队列?</h2><p><strong>解耦</strong>:允许独立的拓展或修该双方逻辑交互过程程序,只要保证保证双方的遵守同样的接口约束<br><strong>冗余</strong>:保证数据多个副本不至于数据丢失以及数据重复<br><strong>拓展性</strong>:可添加相应的额外处理过程<br><strong>灵活性&amp;峰值处理能力</strong>:突发流量访问激增,仍然能够保证程序稳定运行<br><strong>可恢复性</strong>:消息队列降低了进程间的耦合性,一个消息队列处理进程挂掉,加入队列的消息任然可以在系统恢复后被处理<br><strong>顺序保证</strong>:到部分消息队列都要保证处理消息的顺序性(kafka保证一个partition内的消息的有序性)<br><strong>缓冲</strong>:加快数据处理速度<br><strong>异步通信</strong>:减少程序等待,提高程序处理速度</p>\n<h2 id=\"kafka定义\"><a href=\"#kafka定义\" class=\"headerlink\" title=\"kafka定义\"></a>kafka定义</h2><p>kafka是一个开源的消息系统,由Scala语言写成,由apache基金会开发<br>kafka是一个分布式消息队列,kafka对消息保存时根据Topic进行归类,发送消息者称为producer,消息接收者为consumer,kafka集群中存在多个kafka实例,每个实例(server)称为broker<br>kafka集群依赖zookeeper里面的meta信息</p>\n<h2 id=\"kafka的架构流程\"><a href=\"#kafka的架构流程\" class=\"headerlink\" title=\"kafka的架构流程\"></a>kafka的架构流程</h2><p>流程中的角色<br><strong>producer消息生产者</strong>,指消息kafka broker发送数据的客户端<br><strong>consumer消息消费者</strong>,向kafka broker 取数据的客户端<br><strong>topic</strong> 主题,可理解为一个队列<br><strong>cocnsumer group</strong> 消费者组,多个消费者共同消费一个topic消息<br><strong>broker</strong> 就是一台kafka服务器,一个集群中有多个broker,一个broker有多个topic<br><strong>partition</strong> 一个topic可以分为多个partition,每个partition是一个有序队列,partition中的消息都有一个有序的<strong>id(offset)</strong>,kafka只保证一个partition中的消息的有序性,不能保证一个topic或者多个partition中消息的有序性<br><strong>offset</strong> 存储文件按照offset.kafka来命名,用offset命名的好处是方便查找</p>\n<h2 id=\"kafka处理流程步奏\"><a href=\"#kafka处理流程步奏\" class=\"headerlink\" title=\"kafka处理流程步奏\"></a>kafka处理流程步奏</h2><p><strong>producer生产数据到kafuka集群,消息发送到集群中的相应的broker 的topic 以及partition中<br>其中各个topic 和partition都在不同的broker中存在副本,并且各个broker存在leader,follower两种类型,kafka读写数据只存在于leader服务器上,follow只做副本以及当leader挂掉之后可做为新的leader<br>consumer消费集群中的数据,当数据量较大的时候就让多个消费者消费数据提高消费能力,就有了cocnsumer group,同一个消费者组数据共享,多个消费者消费部分数据<br>zookeeper存放kafka的meta集群信息以及消费者消费队列的信息(消费偏移量offset)</strong></p>\n<h2 id=\"kafka下载地址-http-kafka-apache-org-downloads\"><a href=\"#kafka下载地址-http-kafka-apache-org-downloads\" class=\"headerlink\" title=\"kafka下载地址:http://kafka.apache.org/downloads\"></a>kafka下载地址:<a href=\"http://kafka.apache.org/downloads\">http://kafka.apache.org/downloads</a></h2><h2 id=\"kafka集群安装\"><a href=\"#kafka集群安装\" class=\"headerlink\" title=\"kafka集群安装\"></a>kafka集群安装</h2><ol>\n<li>下载kafka安装到指定目录,这里我放在/opt/module/kafka下,解压安装</li>\n<li>创建一个logs日志文件夹(因为kafka存储的日志数据可做其他用途)</li>\n<li>修改配置文件安装目录下的config/server.properties</li>\n<li>配置环境变量profile(为了在任何路径都可执行kafka命令,这一步可省略)</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#kafka home </span></span><br><span class=\"line\">\t<span class=\"built_in\">export</span> KAFKA_HOME=/opt/module/kafka</span><br><span class=\"line\">\t<span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$KAFKA_HOME</span>/bin</span><br></pre></td></tr></table></figure>\n\n<ol start=\"5\">\n<li>分发安装包xsync</li>\n<li>启动集群bin/kafka-server-start.sh config/server.properties &amp;<br>后台启动不打日志,守护线程启动 nohup  bin/kafka-server-start.sh -daemons config/server.properties  &amp;</li>\n</ol>\n<p> server.properties配置文件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class=\"line\"><span class=\"comment\"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class=\"line\"><span class=\"comment\"># this work for additional information regarding copyright ownership.</span></span><br><span class=\"line\"><span class=\"comment\"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class=\"line\"><span class=\"comment\"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class=\"line\"><span class=\"comment\"># the License.  You may obtain a copy of the License at</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class=\"line\"><span class=\"comment\"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class=\"line\"><span class=\"comment\"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class=\"line\"><span class=\"comment\"># See the License for the specific language governing permissions and</span></span><br><span class=\"line\"><span class=\"comment\"># limitations under the License.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># see kafka.server.KafkaConfig for additional details and defaults</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Server Basics #############################</span></span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># The id of the broker. This must be set to a unique integer for each broker.  服务器唯一ID </span></span><br><span class=\"line\">broker.id=0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Switch to enable topic deletion or not, default value is false \t 删除topic功能开关</span></span><br><span class=\"line\"><span class=\"comment\">#delete.topic.enable=true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Socket Server Settings #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The address the socket server listens on. It will get the value returned from </span></span><br><span class=\"line\"><span class=\"comment\"># java.net.InetAddress.getCanonicalHostName() if not configured.</span></span><br><span class=\"line\"><span class=\"comment\">#   FORMAT:</span></span><br><span class=\"line\"><span class=\"comment\">#     listeners = listener_name://host_name:port</span></span><br><span class=\"line\"><span class=\"comment\">#   EXAMPLE:</span></span><br><span class=\"line\"><span class=\"comment\">#     listeners = PLAINTEXT://your.host.name:9092</span></span><br><span class=\"line\"><span class=\"comment\">#listeners=PLAINTEXT://:9092</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Hostname and port the broker will advertise to producers and consumers. If not set, </span></span><br><span class=\"line\"><span class=\"comment\"># it uses the value for &quot;listeners&quot; if configured.  Otherwise, it will use the value</span></span><br><span class=\"line\"><span class=\"comment\"># returned from java.net.InetAddress.getCanonicalHostName().</span></span><br><span class=\"line\"><span class=\"comment\">#advertised.listeners=PLAINTEXT://your.host.name:9092</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details</span></span><br><span class=\"line\"><span class=\"comment\">#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The number of threads that the server uses for receiving requests from the network and sending responses to the network 处理网络请求的的线程数</span></span><br><span class=\"line\">num.network.threads=3</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The number of threads that the server uses for processing requests, which may include disk I/O 处理磁盘io的线程数量</span></span><br><span class=\"line\">num.io.threads=8</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The send buffer (SO_SNDBUF) used by the socket server  发送套接字的缓冲区大小</span></span><br><span class=\"line\">socket.send.buffer.bytes=102400</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The receive buffer (SO_RCVBUF) used by the socket server  接收套接字的缓冲区大小</span></span><br><span class=\"line\">socket.receive.buffer.bytes=102400</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The maximum size of a request that the socket server will accept (protection against OOM)  请求套接字的缓冲区大小</span></span><br><span class=\"line\">socket.request.max.bytes=104857600</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Log Basics #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># A comma seperated list of directories under which to store log files kafka运行日志存放的路径</span></span><br><span class=\"line\">log.dirs=/tmp/kafka-logs</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The default number of log partitions per topic. More partitions allow greater</span></span><br><span class=\"line\"><span class=\"comment\"># parallelism for consumption, but this will also result in more files across  topic在当前broker上的分区个数</span></span><br><span class=\"line\"><span class=\"comment\"># the brokers.</span></span><br><span class=\"line\">num.partitions=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.</span></span><br><span class=\"line\"><span class=\"comment\"># This value is recommended to be increased for installations with data dirs located in RAID array.    恢复和清理data下数据的线程数量</span></span><br><span class=\"line\">num.recovery.threads.per.data.dir=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Internal Topic Settings  #############################</span></span><br><span class=\"line\"><span class=\"comment\"># The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.</span></span><br><span class=\"line\">offsets.topic.replication.factor=1</span><br><span class=\"line\">transaction.state.log.replication.factor=1</span><br><span class=\"line\">transaction.state.log.min.isr=1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Log Flush Policy #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Messages are immediately written to the filesystem but by default we only fsync() to sync</span></span><br><span class=\"line\"><span class=\"comment\"># the OS cache lazily. The following configurations control the flush of data to disk.</span></span><br><span class=\"line\"><span class=\"comment\"># There are a few important trade-offs here:</span></span><br><span class=\"line\"><span class=\"comment\">#    1. Durability: Unflushed data may be lost if you are not using replication.</span></span><br><span class=\"line\"><span class=\"comment\">#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.</span></span><br><span class=\"line\"><span class=\"comment\">#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.</span></span><br><span class=\"line\"><span class=\"comment\"># The settings below allow one to configure the flush policy to flush data after a period of time or</span></span><br><span class=\"line\"><span class=\"comment\"># every N messages (or both). This can be done globally and overridden on a per-topic basis.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The number of messages to accept before forcing a flush of data to disk</span></span><br><span class=\"line\"><span class=\"comment\">#log.flush.interval.messages=10000</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The maximum amount of time a message can sit in a log before we force a flush</span></span><br><span class=\"line\"><span class=\"comment\">#log.flush.interval.ms=1000</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Log Retention Policy #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The following configurations control the disposal of log segments. The policy can</span></span><br><span class=\"line\"><span class=\"comment\"># be set to delete segments after a period of time, or after a given size has accumulated.</span></span><br><span class=\"line\"><span class=\"comment\"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span></span><br><span class=\"line\"><span class=\"comment\"># from the end of the log.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The minimum age of a log file to be eligible for deletion due to age    segment文件保留的最长时间,超时将删除\t</span></span><br><span class=\"line\">log.retention.hours=168</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># A size-based retention policy for logs. Segments are pruned from the log as long as the remaining</span></span><br><span class=\"line\"><span class=\"comment\"># segments don&#x27;t drop below log.retention.bytes. Functions independently of log.retention.hours.</span></span><br><span class=\"line\"><span class=\"comment\">#log.retention.bytes=1073741824</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></span><br><span class=\"line\">log.segment.bytes=1073741824</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The interval at which log segments are checked to see if they can be deleted according</span></span><br><span class=\"line\"><span class=\"comment\"># to the retention policies</span></span><br><span class=\"line\">log.retention.check.interval.ms=300000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Zookeeper #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Zookeeper connection string (see zookeeper docs for details).</span></span><br><span class=\"line\"><span class=\"comment\"># This is a comma separated host:port pairs, each corresponding to a zk</span></span><br><span class=\"line\"><span class=\"comment\"># server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.</span></span><br><span class=\"line\"><span class=\"comment\"># You can also append an optional chroot string to the urls to specify the</span></span><br><span class=\"line\"><span class=\"comment\"># root directory for all kafka znodes.   配置链接zookeeper集群地址</span></span><br><span class=\"line\">zookeeper.connect=localhost:2181</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Timeout in ms for connecting to zookeeper</span></span><br><span class=\"line\">zookeeper.connection.timeout.ms=6000</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">############################# Group Coordinator Settings #############################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.</span></span><br><span class=\"line\"><span class=\"comment\"># The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.</span></span><br><span class=\"line\"><span class=\"comment\"># The default value for this is 3 seconds.</span></span><br><span class=\"line\"><span class=\"comment\"># We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.</span></span><br><span class=\"line\"><span class=\"comment\"># However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.</span></span><br><span class=\"line\">group.initial.rebalance.delay.ms=0</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"kafka命令行操作\"><a href=\"#kafka命令行操作\" class=\"headerlink\" title=\"kafka命令行操作\"></a>kafka命令行操作</h2><p>关闭集群</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-server-stop.sh stop </span><br></pre></td></tr></table></figure>\n\n<p>查看当前服务中的所有topic</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-topics.sh --zookeeper hadoop1:2181 --list</span><br></pre></td></tr></table></figure>\n\n<p>创建topics</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-topics.sh --zookeeper hadoop1:2181 --create --topic hadoop1 --partitions 3 --replication-factor 3</span><br><span class=\"line\">参数说明</span><br><span class=\"line\">--topic 定义topic名</span><br><span class=\"line\">--replication-factor 定义副本数</span><br><span class=\"line\">--partitions 定义分区数</span><br></pre></td></tr></table></figure>\n\n<p>查看topic信息</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-topics.sh --zookeeper hadoop1:2181 --describe --topic hadoop1</span><br></pre></td></tr></table></figure>\n\n<p>删除topic</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-topics.sh --zookeeper hadoop1:2181 --delete --topic hadoop1</span><br></pre></td></tr></table></figure>\n\n<p>发送消息</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-console-producer.sh --broker-list hadoop1:9092 --topic hadoop1</span><br></pre></td></tr></table></figure>\n\n<p>单个消费者启动</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-console-consumer.sh --zookeeper hadoop1:2181 --from-beginning --topic hadoop1</span><br><span class=\"line\">配置消费者组的模式(修改consumer.properties文件,group.id=test-consumer-group)</span><br><span class=\"line\">bin/kafka-console-consumer.sh --zookeeper hadoop1:2181  --topic hadoop1 --consumer.config config/consumer.properties</span><br><span class=\"line\">bin/kafka-console-consumer.sh --bootstrap-server hadoop1:2181  --topic hadoop1 --consumer.config config/consumer.properties</span><br></pre></td></tr></table></figure>\n\n<p>查看消费者组信息</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-consumer-offset-checker.sh --zookeeper hadoop1:2181 --group kafka-group</span><br></pre></td></tr></table></figure>\n\n<p>副本再平衡</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-preferred-replica-election.sh --zookeeper hadoop1:2181</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"kafka生产过程分析\"><a href=\"#kafka生产过程分析\" class=\"headerlink\" title=\"kafka生产过程分析\"></a>kafka生产过程分析</h2><p>producer采用推(push)模式将消息发布到broker,每条消息都被追加(append)到分区(patition)中,属于顺序写磁盘(<strong>顺序写磁盘效率比随机写内存高,零拷贝,kafka分段日志(segment),kafka预读(read ahead),后写(Write behind)保障kafka吞吐率</strong>)</p>\n<p><strong>分区</strong>(partition)消息发送时都被发送到一个topic,其本质就是一个目录,而topic是由一些partition logs(分区日志)组成,每个partition中俄消息都是有序的,生产的消息被不断追加到partition log 上,其中每一个消息都被赋予一个offset</p>\n<p><strong>分区的原因</strong><br>方便集群拓展;<br>提高并发以partition    为单位读写<br><strong>分区的原则</strong><br>指定partition;<br>未指定partition但指定key,通过key的value进行hash出一个partition;<br>partition和key都未指定,使用轮询选出一个partition</p>\n<p><strong>副本(replication)</strong><br>同一个partition可以有多个副本,如果没有副本,一旦broker宕机,其上所有partition的数据都不能被消费同时producer也不能将数据存储在其partition,引入replication,同一个partition可能会有多个副本,而这时需要在其副本中选出leader,生产者和消费者<br><strong>只与leader交互,其他replication作为follower从leader中复制数据</strong><br><strong>ack应答机制</strong><br><strong>0:producer发送数据给leader,不管是否leader收到,效率最高<br>1(kafka默认):producer发送数据给leader,leader存放在log之后,producer就发送新的数据,这一段时间不管follower是否向leader同步成功,数据较为安全<br>-1(all):producer发送数据给leader,leader存放在log之后,等待所有follower同步成功之后,producer才能发送下一条数据,数据最安全,性能非常差</strong></p>\n<h2 id=\"kafka消费过程分析\"><a href=\"#kafka消费过程分析\" class=\"headerlink\" title=\"kafka消费过程分析\"></a>kafka消费过程分析</h2><p><strong>consumer链接zookeeper获取kafka集群的相关信息(主要是消费数据的offset值保存在zookeeper,在后期版本之后offset可放在集群中不用放在zookeeper)<br>消费者pull拉取kafka集群中指定的topic分区的信息消费,分批次取数据(缓冲数据多条数据),一个分区只能一个消费者消费,但是一个消费者可以消费多个分区,group consumer(消费者组)中包含的多个消费者里面的offset统一管理同组消费者成员消费<br>后期添加消费者消费,集群可做再平衡,消费者组从新从zookeeper获取集群信息,再平衡在kafka集群中进行</strong></p>\n<p><strong>zookeeper存储kafka主要节点属性</strong><br><strong>cluster kafka</strong>集群信息(集群id)<br><strong>controller</strong> 集群控制器(leader broker作为整个集群的控制器)<br><strong>controller_epoch</strong> 轮值(leader竞选次数)<br><strong>brokers</strong> 单个服务器信息(ids,topics,seqid)<br><strong>consumers</strong> 消费者组信息(ids,owners)</p>\n<h2 id=\"kafka面试要点\"><a href=\"#kafka面试要点\" class=\"headerlink\" title=\"kafka面试要点\"></a>kafka面试要点</h2><ol>\n<li>kafka的吞吐量高的原因:顺写日志,零拷贝(zero-cooy),kafka分段日志(segment),kafka预读(read ahead),后写(Write behind),批处理,压缩(byte)保障kafka吞吐率</li>\n<li>kafka的偏移量offset存放位置:早前版本zookeeper,后期版本放在cluster版本中(_consumer_offset),自定义维护offset(eg:redis里面,数据库都可以)</li>\n<li>kafka消费方式:poll,拉取方式</li>\n<li>防止kafka数据丢失的的措施:同步发送数据,ack=1(all)</li>\n<li>重复消费:维护offset避免重复消费(低级api)</li>\n<li>kafka元数据存放:zookeeper(/cluster,/controller,/controller_epoch,/brokers,/consumers)</li>\n<li>kafka选举机制:/controller 不同机器同时去zookeeper注册/controller节点,先到先得,成功之后从isr列表选取leader,全挂等待副本</li>\n<li>kafka的消费速度:增加分区和消费者,增加poll数量,增大批处理大小</li>\n</ol>\n<h2 id=\"上手代码地址-https-gitee-com-ArnoldSu-kafka\"><a href=\"#上手代码地址-https-gitee-com-ArnoldSu-kafka\" class=\"headerlink\" title=\"上手代码地址:https://gitee.com/ArnoldSu/kafka\"></a>上手代码地址:<a href=\"https://gitee.com/ArnoldSu/kafka\">https://gitee.com/ArnoldSu/kafka</a></h2>"},{"title":"Maven学习浅记-常用命令及相关概念","date":"2019-12-15T07:14:01.000Z","_content":"Maven学习浅记-常用命令及相关概念\n<!--more-->\n## 1:Maven官网(官方文档是学习工具的最好参考书)\n\n   [ http://maven.apache.org](http://maven.apache.org)\n\n## 2:maven官网定义\n  官方解释：Apache Maven is a software project management and comprehension tool.\n  Based on the concept of a project object model (POM),Maven can manage a project's build,\n  reporting and documentation from a central piece of information\n  (Apache Maven是一个软件项目管理和理解工具。基于项目对象模型（POM）的概念，Maven可以从一个中心信息管理项目的构建，报告和文档)\n  \n  我目前所用到的Maven的主要作用就是:\n  \n    1:添加第三方jar包;\n    2:jar包之间的依赖关系;\n    3:获取第三方jar包；\n    4:将整个项目拆分成多个工程模块;\n    5：部署，测试报告;\n但是maven是一个强大工具(远远不止我提到的这几个基础的功能,其中就包含项目的构建，报告和文档,官方解释地址:https://maven.apache.org/maven-features.html;\n\n## 3:Maven下载地址\n\n [https://maven.apache.org/download.cgi](https://maven.apache.org/download.cgi)\n\n## 4:maven安装\n###  **4.1:解压部署Maven核心程序** \n\n\t①检查JAVA_HOME环境变量\n\t\t首先确保你的JDK已经正确安装;\n\t②解压Maven的核心程序\n\t\t将apache-maven-3.5.3-bin.zip(在项目中以上传元安装包)解压到一个非中文无空格的目录下。例如：D:\\DevInstall\\apache-maven-3.5.3\n\t③配置环境变量\n\t\tM2_HOME D:\\DevInstall\\apache-maven-3.5.3\n\t\tpath\tD:\\DevInstall\\apache-maven-3.5.3\\bin\n\t④查看Maven版本信息验证安装是否正确\n\tC:\\Windows\\System32>mvn -v\n        Apache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-25T03:49:05+08:00)\n        Maven home: D:\\Maven\\apache-maven-3.5.3\\bin\\..\n        Java version: 1.8.0_131, vendor: Oracle Corporation\n        Java home: D:\\Program Files\\Java\\jdk1.8.0_131\\jre\n        Default locale: zh_CN, platform encoding: GBK\n        OS name: \"windows 10\", version: \"10.0\", arch: \"amd64\", family: \"windows\"\n\n### 4.2:修改本地仓库\n\n\t①默认本地仓库位置：~\\.m2\\repository,~表示当前用户的家目录，例如：C:\\Users\\[你当前登录系统的用户名]\n\t②指定本地仓库位置的配置信息文件：apache-maven-3.5.3\\conf\\settings.xml\n\t③在根标签settings下添加如下内容：<localRepository>[本地仓库路径，也就是RepMaven.zip的解压目录]</localRepository>\n\n## 5:官网五分钟教程\n### 5.1:保证安装好Maven(参考本文4:maven安装)\n\n\n### 5.2:首先你要知道Maven的一个项目结构\n\n    my-app\n    |-- pom.xml project's Project Object Model, or POM. 项目对象模型文件\n    |-- src\n        |-- main\n            |-- java\tApplication/Library sources 应用程序/库源\n            |-- resources   Application/Library resources 应用程序/库资源\n            |-- filters   Resource filter files 资源过滤文件\n            |-- webapp   Web application sources Web应用程序源\n        |-- test\n            |--java Test sources 测试来源\n            |--resources Test sources 测试资源\n            |--filters Test resource filter files 测试资源过滤器文件\n        |--it Integration Tests (primarily for plugins) 集成测试（主要用于插件）\n        |--assembly Assembly descriptors 程序装配集成描述\n        |--site Site\n    LICENSE.txt\tProject's license 项目许可证\n    NOTICE.txt\tNotices and attributions required by libraries that the project depends on 项目依赖的库和其他注意的问题\n    README.txt 项目提要\n\n### 5.3:在建成你的项目之后,一定记住拷贝一份官方的pom.xml放到其指定的位置\n\neg:pom.xml\n\n\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n     xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n     <modelVersion>4.0.0</modelVersion>\n\n     <groupId>com.mycompany.app</groupId>\n     <artifactId>my-app</artifactId>\n     <version>1.0-SNAPSHOT</version>\n\n     <properties>\n       <maven.compiler.source>1.7</maven.compiler.source>\n       <maven.compiler.target>1.7</maven.compiler.target>\n     </properties>\n\n     <dependencies>\n       <dependency>\n         <groupId>junit</groupId>\n         <artifactId>junit</artifactId>\n         <version>4.12</version>\n         <scope>test</scope>\n       </dependency>\n     </dependencies>\n   </project>\n```\n\n\n该项目的POM目录下打开命令行窗口执行一段shell脚本:\n`mvn archetype:generate -DgroupId=com.mycompany.app -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false`\n第一次运行可能会花销一些时间下载很多maven依赖的包\n\n### 5.4.POM文件的关键元素解释:\n\n```\n    <project> This is the top-level element in all Maven pom.xml files. \n    (maven项目中最高级别的的pom.xml文件元素节点)\n\n    <modelVersion> This element indicates what version of the object model this POM \n    is using.The version of the model itself changes very infrequently but it is mandatory\n    in order to ensure stability of use if and when the Maven developers deem it necessary\n    to change the model.(工程对象模型的版本号,不经常改变但是开发者可以根据需要改变,存在就是为了确保项目的稳定性)\n\n    <groupId> This element indicates the unique identifier of the organization or group\n    that created the project.The groupId is one of the key identifiers of a project and\n    is typically based on the fully qualified domain name of your organization.For example\n    org.apache.maven.plugins is the designated groupId for all Maven plugins.\n    (创建项目的组织或者组的唯一标识符,一般都是用组织的全限定域名)\n\n    <artifactId> This element indicates the unique base name of the primary artifact being\n    generated by this project.The primary artifact for a project is typically a JAR file.\n    Secondary artifacts like source bundles also use the artifactId as part of their final name.\n    A typical artifact produced by Maven would have the form <artifactId>-<version>.<extension> \n    (for example, myapp-1.0.jar).\n    (由项目生成的唯一主要工件的基本名称(模块名称),主要比如我们打包的时候的生成的包名)\n\n    <packaging> This element indicates the package type to be used by this artifact \n    (e.g. JAR, WAR, EAR, etc.).This not only means if the artifact produced is JAR, WAR,\n    or EAR but can also indicate a specific lifecycle to use as part of the build process.\n    (The lifecycle is a topic we will deal with further on in the guide. For now, just keep\n    in mind that the indicated packaging of a project can play a part in customizing the build\n    lifecycle.) The default value for the packaging element is JAR so you do not have to specify\n    this for most projects.(就是我们打包的类型,eg: jar包,war包.ear包,默认是jarb包)\n\n    <version> This element indicates the version of the artifact generated by the project.\n    Maven goes a long way to help you with version management and you will often see the SNAPSHOT\n    designator in a version,which indicates that a project is in a state of development. We will\n    discuss the use of snapshots and how they work further on in this guide.\n    (由项目生成的工件版本号,有很多版本:eg SNAPSHOT)\n\n    <name> This element indicates the display name used for the project. This is often used\n    in Maven's generated documentation.(项目的显示名称)\n\n    <url> This element indicates where the project's site can be found. This is often used in Maven's\n    generated documentation.(项目的站点位置地址)\n\n    <description> This element provides a basic description of your project. This is often used in Maven's\n    generated documentation.(项目的接本基本描述)\n```\n更多POM.xml元素解释描述文档参考地址:[https://maven.apache.org/ref/3.6.0/maven-model/maven.html](https://maven.apache.org/ref/3.6.0/maven-model/maven.html)\n\n## 6:maven常用命令\n### 6.1:Maven的常用命令(*注意：运行Maven命令时一定要进入pom.xml文件所在的目录)演示:\n\n\t    mvn compile\t编译\n        编译的内容命令行展示窗口展示内容\n        [WARNING]\n        [WARNING] Some problems were encountered while building the effective settings\n        [WARNING] Unrecognised tag: 'mirrors' (position: START_TAG seen ...</mirror>\\n-->\\n\\t \\n<mirrors>... @160:14)    \n        @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n        [WARNING]\n        [INFO] Scanning for projects...\n        [INFO]\n        [INFO] --------------------------< maven_3:maven_3 >---------------------------\n        [INFO] Building maven_3 1.0-SNAPSHOT\n        [INFO] --------------------------------[ jar ]---------------------------------\n        Downloading from central: https://repo.maven.apache.org/maven2/junit/junit/4.0/junit-4.0.pom\n        Downloaded from central: https://repo.maven.apache.org/maven2/junit/junit/4.0/junit-4.0.pom (210 B at 129 B/s)\n        [INFO]\n        [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ maven_3 ---\n        [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n        [INFO] Copying 1 resource\n        [INFO]\n        [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ maven_3 ---\n        [INFO] Changes detected - recompiling the module!\n        [WARNING] File encoding has not been set, using platform encoding GBK, i.e. build is platform dependent!\n        [INFO] Compiling 1 source file to D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\\classes\n        [INFO] ------------------------------------------------------------------------\n        [INFO] BUILD SUCCESS\n        [INFO] ------------------------------------------------------------------------\n        [INFO] Total time: 7.092 s\n        [INFO] Finished at: 2019-02-01T10:37:11+08:00\n        [INFO] ------------------------------------------------------------------------\n\n        mvn clean\t清理\n        [WARNING]\n        [WARNING] Some problems were encountered while building the effective settings\n        [WARNING] Unrecognised tag: 'mirrors' (position: START_TAG seen ...</mirror>\\n-->\\n\\t \\n<mirrors>... @160:14)      \n        @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n        [WARNING]\n        [INFO] Scanning for projects...\n        [INFO]\n        [INFO] --------------------------< maven_3:maven_3 >---------------------------\n        [INFO] Building maven_3 1.0-SNAPSHOT\n        [INFO] --------------------------------[ jar ]---------------------------------\n        [INFO]\n        [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ maven_3 ---\n        [INFO] Deleting D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\n        [INFO] ------------------------------------------------------------------------\n        [INFO] BUILD SUCCESS\n        [INFO] ------------------------------------------------------------------------\n        [INFO] Total time: 0.572 s\n        [INFO] Finished at: 2019-02-01T11:55:52+08:00\n        [INFO] ------------------------------------------------------------------------\n\n        mvn test\t测试\n        [WARNING]\n        [WARNING] Some problems were encountered while building the effective settings\n        [WARNING] Unrecognised tag: 'mirrors' (position: START_TAG seen ...</mirror>\\n-->\\n\\t \\n<mirrors>... @160:14)      \n        @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n        [WARNING]\n        [INFO] Scanning for projects...\n        [INFO]\n        [INFO] --------------------------< maven_3:maven_3 >---------------------------\n        [INFO] Building maven_3 1.0-SNAPSHOT\n        [INFO] --------------------------------[ jar ]---------------------------------\n        [INFO]\n        [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ maven_3 ---\n        [INFO] Deleting D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\n        [INFO] ------------------------------------------------------------------------\n        [INFO] BUILD SUCCESS\n        [INFO] ------------------------------------------------------------------------\n        [INFO] Total time: 0.572 s\n        [INFO] Finished at: 2019-02-01T11:55:52+08:00\n        [INFO] ------------------------------------------------------------------------\n\n        mvn package\t打包\n        打包的内容命令行展示窗口展示内容\n        [WARNING]\n        [WARNING] Some problems were encountered while building the effective settings\n        [WARNING] Unrecognised tag: 'mirrors' (position: START_TAG seen ...</mirror>\\n-->\\n\\t\\n<mirrors>...         \n        @160:14)  @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n        [WARNING]\n        [INFO] Scanning for projects...\n        [INFO]\n        [INFO] --------------------------< maven_3:maven_3 >---------------------------\n        [INFO] Building maven_3 1.0-SNAPSHOT\n        [INFO] --------------------------------[ jar ]---------------------------------\n        [INFO]\n        [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ maven_3 ---\n        [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n        [INFO] Copying 1 resource\n        [INFO]\n        [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ maven_3 ---\n        [INFO] Nothing to compile - all classes are up to date\n        [INFO]\n        [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ maven_3 ---\n        [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n        [INFO] skip non existing resourceDirectory D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\src\\test\\resources\n        [INFO]\n        [INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ maven_3 ---\n        [INFO] Nothing to compile - all classes are up to date\n        [INFO]\n        [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ maven_3 ---\n        [INFO] Surefire report directory: D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\\surefire-reports\n\n        -------------------------------------------------------\n         T E S T S\n        -------------------------------------------------------\n        Running com.boommob.www.HelloWorldTest\n        Hello litingwei!Hello litingwei!\n        Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.176 sec\n        Results :\n\n        Tests run: 1, Failures: 0, Errors: 0, Skipped: 0\n\n        [INFO]\n        [INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ maven_3 ---\n        [INFO] ------------------------------------------------------------------------\n        [INFO] BUILD SUCCESS\n        [INFO] ------------------------------------------------------------------------\n        [INFO] Total time: 4.588 s\n        [INFO] Finished at: 2019-02-01T10:57:07+08:00\n        [INFO] ------------------------------------------------------------------------\n\n \n\n### 6.2:在执行完相应的maven命令之后会在该项目的路径下生成target文件夹:\n     target\n         |-- classes 编译之后的类文件\n         |-- maven-archeiver maven打包时候生成的得一个工程对象模型属性文件里面记载的是该项目的POM.xml的一些相关属性\n         |-- maven-status maven状态,一些maven编译的插件信息\n         |-- surefire-reports maven打包生成的一个报告,测试报告\n         |-- test-classes 编译之后的测试类文件\n\n## 7:maven依赖\n\n### 7.1:首先项目POM.xml添加本文6:maven常用命令的依赖,这是我们本地库的一个模块依赖,如果直接在命令行直接执行:mvn compile 的话会报错, 此处需要先在6:maven常用命令的步骤上执行mvn install,将模块安装到本地,在结合maven依赖进行编译.\n\n### 7.2:POM.xml元素解释\n\ndependencies:(Many) This element describes all of the dependencies associated with a project.\nThese dependencies are used to construct a classpath for your project during the build process.\nThey are automatically downloaded from the repositories defined in this project.See the dependency mechanism for more information.\n(此元素描述与项目关联的所有依赖项。这些依赖项用于在构建过程中为项目构造类路径。它们会自动从此项目中定义的存储库下载,参考依赖机制:https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html);\n\n### 7.3:Dependency Mechanism(依赖机制)\n    3.1.Transitive Dependencies(传递依赖)\n        Dependency mediation(依赖调解),多个版本依赖项nearest definition\n        (最近定义原则:表示所使用的版本将是依赖关系树中与项目最接近的版本。例如，如果A，B和C\n        的依赖关系定义为A - > B - > C - > D 2.0和A - > E - > D 1.0，则构建A时将使用D 1.0,\n        因为A的路径到D到E更短.您可以在A中向D 2.0明确添加依赖项以强制使用D 2.0);\n\n    3.2.Dependency management(依赖管理),在3.1的示例中，依赖项直接添加到A，即使它不是由A直接使用。\n        相反，A可以在其dependencyManagement部分中包含D作为依赖项,并直接控制在何时使用D的哪个版本;\n\n    3.3.Dependency scope(依赖范围),下面4点详细讲解;\n\n    3.4.Dependency scope(排除依赖项),如果项目X依赖于项目Y，项目Y依赖于项目Z，则项目X的所有者可以使用\n        exclusion元素将项目Z明确地排除为依赖项;\n\n    3.5.Optional dependencies(可选择的依赖项),如果项目Y依赖于项目Z，项目Y的所有者可以使用optional元素\n        将项目Z标记为可选依赖项。当项目X依赖于项目Y时，X将仅依赖于Y而不依赖于Y的可选依赖项Z.项目X的所有者可以\n        在她的选项中明确地添加对Z的依赖性;\n\nMaven提供dependency:analyze插件,可以帮助最佳实现依赖机制.\n\n### 7.4:Dependency scope(依赖范围)\n\n    依赖关系范围用于限制依赖关系的传递性，还用于影响用于各种构建任务的类路径。包含六个范围:\n        4.1.compile,默认范围,编译依赖项在项目的所有类路径中都可用,这些依赖项将传播到其他依赖项目。\n\n        4.2.provided,和compile很相似,但是但表示您希望JDK或容器在运行时提供依赖项。例如，在为Java\n            Enterprise Edition构建Web应用程序时，您可以将Servlet API和相关Java EE API的依赖关系设置\n            为提供的范围，因为Web容器提供了这些类。此范围仅在编译和测试类路径中可用，并且不可传递。\n\n        4.3.runtime,此范围表示编译不需要依赖项，但是用于执行。它位于运行时和测试类路径中，但不是编译类路径。\n            可执行不需要编译的依赖\n\n        4.4.test,测试编译和执行的依赖,依赖不传递\n\n        4.5.system,和provided很相似只是您必须提供明确包含它的JAR。可以使用但是不能在库中找到\n\n        4.6.import,仅在POM.xml中引入<dependencyManagement>元素才支持此作用域。并且一旦标注为import,就不参与传递依赖\n            每个依赖范围（import除外）以不同方式影响传递依赖性，如下表所示。如果依赖项设置为左列中的作用域，则该依赖项与顶行\n            中作用域的传递依赖性将导致主项目中的依赖项，并在交集处列出作用域。如果未列出范围，则表示将省略依赖关系。\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-BWzXa9rA-1576392504689)(https://images.gitee.com/uploads/images/2019/0202/135822_124ff85b_1635774.png \"[EF5RN$22FD@[FBW%9O7P]Y.png\")]\n\n### 7.5:Dependency Management(依赖管理)\n\n    5.1.集中依赖信息管理,官方图示来说明其机制:两个扩展同一父级的POM\n    项目A共同依赖group-a,但是第一个依赖排除对grouo-c的依赖,依赖于artifact-a模块,第二个依赖是group-a下的artifact-b\n\n![项目A](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDE1MjlfZTNhNzYwNTlfMTYzNTc3NC5wbmc?x-oss-process=image/format,png)\n    \n\n    项目B,第一个依赖grouo-c下的artifact-b,第二个依赖是group-a下的artifact-b\n![项目B](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDE4MjFfODA2YTUyY2ZfMTYzNTc3NC5wbmc?x-oss-process=image/format,png)\n\n    用依赖管理<dependencyManagement>放在其父级项目POM.xml\n\n![父项目](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDI1NDBfNjliOGNmOTVfMTYzNTc3NC5wbmc?x-oss-process=image/format,png)\n\n    两个子项目的配置就会简单很多\n\n![简化之后的配置](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIxNC8xMjU3MTJfOTRjNDg0NzRfMTYzNTc3NC5wbmc?x-oss-process=image/format,png)\n\n    注意:其中子项目用Dependency Management之后需要指明<type>的类型,因为Dependency Management\n    只针对{groupId, artifactId, type, classifier}为最小单位进行依赖管理\n    \n    5.2.还有个重要的特性就是模块版本控制上面,并且依赖管理的依赖级别是:dependency management>transitive dependencies除了继承依赖传递,还可以通过<import>来导入依赖,在较大的项目中比较实用,并且讲究谁先申明谁且本身pom并未申明版本号,就引用第一个申明的版本号作为当前的版本号.\n\n### 7.6:System Dependencies(系统依赖,已经弃用)\n\n**本文的maven记录在github地址:[https://github.com/ArnoldShu/Maven-learnning](https://github.com/ArnoldShu/Maven-learnning)\n本文的maven记录在gitee地址:[https://gitee.com/ArnoldSu/Maven-learnning](https://gitee.com/ArnoldSu/Maven-learnning)\n个人blog地址:[http://www.bestarnold.com](http://www.bestarnold.com)**\n[本文CSDN链接地址](https://blog.csdn.net/qq_20340547/article/details/103547879)","source":"_posts/summary/2019-12-15.md","raw":"---\ntitle: Maven学习浅记-常用命令及相关概念\ndate: 2019-12-15 15:14:01\ntags: maven\ncategories: 日常总结\n---\nMaven学习浅记-常用命令及相关概念\n<!--more-->\n## 1:Maven官网(官方文档是学习工具的最好参考书)\n\n   [ http://maven.apache.org](http://maven.apache.org)\n\n## 2:maven官网定义\n  官方解释：Apache Maven is a software project management and comprehension tool.\n  Based on the concept of a project object model (POM),Maven can manage a project's build,\n  reporting and documentation from a central piece of information\n  (Apache Maven是一个软件项目管理和理解工具。基于项目对象模型（POM）的概念，Maven可以从一个中心信息管理项目的构建，报告和文档)\n  \n  我目前所用到的Maven的主要作用就是:\n  \n    1:添加第三方jar包;\n    2:jar包之间的依赖关系;\n    3:获取第三方jar包；\n    4:将整个项目拆分成多个工程模块;\n    5：部署，测试报告;\n但是maven是一个强大工具(远远不止我提到的这几个基础的功能,其中就包含项目的构建，报告和文档,官方解释地址:https://maven.apache.org/maven-features.html;\n\n## 3:Maven下载地址\n\n [https://maven.apache.org/download.cgi](https://maven.apache.org/download.cgi)\n\n## 4:maven安装\n###  **4.1:解压部署Maven核心程序** \n\n\t①检查JAVA_HOME环境变量\n\t\t首先确保你的JDK已经正确安装;\n\t②解压Maven的核心程序\n\t\t将apache-maven-3.5.3-bin.zip(在项目中以上传元安装包)解压到一个非中文无空格的目录下。例如：D:\\DevInstall\\apache-maven-3.5.3\n\t③配置环境变量\n\t\tM2_HOME D:\\DevInstall\\apache-maven-3.5.3\n\t\tpath\tD:\\DevInstall\\apache-maven-3.5.3\\bin\n\t④查看Maven版本信息验证安装是否正确\n\tC:\\Windows\\System32>mvn -v\n        Apache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-25T03:49:05+08:00)\n        Maven home: D:\\Maven\\apache-maven-3.5.3\\bin\\..\n        Java version: 1.8.0_131, vendor: Oracle Corporation\n        Java home: D:\\Program Files\\Java\\jdk1.8.0_131\\jre\n        Default locale: zh_CN, platform encoding: GBK\n        OS name: \"windows 10\", version: \"10.0\", arch: \"amd64\", family: \"windows\"\n\n### 4.2:修改本地仓库\n\n\t①默认本地仓库位置：~\\.m2\\repository,~表示当前用户的家目录，例如：C:\\Users\\[你当前登录系统的用户名]\n\t②指定本地仓库位置的配置信息文件：apache-maven-3.5.3\\conf\\settings.xml\n\t③在根标签settings下添加如下内容：<localRepository>[本地仓库路径，也就是RepMaven.zip的解压目录]</localRepository>\n\n## 5:官网五分钟教程\n### 5.1:保证安装好Maven(参考本文4:maven安装)\n\n\n### 5.2:首先你要知道Maven的一个项目结构\n\n    my-app\n    |-- pom.xml project's Project Object Model, or POM. 项目对象模型文件\n    |-- src\n        |-- main\n            |-- java\tApplication/Library sources 应用程序/库源\n            |-- resources   Application/Library resources 应用程序/库资源\n            |-- filters   Resource filter files 资源过滤文件\n            |-- webapp   Web application sources Web应用程序源\n        |-- test\n            |--java Test sources 测试来源\n            |--resources Test sources 测试资源\n            |--filters Test resource filter files 测试资源过滤器文件\n        |--it Integration Tests (primarily for plugins) 集成测试（主要用于插件）\n        |--assembly Assembly descriptors 程序装配集成描述\n        |--site Site\n    LICENSE.txt\tProject's license 项目许可证\n    NOTICE.txt\tNotices and attributions required by libraries that the project depends on 项目依赖的库和其他注意的问题\n    README.txt 项目提要\n\n### 5.3:在建成你的项目之后,一定记住拷贝一份官方的pom.xml放到其指定的位置\n\neg:pom.xml\n\n\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n     xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n     <modelVersion>4.0.0</modelVersion>\n\n     <groupId>com.mycompany.app</groupId>\n     <artifactId>my-app</artifactId>\n     <version>1.0-SNAPSHOT</version>\n\n     <properties>\n       <maven.compiler.source>1.7</maven.compiler.source>\n       <maven.compiler.target>1.7</maven.compiler.target>\n     </properties>\n\n     <dependencies>\n       <dependency>\n         <groupId>junit</groupId>\n         <artifactId>junit</artifactId>\n         <version>4.12</version>\n         <scope>test</scope>\n       </dependency>\n     </dependencies>\n   </project>\n```\n\n\n该项目的POM目录下打开命令行窗口执行一段shell脚本:\n`mvn archetype:generate -DgroupId=com.mycompany.app -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false`\n第一次运行可能会花销一些时间下载很多maven依赖的包\n\n### 5.4.POM文件的关键元素解释:\n\n```\n    <project> This is the top-level element in all Maven pom.xml files. \n    (maven项目中最高级别的的pom.xml文件元素节点)\n\n    <modelVersion> This element indicates what version of the object model this POM \n    is using.The version of the model itself changes very infrequently but it is mandatory\n    in order to ensure stability of use if and when the Maven developers deem it necessary\n    to change the model.(工程对象模型的版本号,不经常改变但是开发者可以根据需要改变,存在就是为了确保项目的稳定性)\n\n    <groupId> This element indicates the unique identifier of the organization or group\n    that created the project.The groupId is one of the key identifiers of a project and\n    is typically based on the fully qualified domain name of your organization.For example\n    org.apache.maven.plugins is the designated groupId for all Maven plugins.\n    (创建项目的组织或者组的唯一标识符,一般都是用组织的全限定域名)\n\n    <artifactId> This element indicates the unique base name of the primary artifact being\n    generated by this project.The primary artifact for a project is typically a JAR file.\n    Secondary artifacts like source bundles also use the artifactId as part of their final name.\n    A typical artifact produced by Maven would have the form <artifactId>-<version>.<extension> \n    (for example, myapp-1.0.jar).\n    (由项目生成的唯一主要工件的基本名称(模块名称),主要比如我们打包的时候的生成的包名)\n\n    <packaging> This element indicates the package type to be used by this artifact \n    (e.g. JAR, WAR, EAR, etc.).This not only means if the artifact produced is JAR, WAR,\n    or EAR but can also indicate a specific lifecycle to use as part of the build process.\n    (The lifecycle is a topic we will deal with further on in the guide. For now, just keep\n    in mind that the indicated packaging of a project can play a part in customizing the build\n    lifecycle.) The default value for the packaging element is JAR so you do not have to specify\n    this for most projects.(就是我们打包的类型,eg: jar包,war包.ear包,默认是jarb包)\n\n    <version> This element indicates the version of the artifact generated by the project.\n    Maven goes a long way to help you with version management and you will often see the SNAPSHOT\n    designator in a version,which indicates that a project is in a state of development. We will\n    discuss the use of snapshots and how they work further on in this guide.\n    (由项目生成的工件版本号,有很多版本:eg SNAPSHOT)\n\n    <name> This element indicates the display name used for the project. This is often used\n    in Maven's generated documentation.(项目的显示名称)\n\n    <url> This element indicates where the project's site can be found. This is often used in Maven's\n    generated documentation.(项目的站点位置地址)\n\n    <description> This element provides a basic description of your project. This is often used in Maven's\n    generated documentation.(项目的接本基本描述)\n```\n更多POM.xml元素解释描述文档参考地址:[https://maven.apache.org/ref/3.6.0/maven-model/maven.html](https://maven.apache.org/ref/3.6.0/maven-model/maven.html)\n\n## 6:maven常用命令\n### 6.1:Maven的常用命令(*注意：运行Maven命令时一定要进入pom.xml文件所在的目录)演示:\n\n\t    mvn compile\t编译\n        编译的内容命令行展示窗口展示内容\n        [WARNING]\n        [WARNING] Some problems were encountered while building the effective settings\n        [WARNING] Unrecognised tag: 'mirrors' (position: START_TAG seen ...</mirror>\\n-->\\n\\t \\n<mirrors>... @160:14)    \n        @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n        [WARNING]\n        [INFO] Scanning for projects...\n        [INFO]\n        [INFO] --------------------------< maven_3:maven_3 >---------------------------\n        [INFO] Building maven_3 1.0-SNAPSHOT\n        [INFO] --------------------------------[ jar ]---------------------------------\n        Downloading from central: https://repo.maven.apache.org/maven2/junit/junit/4.0/junit-4.0.pom\n        Downloaded from central: https://repo.maven.apache.org/maven2/junit/junit/4.0/junit-4.0.pom (210 B at 129 B/s)\n        [INFO]\n        [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ maven_3 ---\n        [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n        [INFO] Copying 1 resource\n        [INFO]\n        [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ maven_3 ---\n        [INFO] Changes detected - recompiling the module!\n        [WARNING] File encoding has not been set, using platform encoding GBK, i.e. build is platform dependent!\n        [INFO] Compiling 1 source file to D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\\classes\n        [INFO] ------------------------------------------------------------------------\n        [INFO] BUILD SUCCESS\n        [INFO] ------------------------------------------------------------------------\n        [INFO] Total time: 7.092 s\n        [INFO] Finished at: 2019-02-01T10:37:11+08:00\n        [INFO] ------------------------------------------------------------------------\n\n        mvn clean\t清理\n        [WARNING]\n        [WARNING] Some problems were encountered while building the effective settings\n        [WARNING] Unrecognised tag: 'mirrors' (position: START_TAG seen ...</mirror>\\n-->\\n\\t \\n<mirrors>... @160:14)      \n        @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n        [WARNING]\n        [INFO] Scanning for projects...\n        [INFO]\n        [INFO] --------------------------< maven_3:maven_3 >---------------------------\n        [INFO] Building maven_3 1.0-SNAPSHOT\n        [INFO] --------------------------------[ jar ]---------------------------------\n        [INFO]\n        [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ maven_3 ---\n        [INFO] Deleting D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\n        [INFO] ------------------------------------------------------------------------\n        [INFO] BUILD SUCCESS\n        [INFO] ------------------------------------------------------------------------\n        [INFO] Total time: 0.572 s\n        [INFO] Finished at: 2019-02-01T11:55:52+08:00\n        [INFO] ------------------------------------------------------------------------\n\n        mvn test\t测试\n        [WARNING]\n        [WARNING] Some problems were encountered while building the effective settings\n        [WARNING] Unrecognised tag: 'mirrors' (position: START_TAG seen ...</mirror>\\n-->\\n\\t \\n<mirrors>... @160:14)      \n        @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n        [WARNING]\n        [INFO] Scanning for projects...\n        [INFO]\n        [INFO] --------------------------< maven_3:maven_3 >---------------------------\n        [INFO] Building maven_3 1.0-SNAPSHOT\n        [INFO] --------------------------------[ jar ]---------------------------------\n        [INFO]\n        [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ maven_3 ---\n        [INFO] Deleting D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\n        [INFO] ------------------------------------------------------------------------\n        [INFO] BUILD SUCCESS\n        [INFO] ------------------------------------------------------------------------\n        [INFO] Total time: 0.572 s\n        [INFO] Finished at: 2019-02-01T11:55:52+08:00\n        [INFO] ------------------------------------------------------------------------\n\n        mvn package\t打包\n        打包的内容命令行展示窗口展示内容\n        [WARNING]\n        [WARNING] Some problems were encountered while building the effective settings\n        [WARNING] Unrecognised tag: 'mirrors' (position: START_TAG seen ...</mirror>\\n-->\\n\\t\\n<mirrors>...         \n        @160:14)  @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n        [WARNING]\n        [INFO] Scanning for projects...\n        [INFO]\n        [INFO] --------------------------< maven_3:maven_3 >---------------------------\n        [INFO] Building maven_3 1.0-SNAPSHOT\n        [INFO] --------------------------------[ jar ]---------------------------------\n        [INFO]\n        [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ maven_3 ---\n        [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n        [INFO] Copying 1 resource\n        [INFO]\n        [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ maven_3 ---\n        [INFO] Nothing to compile - all classes are up to date\n        [INFO]\n        [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ maven_3 ---\n        [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n        [INFO] skip non existing resourceDirectory D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\src\\test\\resources\n        [INFO]\n        [INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ maven_3 ---\n        [INFO] Nothing to compile - all classes are up to date\n        [INFO]\n        [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ maven_3 ---\n        [INFO] Surefire report directory: D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\\surefire-reports\n\n        -------------------------------------------------------\n         T E S T S\n        -------------------------------------------------------\n        Running com.boommob.www.HelloWorldTest\n        Hello litingwei!Hello litingwei!\n        Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.176 sec\n        Results :\n\n        Tests run: 1, Failures: 0, Errors: 0, Skipped: 0\n\n        [INFO]\n        [INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ maven_3 ---\n        [INFO] ------------------------------------------------------------------------\n        [INFO] BUILD SUCCESS\n        [INFO] ------------------------------------------------------------------------\n        [INFO] Total time: 4.588 s\n        [INFO] Finished at: 2019-02-01T10:57:07+08:00\n        [INFO] ------------------------------------------------------------------------\n\n \n\n### 6.2:在执行完相应的maven命令之后会在该项目的路径下生成target文件夹:\n     target\n         |-- classes 编译之后的类文件\n         |-- maven-archeiver maven打包时候生成的得一个工程对象模型属性文件里面记载的是该项目的POM.xml的一些相关属性\n         |-- maven-status maven状态,一些maven编译的插件信息\n         |-- surefire-reports maven打包生成的一个报告,测试报告\n         |-- test-classes 编译之后的测试类文件\n\n## 7:maven依赖\n\n### 7.1:首先项目POM.xml添加本文6:maven常用命令的依赖,这是我们本地库的一个模块依赖,如果直接在命令行直接执行:mvn compile 的话会报错, 此处需要先在6:maven常用命令的步骤上执行mvn install,将模块安装到本地,在结合maven依赖进行编译.\n\n### 7.2:POM.xml元素解释\n\ndependencies:(Many) This element describes all of the dependencies associated with a project.\nThese dependencies are used to construct a classpath for your project during the build process.\nThey are automatically downloaded from the repositories defined in this project.See the dependency mechanism for more information.\n(此元素描述与项目关联的所有依赖项。这些依赖项用于在构建过程中为项目构造类路径。它们会自动从此项目中定义的存储库下载,参考依赖机制:https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html);\n\n### 7.3:Dependency Mechanism(依赖机制)\n    3.1.Transitive Dependencies(传递依赖)\n        Dependency mediation(依赖调解),多个版本依赖项nearest definition\n        (最近定义原则:表示所使用的版本将是依赖关系树中与项目最接近的版本。例如，如果A，B和C\n        的依赖关系定义为A - > B - > C - > D 2.0和A - > E - > D 1.0，则构建A时将使用D 1.0,\n        因为A的路径到D到E更短.您可以在A中向D 2.0明确添加依赖项以强制使用D 2.0);\n\n    3.2.Dependency management(依赖管理),在3.1的示例中，依赖项直接添加到A，即使它不是由A直接使用。\n        相反，A可以在其dependencyManagement部分中包含D作为依赖项,并直接控制在何时使用D的哪个版本;\n\n    3.3.Dependency scope(依赖范围),下面4点详细讲解;\n\n    3.4.Dependency scope(排除依赖项),如果项目X依赖于项目Y，项目Y依赖于项目Z，则项目X的所有者可以使用\n        exclusion元素将项目Z明确地排除为依赖项;\n\n    3.5.Optional dependencies(可选择的依赖项),如果项目Y依赖于项目Z，项目Y的所有者可以使用optional元素\n        将项目Z标记为可选依赖项。当项目X依赖于项目Y时，X将仅依赖于Y而不依赖于Y的可选依赖项Z.项目X的所有者可以\n        在她的选项中明确地添加对Z的依赖性;\n\nMaven提供dependency:analyze插件,可以帮助最佳实现依赖机制.\n\n### 7.4:Dependency scope(依赖范围)\n\n    依赖关系范围用于限制依赖关系的传递性，还用于影响用于各种构建任务的类路径。包含六个范围:\n        4.1.compile,默认范围,编译依赖项在项目的所有类路径中都可用,这些依赖项将传播到其他依赖项目。\n\n        4.2.provided,和compile很相似,但是但表示您希望JDK或容器在运行时提供依赖项。例如，在为Java\n            Enterprise Edition构建Web应用程序时，您可以将Servlet API和相关Java EE API的依赖关系设置\n            为提供的范围，因为Web容器提供了这些类。此范围仅在编译和测试类路径中可用，并且不可传递。\n\n        4.3.runtime,此范围表示编译不需要依赖项，但是用于执行。它位于运行时和测试类路径中，但不是编译类路径。\n            可执行不需要编译的依赖\n\n        4.4.test,测试编译和执行的依赖,依赖不传递\n\n        4.5.system,和provided很相似只是您必须提供明确包含它的JAR。可以使用但是不能在库中找到\n\n        4.6.import,仅在POM.xml中引入<dependencyManagement>元素才支持此作用域。并且一旦标注为import,就不参与传递依赖\n            每个依赖范围（import除外）以不同方式影响传递依赖性，如下表所示。如果依赖项设置为左列中的作用域，则该依赖项与顶行\n            中作用域的传递依赖性将导致主项目中的依赖项，并在交集处列出作用域。如果未列出范围，则表示将省略依赖关系。\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-BWzXa9rA-1576392504689)(https://images.gitee.com/uploads/images/2019/0202/135822_124ff85b_1635774.png \"[EF5RN$22FD@[FBW%9O7P]Y.png\")]\n\n### 7.5:Dependency Management(依赖管理)\n\n    5.1.集中依赖信息管理,官方图示来说明其机制:两个扩展同一父级的POM\n    项目A共同依赖group-a,但是第一个依赖排除对grouo-c的依赖,依赖于artifact-a模块,第二个依赖是group-a下的artifact-b\n\n![项目A](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDE1MjlfZTNhNzYwNTlfMTYzNTc3NC5wbmc?x-oss-process=image/format,png)\n    \n\n    项目B,第一个依赖grouo-c下的artifact-b,第二个依赖是group-a下的artifact-b\n![项目B](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDE4MjFfODA2YTUyY2ZfMTYzNTc3NC5wbmc?x-oss-process=image/format,png)\n\n    用依赖管理<dependencyManagement>放在其父级项目POM.xml\n\n![父项目](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDI1NDBfNjliOGNmOTVfMTYzNTc3NC5wbmc?x-oss-process=image/format,png)\n\n    两个子项目的配置就会简单很多\n\n![简化之后的配置](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIxNC8xMjU3MTJfOTRjNDg0NzRfMTYzNTc3NC5wbmc?x-oss-process=image/format,png)\n\n    注意:其中子项目用Dependency Management之后需要指明<type>的类型,因为Dependency Management\n    只针对{groupId, artifactId, type, classifier}为最小单位进行依赖管理\n    \n    5.2.还有个重要的特性就是模块版本控制上面,并且依赖管理的依赖级别是:dependency management>transitive dependencies除了继承依赖传递,还可以通过<import>来导入依赖,在较大的项目中比较实用,并且讲究谁先申明谁且本身pom并未申明版本号,就引用第一个申明的版本号作为当前的版本号.\n\n### 7.6:System Dependencies(系统依赖,已经弃用)\n\n**本文的maven记录在github地址:[https://github.com/ArnoldShu/Maven-learnning](https://github.com/ArnoldShu/Maven-learnning)\n本文的maven记录在gitee地址:[https://gitee.com/ArnoldSu/Maven-learnning](https://gitee.com/ArnoldSu/Maven-learnning)\n个人blog地址:[http://www.bestarnold.com](http://www.bestarnold.com)**\n[本文CSDN链接地址](https://blog.csdn.net/qq_20340547/article/details/103547879)","slug":"summary/2019-12-15","published":1,"updated":"2019-12-15T07:34:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue2n001fbcvzgica4yxb","content":"<p>Maven学习浅记-常用命令及相关概念</p>\n<a id=\"more\"></a>\n<h2 id=\"1-Maven官网-官方文档是学习工具的最好参考书\"><a href=\"#1-Maven官网-官方文档是学习工具的最好参考书\" class=\"headerlink\" title=\"1:Maven官网(官方文档是学习工具的最好参考书)\"></a>1:Maven官网(官方文档是学习工具的最好参考书)</h2><p>   <a href=\"http://maven.apache.org/\"> http://maven.apache.org</a></p>\n<h2 id=\"2-maven官网定义\"><a href=\"#2-maven官网定义\" class=\"headerlink\" title=\"2:maven官网定义\"></a>2:maven官网定义</h2><p>  官方解释：Apache Maven is a software project management and comprehension tool.<br>  Based on the concept of a project object model (POM),Maven can manage a project’s build,<br>  reporting and documentation from a central piece of information<br>  (Apache Maven是一个软件项目管理和理解工具。基于项目对象模型（POM）的概念，Maven可以从一个中心信息管理项目的构建，报告和文档)</p>\n<p>  我目前所用到的Maven的主要作用就是:</p>\n<pre><code>1:添加第三方jar包;\n2:jar包之间的依赖关系;\n3:获取第三方jar包；\n4:将整个项目拆分成多个工程模块;\n5：部署，测试报告;</code></pre>\n<p>但是maven是一个强大工具(远远不止我提到的这几个基础的功能,其中就包含项目的构建，报告和文档,官方解释地址:<a href=\"https://maven.apache.org/maven-features.html\">https://maven.apache.org/maven-features.html</a>;</p>\n<h2 id=\"3-Maven下载地址\"><a href=\"#3-Maven下载地址\" class=\"headerlink\" title=\"3:Maven下载地址\"></a>3:Maven下载地址</h2><p> <a href=\"https://maven.apache.org/download.cgi\">https://maven.apache.org/download.cgi</a></p>\n<h2 id=\"4-maven安装\"><a href=\"#4-maven安装\" class=\"headerlink\" title=\"4:maven安装\"></a>4:maven安装</h2><h3 id=\"4-1-解压部署Maven核心程序\"><a href=\"#4-1-解压部署Maven核心程序\" class=\"headerlink\" title=\"4.1:解压部署Maven核心程序\"></a><strong>4.1:解压部署Maven核心程序</strong></h3><pre><code>①检查JAVA_HOME环境变量\n    首先确保你的JDK已经正确安装;\n②解压Maven的核心程序\n    将apache-maven-3.5.3-bin.zip(在项目中以上传元安装包)解压到一个非中文无空格的目录下。例如：D:\\DevInstall\\apache-maven-3.5.3\n③配置环境变量\n    M2_HOME D:\\DevInstall\\apache-maven-3.5.3\n    path    D:\\DevInstall\\apache-maven-3.5.3\\bin\n④查看Maven版本信息验证安装是否正确\nC:\\Windows\\System32&gt;mvn -v\n    Apache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-25T03:49:05+08:00)\n    Maven home: D:\\Maven\\apache-maven-3.5.3\\bin\\..\n    Java version: 1.8.0_131, vendor: Oracle Corporation\n    Java home: D:\\Program Files\\Java\\jdk1.8.0_131\\jre\n    Default locale: zh_CN, platform encoding: GBK\n    OS name: &quot;windows 10&quot;, version: &quot;10.0&quot;, arch: &quot;amd64&quot;, family: &quot;windows&quot;</code></pre>\n<h3 id=\"4-2-修改本地仓库\"><a href=\"#4-2-修改本地仓库\" class=\"headerlink\" title=\"4.2:修改本地仓库\"></a>4.2:修改本地仓库</h3><pre><code>①默认本地仓库位置：~\\.m2\\repository,~表示当前用户的家目录，例如：C:\\Users\\[你当前登录系统的用户名]\n②指定本地仓库位置的配置信息文件：apache-maven-3.5.3\\conf\\settings.xml\n③在根标签settings下添加如下内容：&lt;localRepository&gt;[本地仓库路径，也就是RepMaven.zip的解压目录]&lt;/localRepository&gt;</code></pre>\n<h2 id=\"5-官网五分钟教程\"><a href=\"#5-官网五分钟教程\" class=\"headerlink\" title=\"5:官网五分钟教程\"></a>5:官网五分钟教程</h2><h3 id=\"5-1-保证安装好Maven-参考本文4-maven安装\"><a href=\"#5-1-保证安装好Maven-参考本文4-maven安装\" class=\"headerlink\" title=\"5.1:保证安装好Maven(参考本文4:maven安装)\"></a>5.1:保证安装好Maven(参考本文4:maven安装)</h3><h3 id=\"5-2-首先你要知道Maven的一个项目结构\"><a href=\"#5-2-首先你要知道Maven的一个项目结构\" class=\"headerlink\" title=\"5.2:首先你要知道Maven的一个项目结构\"></a>5.2:首先你要知道Maven的一个项目结构</h3><pre><code>my-app\n|-- pom.xml project&#39;s Project Object Model, or POM. 项目对象模型文件\n|-- src\n    |-- main\n        |-- java    Application/Library sources 应用程序/库源\n        |-- resources   Application/Library resources 应用程序/库资源\n        |-- filters   Resource filter files 资源过滤文件\n        |-- webapp   Web application sources Web应用程序源\n    |-- test\n        |--java Test sources 测试来源\n        |--resources Test sources 测试资源\n        |--filters Test resource filter files 测试资源过滤器文件\n    |--it Integration Tests (primarily for plugins) 集成测试（主要用于插件）\n    |--assembly Assembly descriptors 程序装配集成描述\n    |--site Site\nLICENSE.txt    Project&#39;s license 项目许可证\nNOTICE.txt    Notices and attributions required by libraries that the project depends on 项目依赖的库和其他注意的问题\nREADME.txt 项目提要</code></pre>\n<h3 id=\"5-3-在建成你的项目之后-一定记住拷贝一份官方的pom-xml放到其指定的位置\"><a href=\"#5-3-在建成你的项目之后-一定记住拷贝一份官方的pom-xml放到其指定的位置\" class=\"headerlink\" title=\"5.3:在建成你的项目之后,一定记住拷贝一份官方的pom.xml放到其指定的位置\"></a>5.3:在建成你的项目之后,一定记住拷贝一份官方的pom.xml放到其指定的位置</h3><p>eg:pom.xml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class=\"line\">     xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt;</span><br><span class=\"line\">     &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">     &lt;groupId&gt;com.mycompany.app&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">     &lt;artifactId&gt;my-app&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">     &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">     &lt;properties&gt;</span><br><span class=\"line\">       &lt;maven.compiler.source&gt;1.7&lt;&#x2F;maven.compiler.source&gt;</span><br><span class=\"line\">       &lt;maven.compiler.target&gt;1.7&lt;&#x2F;maven.compiler.target&gt;</span><br><span class=\"line\">     &lt;&#x2F;properties&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">     &lt;dependencies&gt;</span><br><span class=\"line\">       &lt;dependency&gt;</span><br><span class=\"line\">         &lt;groupId&gt;junit&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">         &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">         &lt;version&gt;4.12&lt;&#x2F;version&gt;</span><br><span class=\"line\">         &lt;scope&gt;test&lt;&#x2F;scope&gt;</span><br><span class=\"line\">       &lt;&#x2F;dependency&gt;</span><br><span class=\"line\">     &lt;&#x2F;dependencies&gt;</span><br><span class=\"line\">   &lt;&#x2F;project&gt;</span><br></pre></td></tr></table></figure>\n\n\n<p>该项目的POM目录下打开命令行窗口执行一段shell脚本:<br><code>mvn archetype:generate -DgroupId=com.mycompany.app -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false</code><br>第一次运行可能会花销一些时间下载很多maven依赖的包</p>\n<h3 id=\"5-4-POM文件的关键元素解释\"><a href=\"#5-4-POM文件的关键元素解释\" class=\"headerlink\" title=\"5.4.POM文件的关键元素解释:\"></a>5.4.POM文件的关键元素解释:</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;project&gt; This is the top-level element in all Maven pom.xml files. </span><br><span class=\"line\">(maven项目中最高级别的的pom.xml文件元素节点)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;modelVersion&gt; This element indicates what version of the object model this POM </span><br><span class=\"line\">is using.The version of the model itself changes very infrequently but it is mandatory</span><br><span class=\"line\">in order to ensure stability of use if and when the Maven developers deem it necessary</span><br><span class=\"line\">to change the model.(工程对象模型的版本号,不经常改变但是开发者可以根据需要改变,存在就是为了确保项目的稳定性)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;groupId&gt; This element indicates the unique identifier of the organization or group</span><br><span class=\"line\">that created the project.The groupId is one of the key identifiers of a project and</span><br><span class=\"line\">is typically based on the fully qualified domain name of your organization.For example</span><br><span class=\"line\">org.apache.maven.plugins is the designated groupId for all Maven plugins.</span><br><span class=\"line\">(创建项目的组织或者组的唯一标识符,一般都是用组织的全限定域名)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;artifactId&gt; This element indicates the unique base name of the primary artifact being</span><br><span class=\"line\">generated by this project.The primary artifact for a project is typically a JAR file.</span><br><span class=\"line\">Secondary artifacts like source bundles also use the artifactId as part of their final name.</span><br><span class=\"line\">A typical artifact produced by Maven would have the form &lt;artifactId&gt;-&lt;version&gt;.&lt;extension&gt; </span><br><span class=\"line\">(for example, myapp-1.0.jar).</span><br><span class=\"line\">(由项目生成的唯一主要工件的基本名称(模块名称),主要比如我们打包的时候的生成的包名)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;packaging&gt; This element indicates the package type to be used by this artifact </span><br><span class=\"line\">(e.g. JAR, WAR, EAR, etc.).This not only means if the artifact produced is JAR, WAR,</span><br><span class=\"line\">or EAR but can also indicate a specific lifecycle to use as part of the build process.</span><br><span class=\"line\">(The lifecycle is a topic we will deal with further on in the guide. For now, just keep</span><br><span class=\"line\">in mind that the indicated packaging of a project can play a part in customizing the build</span><br><span class=\"line\">lifecycle.) The default value for the packaging element is JAR so you do not have to specify</span><br><span class=\"line\">this for most projects.(就是我们打包的类型,eg: jar包,war包.ear包,默认是jarb包)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;version&gt; This element indicates the version of the artifact generated by the project.</span><br><span class=\"line\">Maven goes a long way to help you with version management and you will often see the SNAPSHOT</span><br><span class=\"line\">designator in a version,which indicates that a project is in a state of development. We will</span><br><span class=\"line\">discuss the use of snapshots and how they work further on in this guide.</span><br><span class=\"line\">(由项目生成的工件版本号,有很多版本:eg SNAPSHOT)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;name&gt; This element indicates the display name used for the project. This is often used</span><br><span class=\"line\">in Maven&#39;s generated documentation.(项目的显示名称)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;url&gt; This element indicates where the project&#39;s site can be found. This is often used in Maven&#39;s</span><br><span class=\"line\">generated documentation.(项目的站点位置地址)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;description&gt; This element provides a basic description of your project. This is often used in Maven&#39;s</span><br><span class=\"line\">generated documentation.(项目的接本基本描述)</span><br></pre></td></tr></table></figure>\n<p>更多POM.xml元素解释描述文档参考地址:<a href=\"https://maven.apache.org/ref/3.6.0/maven-model/maven.html\">https://maven.apache.org/ref/3.6.0/maven-model/maven.html</a></p>\n<h2 id=\"6-maven常用命令\"><a href=\"#6-maven常用命令\" class=\"headerlink\" title=\"6:maven常用命令\"></a>6:maven常用命令</h2><h3 id=\"6-1-Maven的常用命令-注意：运行Maven命令时一定要进入pom-xml文件所在的目录-演示\"><a href=\"#6-1-Maven的常用命令-注意：运行Maven命令时一定要进入pom-xml文件所在的目录-演示\" class=\"headerlink\" title=\"6.1:Maven的常用命令(*注意：运行Maven命令时一定要进入pom.xml文件所在的目录)演示:\"></a>6.1:Maven的常用命令(*注意：运行Maven命令时一定要进入pom.xml文件所在的目录)演示:</h3><pre><code>    mvn compile    编译\n    编译的内容命令行展示窗口展示内容\n    [WARNING]\n    [WARNING] Some problems were encountered while building the effective settings\n    [WARNING] Unrecognised tag: &#39;mirrors&#39; (position: START_TAG seen ...&lt;/mirror&gt;\\n--&gt;\\n\\t \\n&lt;mirrors&gt;... @160:14)    \n    @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n    [WARNING]\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] --------------------------&lt; maven_3:maven_3 &gt;---------------------------\n    [INFO] Building maven_3 1.0-SNAPSHOT\n    [INFO] --------------------------------[ jar ]---------------------------------\n    Downloading from central: https://repo.maven.apache.org/maven2/junit/junit/4.0/junit-4.0.pom\n    Downloaded from central: https://repo.maven.apache.org/maven2/junit/junit/4.0/junit-4.0.pom (210 B at 129 B/s)\n    [INFO]\n    [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ maven_3 ---\n    [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n    [INFO] Copying 1 resource\n    [INFO]\n    [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ maven_3 ---\n    [INFO] Changes detected - recompiling the module!\n    [WARNING] File encoding has not been set, using platform encoding GBK, i.e. build is platform dependent!\n    [INFO] Compiling 1 source file to D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\\classes\n    [INFO] ------------------------------------------------------------------------\n    [INFO] BUILD SUCCESS\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Total time: 7.092 s\n    [INFO] Finished at: 2019-02-01T10:37:11+08:00\n    [INFO] ------------------------------------------------------------------------\n\n    mvn clean    清理\n    [WARNING]\n    [WARNING] Some problems were encountered while building the effective settings\n    [WARNING] Unrecognised tag: &#39;mirrors&#39; (position: START_TAG seen ...&lt;/mirror&gt;\\n--&gt;\\n\\t \\n&lt;mirrors&gt;... @160:14)      \n    @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n    [WARNING]\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] --------------------------&lt; maven_3:maven_3 &gt;---------------------------\n    [INFO] Building maven_3 1.0-SNAPSHOT\n    [INFO] --------------------------------[ jar ]---------------------------------\n    [INFO]\n    [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ maven_3 ---\n    [INFO] Deleting D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\n    [INFO] ------------------------------------------------------------------------\n    [INFO] BUILD SUCCESS\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Total time: 0.572 s\n    [INFO] Finished at: 2019-02-01T11:55:52+08:00\n    [INFO] ------------------------------------------------------------------------\n\n    mvn test    测试\n    [WARNING]\n    [WARNING] Some problems were encountered while building the effective settings\n    [WARNING] Unrecognised tag: &#39;mirrors&#39; (position: START_TAG seen ...&lt;/mirror&gt;\\n--&gt;\\n\\t \\n&lt;mirrors&gt;... @160:14)      \n    @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n    [WARNING]\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] --------------------------&lt; maven_3:maven_3 &gt;---------------------------\n    [INFO] Building maven_3 1.0-SNAPSHOT\n    [INFO] --------------------------------[ jar ]---------------------------------\n    [INFO]\n    [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ maven_3 ---\n    [INFO] Deleting D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\n    [INFO] ------------------------------------------------------------------------\n    [INFO] BUILD SUCCESS\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Total time: 0.572 s\n    [INFO] Finished at: 2019-02-01T11:55:52+08:00\n    [INFO] ------------------------------------------------------------------------\n\n    mvn package    打包\n    打包的内容命令行展示窗口展示内容\n    [WARNING]\n    [WARNING] Some problems were encountered while building the effective settings\n    [WARNING] Unrecognised tag: &#39;mirrors&#39; (position: START_TAG seen ...&lt;/mirror&gt;\\n--&gt;\\n\\t\\n&lt;mirrors&gt;...         \n    @160:14)  @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n    [WARNING]\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] --------------------------&lt; maven_3:maven_3 &gt;---------------------------\n    [INFO] Building maven_3 1.0-SNAPSHOT\n    [INFO] --------------------------------[ jar ]---------------------------------\n    [INFO]\n    [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ maven_3 ---\n    [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n    [INFO] Copying 1 resource\n    [INFO]\n    [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ maven_3 ---\n    [INFO] Nothing to compile - all classes are up to date\n    [INFO]\n    [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ maven_3 ---\n    [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n    [INFO] skip non existing resourceDirectory D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\src\\test\\resources\n    [INFO]\n    [INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ maven_3 ---\n    [INFO] Nothing to compile - all classes are up to date\n    [INFO]\n    [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ maven_3 ---\n    [INFO] Surefire report directory: D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\\surefire-reports\n\n    -------------------------------------------------------\n     T E S T S\n    -------------------------------------------------------\n    Running com.boommob.www.HelloWorldTest\n    Hello litingwei!Hello litingwei!\n    Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.176 sec\n    Results :\n\n    Tests run: 1, Failures: 0, Errors: 0, Skipped: 0\n\n    [INFO]\n    [INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ maven_3 ---\n    [INFO] ------------------------------------------------------------------------\n    [INFO] BUILD SUCCESS\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Total time: 4.588 s\n    [INFO] Finished at: 2019-02-01T10:57:07+08:00\n    [INFO] ------------------------------------------------------------------------</code></pre>\n<h3 id=\"6-2-在执行完相应的maven命令之后会在该项目的路径下生成target文件夹\"><a href=\"#6-2-在执行完相应的maven命令之后会在该项目的路径下生成target文件夹\" class=\"headerlink\" title=\"6.2:在执行完相应的maven命令之后会在该项目的路径下生成target文件夹:\"></a>6.2:在执行完相应的maven命令之后会在该项目的路径下生成target文件夹:</h3><pre><code> target\n     |-- classes 编译之后的类文件\n     |-- maven-archeiver maven打包时候生成的得一个工程对象模型属性文件里面记载的是该项目的POM.xml的一些相关属性\n     |-- maven-status maven状态,一些maven编译的插件信息\n     |-- surefire-reports maven打包生成的一个报告,测试报告\n     |-- test-classes 编译之后的测试类文件</code></pre>\n<h2 id=\"7-maven依赖\"><a href=\"#7-maven依赖\" class=\"headerlink\" title=\"7:maven依赖\"></a>7:maven依赖</h2><h3 id=\"7-1-首先项目POM-xml添加本文6-maven常用命令的依赖-这是我们本地库的一个模块依赖-如果直接在命令行直接执行-mvn-compile-的话会报错-此处需要先在6-maven常用命令的步骤上执行mvn-install-将模块安装到本地-在结合maven依赖进行编译\"><a href=\"#7-1-首先项目POM-xml添加本文6-maven常用命令的依赖-这是我们本地库的一个模块依赖-如果直接在命令行直接执行-mvn-compile-的话会报错-此处需要先在6-maven常用命令的步骤上执行mvn-install-将模块安装到本地-在结合maven依赖进行编译\" class=\"headerlink\" title=\"7.1:首先项目POM.xml添加本文6:maven常用命令的依赖,这是我们本地库的一个模块依赖,如果直接在命令行直接执行:mvn compile 的话会报错, 此处需要先在6:maven常用命令的步骤上执行mvn install,将模块安装到本地,在结合maven依赖进行编译.\"></a>7.1:首先项目POM.xml添加本文6:maven常用命令的依赖,这是我们本地库的一个模块依赖,如果直接在命令行直接执行:mvn compile 的话会报错, 此处需要先在6:maven常用命令的步骤上执行mvn install,将模块安装到本地,在结合maven依赖进行编译.</h3><h3 id=\"7-2-POM-xml元素解释\"><a href=\"#7-2-POM-xml元素解释\" class=\"headerlink\" title=\"7.2:POM.xml元素解释\"></a>7.2:POM.xml元素解释</h3><p>dependencies:(Many) This element describes all of the dependencies associated with a project.<br>These dependencies are used to construct a classpath for your project during the build process.<br>They are automatically downloaded from the repositories defined in this project.See the dependency mechanism for more information.<br>(此元素描述与项目关联的所有依赖项。这些依赖项用于在构建过程中为项目构造类路径。它们会自动从此项目中定义的存储库下载,参考依赖机制:<a href=\"https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html\">https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html</a>);</p>\n<h3 id=\"7-3-Dependency-Mechanism-依赖机制\"><a href=\"#7-3-Dependency-Mechanism-依赖机制\" class=\"headerlink\" title=\"7.3:Dependency Mechanism(依赖机制)\"></a>7.3:Dependency Mechanism(依赖机制)</h3><pre><code>3.1.Transitive Dependencies(传递依赖)\n    Dependency mediation(依赖调解),多个版本依赖项nearest definition\n    (最近定义原则:表示所使用的版本将是依赖关系树中与项目最接近的版本。例如，如果A，B和C\n    的依赖关系定义为A - &gt; B - &gt; C - &gt; D 2.0和A - &gt; E - &gt; D 1.0，则构建A时将使用D 1.0,\n    因为A的路径到D到E更短.您可以在A中向D 2.0明确添加依赖项以强制使用D 2.0);\n\n3.2.Dependency management(依赖管理),在3.1的示例中，依赖项直接添加到A，即使它不是由A直接使用。\n    相反，A可以在其dependencyManagement部分中包含D作为依赖项,并直接控制在何时使用D的哪个版本;\n\n3.3.Dependency scope(依赖范围),下面4点详细讲解;\n\n3.4.Dependency scope(排除依赖项),如果项目X依赖于项目Y，项目Y依赖于项目Z，则项目X的所有者可以使用\n    exclusion元素将项目Z明确地排除为依赖项;\n\n3.5.Optional dependencies(可选择的依赖项),如果项目Y依赖于项目Z，项目Y的所有者可以使用optional元素\n    将项目Z标记为可选依赖项。当项目X依赖于项目Y时，X将仅依赖于Y而不依赖于Y的可选依赖项Z.项目X的所有者可以\n    在她的选项中明确地添加对Z的依赖性;</code></pre>\n<p>Maven提供dependency:analyze插件,可以帮助最佳实现依赖机制.</p>\n<h3 id=\"7-4-Dependency-scope-依赖范围\"><a href=\"#7-4-Dependency-scope-依赖范围\" class=\"headerlink\" title=\"7.4:Dependency scope(依赖范围)\"></a>7.4:Dependency scope(依赖范围)</h3><pre><code>依赖关系范围用于限制依赖关系的传递性，还用于影响用于各种构建任务的类路径。包含六个范围:\n    4.1.compile,默认范围,编译依赖项在项目的所有类路径中都可用,这些依赖项将传播到其他依赖项目。\n\n    4.2.provided,和compile很相似,但是但表示您希望JDK或容器在运行时提供依赖项。例如，在为Java\n        Enterprise Edition构建Web应用程序时，您可以将Servlet API和相关Java EE API的依赖关系设置\n        为提供的范围，因为Web容器提供了这些类。此范围仅在编译和测试类路径中可用，并且不可传递。\n\n    4.3.runtime,此范围表示编译不需要依赖项，但是用于执行。它位于运行时和测试类路径中，但不是编译类路径。\n        可执行不需要编译的依赖\n\n    4.4.test,测试编译和执行的依赖,依赖不传递\n\n    4.5.system,和provided很相似只是您必须提供明确包含它的JAR。可以使用但是不能在库中找到\n\n    4.6.import,仅在POM.xml中引入&lt;dependencyManagement&gt;元素才支持此作用域。并且一旦标注为import,就不参与传递依赖\n        每个依赖范围（import除外）以不同方式影响传递依赖性，如下表所示。如果依赖项设置为左列中的作用域，则该依赖项与顶行\n        中作用域的传递依赖性将导致主项目中的依赖项，并在交集处列出作用域。如果未列出范围，则表示将省略依赖关系。</code></pre>\n<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-BWzXa9rA-1576392504689)(<a href=\"https://images.gitee.com/uploads/images/2019/0202/135822_124ff85b_1635774.png\">https://images.gitee.com/uploads/images/2019/0202/135822_124ff85b_1635774.png</a> “[EF5RN$22FD@[FBW%9O7P]Y.png”)]</p>\n<h3 id=\"7-5-Dependency-Management-依赖管理\"><a href=\"#7-5-Dependency-Management-依赖管理\" class=\"headerlink\" title=\"7.5:Dependency Management(依赖管理)\"></a>7.5:Dependency Management(依赖管理)</h3><pre><code>5.1.集中依赖信息管理,官方图示来说明其机制:两个扩展同一父级的POM\n项目A共同依赖group-a,但是第一个依赖排除对grouo-c的依赖,依赖于artifact-a模块,第二个依赖是group-a下的artifact-b</code></pre>\n<p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDE1MjlfZTNhNzYwNTlfMTYzNTc3NC5wbmc?x-oss-process=image/format,png\" alt=\"项目A\"></p>\n<pre><code>项目B,第一个依赖grouo-c下的artifact-b,第二个依赖是group-a下的artifact-b</code></pre>\n<p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDE4MjFfODA2YTUyY2ZfMTYzNTc3NC5wbmc?x-oss-process=image/format,png\" alt=\"项目B\"></p>\n<pre><code>用依赖管理&lt;dependencyManagement&gt;放在其父级项目POM.xml</code></pre>\n<p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDI1NDBfNjliOGNmOTVfMTYzNTc3NC5wbmc?x-oss-process=image/format,png\" alt=\"父项目\"></p>\n<pre><code>两个子项目的配置就会简单很多</code></pre>\n<p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIxNC8xMjU3MTJfOTRjNDg0NzRfMTYzNTc3NC5wbmc?x-oss-process=image/format,png\" alt=\"简化之后的配置\"></p>\n<pre><code>注意:其中子项目用Dependency Management之后需要指明&lt;type&gt;的类型,因为Dependency Management\n只针对&#123;groupId, artifactId, type, classifier&#125;为最小单位进行依赖管理\n\n5.2.还有个重要的特性就是模块版本控制上面,并且依赖管理的依赖级别是:dependency management&gt;transitive dependencies除了继承依赖传递,还可以通过&lt;import&gt;来导入依赖,在较大的项目中比较实用,并且讲究谁先申明谁且本身pom并未申明版本号,就引用第一个申明的版本号作为当前的版本号.</code></pre>\n<h3 id=\"7-6-System-Dependencies-系统依赖-已经弃用\"><a href=\"#7-6-System-Dependencies-系统依赖-已经弃用\" class=\"headerlink\" title=\"7.6:System Dependencies(系统依赖,已经弃用)\"></a>7.6:System Dependencies(系统依赖,已经弃用)</h3><p><strong>本文的maven记录在github地址:<a href=\"https://github.com/ArnoldShu/Maven-learnning\">https://github.com/ArnoldShu/Maven-learnning</a><br>本文的maven记录在gitee地址:<a href=\"https://gitee.com/ArnoldSu/Maven-learnning\">https://gitee.com/ArnoldSu/Maven-learnning</a><br>个人blog地址:<a href=\"http://www.bestarnold.com/\">http://www.bestarnold.com</a></strong><br><a href=\"https://blog.csdn.net/qq_20340547/article/details/103547879\">本文CSDN链接地址</a></p>\n","site":{"data":{}},"excerpt":"<p>Maven学习浅记-常用命令及相关概念</p>","more":"<h2 id=\"1-Maven官网-官方文档是学习工具的最好参考书\"><a href=\"#1-Maven官网-官方文档是学习工具的最好参考书\" class=\"headerlink\" title=\"1:Maven官网(官方文档是学习工具的最好参考书)\"></a>1:Maven官网(官方文档是学习工具的最好参考书)</h2><p>   <a href=\"http://maven.apache.org/\"> http://maven.apache.org</a></p>\n<h2 id=\"2-maven官网定义\"><a href=\"#2-maven官网定义\" class=\"headerlink\" title=\"2:maven官网定义\"></a>2:maven官网定义</h2><p>  官方解释：Apache Maven is a software project management and comprehension tool.<br>  Based on the concept of a project object model (POM),Maven can manage a project’s build,<br>  reporting and documentation from a central piece of information<br>  (Apache Maven是一个软件项目管理和理解工具。基于项目对象模型（POM）的概念，Maven可以从一个中心信息管理项目的构建，报告和文档)</p>\n<p>  我目前所用到的Maven的主要作用就是:</p>\n<pre><code>1:添加第三方jar包;\n2:jar包之间的依赖关系;\n3:获取第三方jar包；\n4:将整个项目拆分成多个工程模块;\n5：部署，测试报告;</code></pre>\n<p>但是maven是一个强大工具(远远不止我提到的这几个基础的功能,其中就包含项目的构建，报告和文档,官方解释地址:<a href=\"https://maven.apache.org/maven-features.html\">https://maven.apache.org/maven-features.html</a>;</p>\n<h2 id=\"3-Maven下载地址\"><a href=\"#3-Maven下载地址\" class=\"headerlink\" title=\"3:Maven下载地址\"></a>3:Maven下载地址</h2><p> <a href=\"https://maven.apache.org/download.cgi\">https://maven.apache.org/download.cgi</a></p>\n<h2 id=\"4-maven安装\"><a href=\"#4-maven安装\" class=\"headerlink\" title=\"4:maven安装\"></a>4:maven安装</h2><h3 id=\"4-1-解压部署Maven核心程序\"><a href=\"#4-1-解压部署Maven核心程序\" class=\"headerlink\" title=\"4.1:解压部署Maven核心程序\"></a><strong>4.1:解压部署Maven核心程序</strong></h3><pre><code>①检查JAVA_HOME环境变量\n    首先确保你的JDK已经正确安装;\n②解压Maven的核心程序\n    将apache-maven-3.5.3-bin.zip(在项目中以上传元安装包)解压到一个非中文无空格的目录下。例如：D:\\DevInstall\\apache-maven-3.5.3\n③配置环境变量\n    M2_HOME D:\\DevInstall\\apache-maven-3.5.3\n    path    D:\\DevInstall\\apache-maven-3.5.3\\bin\n④查看Maven版本信息验证安装是否正确\nC:\\Windows\\System32&gt;mvn -v\n    Apache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-25T03:49:05+08:00)\n    Maven home: D:\\Maven\\apache-maven-3.5.3\\bin\\..\n    Java version: 1.8.0_131, vendor: Oracle Corporation\n    Java home: D:\\Program Files\\Java\\jdk1.8.0_131\\jre\n    Default locale: zh_CN, platform encoding: GBK\n    OS name: &quot;windows 10&quot;, version: &quot;10.0&quot;, arch: &quot;amd64&quot;, family: &quot;windows&quot;</code></pre>\n<h3 id=\"4-2-修改本地仓库\"><a href=\"#4-2-修改本地仓库\" class=\"headerlink\" title=\"4.2:修改本地仓库\"></a>4.2:修改本地仓库</h3><pre><code>①默认本地仓库位置：~\\.m2\\repository,~表示当前用户的家目录，例如：C:\\Users\\[你当前登录系统的用户名]\n②指定本地仓库位置的配置信息文件：apache-maven-3.5.3\\conf\\settings.xml\n③在根标签settings下添加如下内容：&lt;localRepository&gt;[本地仓库路径，也就是RepMaven.zip的解压目录]&lt;/localRepository&gt;</code></pre>\n<h2 id=\"5-官网五分钟教程\"><a href=\"#5-官网五分钟教程\" class=\"headerlink\" title=\"5:官网五分钟教程\"></a>5:官网五分钟教程</h2><h3 id=\"5-1-保证安装好Maven-参考本文4-maven安装\"><a href=\"#5-1-保证安装好Maven-参考本文4-maven安装\" class=\"headerlink\" title=\"5.1:保证安装好Maven(参考本文4:maven安装)\"></a>5.1:保证安装好Maven(参考本文4:maven安装)</h3><h3 id=\"5-2-首先你要知道Maven的一个项目结构\"><a href=\"#5-2-首先你要知道Maven的一个项目结构\" class=\"headerlink\" title=\"5.2:首先你要知道Maven的一个项目结构\"></a>5.2:首先你要知道Maven的一个项目结构</h3><pre><code>my-app\n|-- pom.xml project&#39;s Project Object Model, or POM. 项目对象模型文件\n|-- src\n    |-- main\n        |-- java    Application/Library sources 应用程序/库源\n        |-- resources   Application/Library resources 应用程序/库资源\n        |-- filters   Resource filter files 资源过滤文件\n        |-- webapp   Web application sources Web应用程序源\n    |-- test\n        |--java Test sources 测试来源\n        |--resources Test sources 测试资源\n        |--filters Test resource filter files 测试资源过滤器文件\n    |--it Integration Tests (primarily for plugins) 集成测试（主要用于插件）\n    |--assembly Assembly descriptors 程序装配集成描述\n    |--site Site\nLICENSE.txt    Project&#39;s license 项目许可证\nNOTICE.txt    Notices and attributions required by libraries that the project depends on 项目依赖的库和其他注意的问题\nREADME.txt 项目提要</code></pre>\n<h3 id=\"5-3-在建成你的项目之后-一定记住拷贝一份官方的pom-xml放到其指定的位置\"><a href=\"#5-3-在建成你的项目之后-一定记住拷贝一份官方的pom-xml放到其指定的位置\" class=\"headerlink\" title=\"5.3:在建成你的项目之后,一定记住拷贝一份官方的pom.xml放到其指定的位置\"></a>5.3:在建成你的项目之后,一定记住拷贝一份官方的pom.xml放到其指定的位置</h3><p>eg:pom.xml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class=\"line\">     xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt;</span><br><span class=\"line\">     &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">     &lt;groupId&gt;com.mycompany.app&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">     &lt;artifactId&gt;my-app&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">     &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">     &lt;properties&gt;</span><br><span class=\"line\">       &lt;maven.compiler.source&gt;1.7&lt;&#x2F;maven.compiler.source&gt;</span><br><span class=\"line\">       &lt;maven.compiler.target&gt;1.7&lt;&#x2F;maven.compiler.target&gt;</span><br><span class=\"line\">     &lt;&#x2F;properties&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">     &lt;dependencies&gt;</span><br><span class=\"line\">       &lt;dependency&gt;</span><br><span class=\"line\">         &lt;groupId&gt;junit&lt;&#x2F;groupId&gt;</span><br><span class=\"line\">         &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt;</span><br><span class=\"line\">         &lt;version&gt;4.12&lt;&#x2F;version&gt;</span><br><span class=\"line\">         &lt;scope&gt;test&lt;&#x2F;scope&gt;</span><br><span class=\"line\">       &lt;&#x2F;dependency&gt;</span><br><span class=\"line\">     &lt;&#x2F;dependencies&gt;</span><br><span class=\"line\">   &lt;&#x2F;project&gt;</span><br></pre></td></tr></table></figure>\n\n\n<p>该项目的POM目录下打开命令行窗口执行一段shell脚本:<br><code>mvn archetype:generate -DgroupId=com.mycompany.app -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false</code><br>第一次运行可能会花销一些时间下载很多maven依赖的包</p>\n<h3 id=\"5-4-POM文件的关键元素解释\"><a href=\"#5-4-POM文件的关键元素解释\" class=\"headerlink\" title=\"5.4.POM文件的关键元素解释:\"></a>5.4.POM文件的关键元素解释:</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;project&gt; This is the top-level element in all Maven pom.xml files. </span><br><span class=\"line\">(maven项目中最高级别的的pom.xml文件元素节点)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;modelVersion&gt; This element indicates what version of the object model this POM </span><br><span class=\"line\">is using.The version of the model itself changes very infrequently but it is mandatory</span><br><span class=\"line\">in order to ensure stability of use if and when the Maven developers deem it necessary</span><br><span class=\"line\">to change the model.(工程对象模型的版本号,不经常改变但是开发者可以根据需要改变,存在就是为了确保项目的稳定性)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;groupId&gt; This element indicates the unique identifier of the organization or group</span><br><span class=\"line\">that created the project.The groupId is one of the key identifiers of a project and</span><br><span class=\"line\">is typically based on the fully qualified domain name of your organization.For example</span><br><span class=\"line\">org.apache.maven.plugins is the designated groupId for all Maven plugins.</span><br><span class=\"line\">(创建项目的组织或者组的唯一标识符,一般都是用组织的全限定域名)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;artifactId&gt; This element indicates the unique base name of the primary artifact being</span><br><span class=\"line\">generated by this project.The primary artifact for a project is typically a JAR file.</span><br><span class=\"line\">Secondary artifacts like source bundles also use the artifactId as part of their final name.</span><br><span class=\"line\">A typical artifact produced by Maven would have the form &lt;artifactId&gt;-&lt;version&gt;.&lt;extension&gt; </span><br><span class=\"line\">(for example, myapp-1.0.jar).</span><br><span class=\"line\">(由项目生成的唯一主要工件的基本名称(模块名称),主要比如我们打包的时候的生成的包名)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;packaging&gt; This element indicates the package type to be used by this artifact </span><br><span class=\"line\">(e.g. JAR, WAR, EAR, etc.).This not only means if the artifact produced is JAR, WAR,</span><br><span class=\"line\">or EAR but can also indicate a specific lifecycle to use as part of the build process.</span><br><span class=\"line\">(The lifecycle is a topic we will deal with further on in the guide. For now, just keep</span><br><span class=\"line\">in mind that the indicated packaging of a project can play a part in customizing the build</span><br><span class=\"line\">lifecycle.) The default value for the packaging element is JAR so you do not have to specify</span><br><span class=\"line\">this for most projects.(就是我们打包的类型,eg: jar包,war包.ear包,默认是jarb包)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;version&gt; This element indicates the version of the artifact generated by the project.</span><br><span class=\"line\">Maven goes a long way to help you with version management and you will often see the SNAPSHOT</span><br><span class=\"line\">designator in a version,which indicates that a project is in a state of development. We will</span><br><span class=\"line\">discuss the use of snapshots and how they work further on in this guide.</span><br><span class=\"line\">(由项目生成的工件版本号,有很多版本:eg SNAPSHOT)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;name&gt; This element indicates the display name used for the project. This is often used</span><br><span class=\"line\">in Maven&#39;s generated documentation.(项目的显示名称)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;url&gt; This element indicates where the project&#39;s site can be found. This is often used in Maven&#39;s</span><br><span class=\"line\">generated documentation.(项目的站点位置地址)</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;description&gt; This element provides a basic description of your project. This is often used in Maven&#39;s</span><br><span class=\"line\">generated documentation.(项目的接本基本描述)</span><br></pre></td></tr></table></figure>\n<p>更多POM.xml元素解释描述文档参考地址:<a href=\"https://maven.apache.org/ref/3.6.0/maven-model/maven.html\">https://maven.apache.org/ref/3.6.0/maven-model/maven.html</a></p>\n<h2 id=\"6-maven常用命令\"><a href=\"#6-maven常用命令\" class=\"headerlink\" title=\"6:maven常用命令\"></a>6:maven常用命令</h2><h3 id=\"6-1-Maven的常用命令-注意：运行Maven命令时一定要进入pom-xml文件所在的目录-演示\"><a href=\"#6-1-Maven的常用命令-注意：运行Maven命令时一定要进入pom-xml文件所在的目录-演示\" class=\"headerlink\" title=\"6.1:Maven的常用命令(*注意：运行Maven命令时一定要进入pom.xml文件所在的目录)演示:\"></a>6.1:Maven的常用命令(*注意：运行Maven命令时一定要进入pom.xml文件所在的目录)演示:</h3><pre><code>    mvn compile    编译\n    编译的内容命令行展示窗口展示内容\n    [WARNING]\n    [WARNING] Some problems were encountered while building the effective settings\n    [WARNING] Unrecognised tag: &#39;mirrors&#39; (position: START_TAG seen ...&lt;/mirror&gt;\\n--&gt;\\n\\t \\n&lt;mirrors&gt;... @160:14)    \n    @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n    [WARNING]\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] --------------------------&lt; maven_3:maven_3 &gt;---------------------------\n    [INFO] Building maven_3 1.0-SNAPSHOT\n    [INFO] --------------------------------[ jar ]---------------------------------\n    Downloading from central: https://repo.maven.apache.org/maven2/junit/junit/4.0/junit-4.0.pom\n    Downloaded from central: https://repo.maven.apache.org/maven2/junit/junit/4.0/junit-4.0.pom (210 B at 129 B/s)\n    [INFO]\n    [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ maven_3 ---\n    [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n    [INFO] Copying 1 resource\n    [INFO]\n    [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ maven_3 ---\n    [INFO] Changes detected - recompiling the module!\n    [WARNING] File encoding has not been set, using platform encoding GBK, i.e. build is platform dependent!\n    [INFO] Compiling 1 source file to D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\\classes\n    [INFO] ------------------------------------------------------------------------\n    [INFO] BUILD SUCCESS\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Total time: 7.092 s\n    [INFO] Finished at: 2019-02-01T10:37:11+08:00\n    [INFO] ------------------------------------------------------------------------\n\n    mvn clean    清理\n    [WARNING]\n    [WARNING] Some problems were encountered while building the effective settings\n    [WARNING] Unrecognised tag: &#39;mirrors&#39; (position: START_TAG seen ...&lt;/mirror&gt;\\n--&gt;\\n\\t \\n&lt;mirrors&gt;... @160:14)      \n    @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n    [WARNING]\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] --------------------------&lt; maven_3:maven_3 &gt;---------------------------\n    [INFO] Building maven_3 1.0-SNAPSHOT\n    [INFO] --------------------------------[ jar ]---------------------------------\n    [INFO]\n    [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ maven_3 ---\n    [INFO] Deleting D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\n    [INFO] ------------------------------------------------------------------------\n    [INFO] BUILD SUCCESS\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Total time: 0.572 s\n    [INFO] Finished at: 2019-02-01T11:55:52+08:00\n    [INFO] ------------------------------------------------------------------------\n\n    mvn test    测试\n    [WARNING]\n    [WARNING] Some problems were encountered while building the effective settings\n    [WARNING] Unrecognised tag: &#39;mirrors&#39; (position: START_TAG seen ...&lt;/mirror&gt;\\n--&gt;\\n\\t \\n&lt;mirrors&gt;... @160:14)      \n    @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n    [WARNING]\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] --------------------------&lt; maven_3:maven_3 &gt;---------------------------\n    [INFO] Building maven_3 1.0-SNAPSHOT\n    [INFO] --------------------------------[ jar ]---------------------------------\n    [INFO]\n    [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ maven_3 ---\n    [INFO] Deleting D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\n    [INFO] ------------------------------------------------------------------------\n    [INFO] BUILD SUCCESS\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Total time: 0.572 s\n    [INFO] Finished at: 2019-02-01T11:55:52+08:00\n    [INFO] ------------------------------------------------------------------------\n\n    mvn package    打包\n    打包的内容命令行展示窗口展示内容\n    [WARNING]\n    [WARNING] Some problems were encountered while building the effective settings\n    [WARNING] Unrecognised tag: &#39;mirrors&#39; (position: START_TAG seen ...&lt;/mirror&gt;\\n--&gt;\\n\\t\\n&lt;mirrors&gt;...         \n    @160:14)  @ D:\\Maven\\apache-maven-3.5.3\\bin\\..\\conf\\settings.xml, line 160, column 14\n    [WARNING]\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] --------------------------&lt; maven_3:maven_3 &gt;---------------------------\n    [INFO] Building maven_3 1.0-SNAPSHOT\n    [INFO] --------------------------------[ jar ]---------------------------------\n    [INFO]\n    [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ maven_3 ---\n    [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n    [INFO] Copying 1 resource\n    [INFO]\n    [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ maven_3 ---\n    [INFO] Nothing to compile - all classes are up to date\n    [INFO]\n    [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ maven_3 ---\n    [WARNING] Using platform encoding (GBK actually) to copy filtered resources, i.e. build is platform dependent!\n    [INFO] skip non existing resourceDirectory D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\src\\test\\resources\n    [INFO]\n    [INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ maven_3 ---\n    [INFO] Nothing to compile - all classes are up to date\n    [INFO]\n    [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ maven_3 ---\n    [INFO] Surefire report directory: D:\\ArnoldSu\\Maven-learnning\\maven_3_maven项目与常用命令\\target\\surefire-reports\n\n    -------------------------------------------------------\n     T E S T S\n    -------------------------------------------------------\n    Running com.boommob.www.HelloWorldTest\n    Hello litingwei!Hello litingwei!\n    Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.176 sec\n    Results :\n\n    Tests run: 1, Failures: 0, Errors: 0, Skipped: 0\n\n    [INFO]\n    [INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ maven_3 ---\n    [INFO] ------------------------------------------------------------------------\n    [INFO] BUILD SUCCESS\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Total time: 4.588 s\n    [INFO] Finished at: 2019-02-01T10:57:07+08:00\n    [INFO] ------------------------------------------------------------------------</code></pre>\n<h3 id=\"6-2-在执行完相应的maven命令之后会在该项目的路径下生成target文件夹\"><a href=\"#6-2-在执行完相应的maven命令之后会在该项目的路径下生成target文件夹\" class=\"headerlink\" title=\"6.2:在执行完相应的maven命令之后会在该项目的路径下生成target文件夹:\"></a>6.2:在执行完相应的maven命令之后会在该项目的路径下生成target文件夹:</h3><pre><code> target\n     |-- classes 编译之后的类文件\n     |-- maven-archeiver maven打包时候生成的得一个工程对象模型属性文件里面记载的是该项目的POM.xml的一些相关属性\n     |-- maven-status maven状态,一些maven编译的插件信息\n     |-- surefire-reports maven打包生成的一个报告,测试报告\n     |-- test-classes 编译之后的测试类文件</code></pre>\n<h2 id=\"7-maven依赖\"><a href=\"#7-maven依赖\" class=\"headerlink\" title=\"7:maven依赖\"></a>7:maven依赖</h2><h3 id=\"7-1-首先项目POM-xml添加本文6-maven常用命令的依赖-这是我们本地库的一个模块依赖-如果直接在命令行直接执行-mvn-compile-的话会报错-此处需要先在6-maven常用命令的步骤上执行mvn-install-将模块安装到本地-在结合maven依赖进行编译\"><a href=\"#7-1-首先项目POM-xml添加本文6-maven常用命令的依赖-这是我们本地库的一个模块依赖-如果直接在命令行直接执行-mvn-compile-的话会报错-此处需要先在6-maven常用命令的步骤上执行mvn-install-将模块安装到本地-在结合maven依赖进行编译\" class=\"headerlink\" title=\"7.1:首先项目POM.xml添加本文6:maven常用命令的依赖,这是我们本地库的一个模块依赖,如果直接在命令行直接执行:mvn compile 的话会报错, 此处需要先在6:maven常用命令的步骤上执行mvn install,将模块安装到本地,在结合maven依赖进行编译.\"></a>7.1:首先项目POM.xml添加本文6:maven常用命令的依赖,这是我们本地库的一个模块依赖,如果直接在命令行直接执行:mvn compile 的话会报错, 此处需要先在6:maven常用命令的步骤上执行mvn install,将模块安装到本地,在结合maven依赖进行编译.</h3><h3 id=\"7-2-POM-xml元素解释\"><a href=\"#7-2-POM-xml元素解释\" class=\"headerlink\" title=\"7.2:POM.xml元素解释\"></a>7.2:POM.xml元素解释</h3><p>dependencies:(Many) This element describes all of the dependencies associated with a project.<br>These dependencies are used to construct a classpath for your project during the build process.<br>They are automatically downloaded from the repositories defined in this project.See the dependency mechanism for more information.<br>(此元素描述与项目关联的所有依赖项。这些依赖项用于在构建过程中为项目构造类路径。它们会自动从此项目中定义的存储库下载,参考依赖机制:<a href=\"https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html\">https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html</a>);</p>\n<h3 id=\"7-3-Dependency-Mechanism-依赖机制\"><a href=\"#7-3-Dependency-Mechanism-依赖机制\" class=\"headerlink\" title=\"7.3:Dependency Mechanism(依赖机制)\"></a>7.3:Dependency Mechanism(依赖机制)</h3><pre><code>3.1.Transitive Dependencies(传递依赖)\n    Dependency mediation(依赖调解),多个版本依赖项nearest definition\n    (最近定义原则:表示所使用的版本将是依赖关系树中与项目最接近的版本。例如，如果A，B和C\n    的依赖关系定义为A - &gt; B - &gt; C - &gt; D 2.0和A - &gt; E - &gt; D 1.0，则构建A时将使用D 1.0,\n    因为A的路径到D到E更短.您可以在A中向D 2.0明确添加依赖项以强制使用D 2.0);\n\n3.2.Dependency management(依赖管理),在3.1的示例中，依赖项直接添加到A，即使它不是由A直接使用。\n    相反，A可以在其dependencyManagement部分中包含D作为依赖项,并直接控制在何时使用D的哪个版本;\n\n3.3.Dependency scope(依赖范围),下面4点详细讲解;\n\n3.4.Dependency scope(排除依赖项),如果项目X依赖于项目Y，项目Y依赖于项目Z，则项目X的所有者可以使用\n    exclusion元素将项目Z明确地排除为依赖项;\n\n3.5.Optional dependencies(可选择的依赖项),如果项目Y依赖于项目Z，项目Y的所有者可以使用optional元素\n    将项目Z标记为可选依赖项。当项目X依赖于项目Y时，X将仅依赖于Y而不依赖于Y的可选依赖项Z.项目X的所有者可以\n    在她的选项中明确地添加对Z的依赖性;</code></pre>\n<p>Maven提供dependency:analyze插件,可以帮助最佳实现依赖机制.</p>\n<h3 id=\"7-4-Dependency-scope-依赖范围\"><a href=\"#7-4-Dependency-scope-依赖范围\" class=\"headerlink\" title=\"7.4:Dependency scope(依赖范围)\"></a>7.4:Dependency scope(依赖范围)</h3><pre><code>依赖关系范围用于限制依赖关系的传递性，还用于影响用于各种构建任务的类路径。包含六个范围:\n    4.1.compile,默认范围,编译依赖项在项目的所有类路径中都可用,这些依赖项将传播到其他依赖项目。\n\n    4.2.provided,和compile很相似,但是但表示您希望JDK或容器在运行时提供依赖项。例如，在为Java\n        Enterprise Edition构建Web应用程序时，您可以将Servlet API和相关Java EE API的依赖关系设置\n        为提供的范围，因为Web容器提供了这些类。此范围仅在编译和测试类路径中可用，并且不可传递。\n\n    4.3.runtime,此范围表示编译不需要依赖项，但是用于执行。它位于运行时和测试类路径中，但不是编译类路径。\n        可执行不需要编译的依赖\n\n    4.4.test,测试编译和执行的依赖,依赖不传递\n\n    4.5.system,和provided很相似只是您必须提供明确包含它的JAR。可以使用但是不能在库中找到\n\n    4.6.import,仅在POM.xml中引入&lt;dependencyManagement&gt;元素才支持此作用域。并且一旦标注为import,就不参与传递依赖\n        每个依赖范围（import除外）以不同方式影响传递依赖性，如下表所示。如果依赖项设置为左列中的作用域，则该依赖项与顶行\n        中作用域的传递依赖性将导致主项目中的依赖项，并在交集处列出作用域。如果未列出范围，则表示将省略依赖关系。</code></pre>\n<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-BWzXa9rA-1576392504689)(<a href=\"https://images.gitee.com/uploads/images/2019/0202/135822_124ff85b_1635774.png\">https://images.gitee.com/uploads/images/2019/0202/135822_124ff85b_1635774.png</a> “[EF5RN$22FD@[FBW%9O7P]Y.png”)]</p>\n<h3 id=\"7-5-Dependency-Management-依赖管理\"><a href=\"#7-5-Dependency-Management-依赖管理\" class=\"headerlink\" title=\"7.5:Dependency Management(依赖管理)\"></a>7.5:Dependency Management(依赖管理)</h3><pre><code>5.1.集中依赖信息管理,官方图示来说明其机制:两个扩展同一父级的POM\n项目A共同依赖group-a,但是第一个依赖排除对grouo-c的依赖,依赖于artifact-a模块,第二个依赖是group-a下的artifact-b</code></pre>\n<p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDE1MjlfZTNhNzYwNTlfMTYzNTc3NC5wbmc?x-oss-process=image/format,png\" alt=\"项目A\"></p>\n<pre><code>项目B,第一个依赖grouo-c下的artifact-b,第二个依赖是group-a下的artifact-b</code></pre>\n<p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDE4MjFfODA2YTUyY2ZfMTYzNTc3NC5wbmc?x-oss-process=image/format,png\" alt=\"项目B\"></p>\n<pre><code>用依赖管理&lt;dependencyManagement&gt;放在其父级项目POM.xml</code></pre>\n<p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIwMi8xNDI1NDBfNjliOGNmOTVfMTYzNTc3NC5wbmc?x-oss-process=image/format,png\" alt=\"父项目\"></p>\n<pre><code>两个子项目的配置就会简单很多</code></pre>\n<p><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMuZ2l0ZWUuY29tL3VwbG9hZHMvaW1hZ2VzLzIwMTkvMDIxNC8xMjU3MTJfOTRjNDg0NzRfMTYzNTc3NC5wbmc?x-oss-process=image/format,png\" alt=\"简化之后的配置\"></p>\n<pre><code>注意:其中子项目用Dependency Management之后需要指明&lt;type&gt;的类型,因为Dependency Management\n只针对&#123;groupId, artifactId, type, classifier&#125;为最小单位进行依赖管理\n\n5.2.还有个重要的特性就是模块版本控制上面,并且依赖管理的依赖级别是:dependency management&gt;transitive dependencies除了继承依赖传递,还可以通过&lt;import&gt;来导入依赖,在较大的项目中比较实用,并且讲究谁先申明谁且本身pom并未申明版本号,就引用第一个申明的版本号作为当前的版本号.</code></pre>\n<h3 id=\"7-6-System-Dependencies-系统依赖-已经弃用\"><a href=\"#7-6-System-Dependencies-系统依赖-已经弃用\" class=\"headerlink\" title=\"7.6:System Dependencies(系统依赖,已经弃用)\"></a>7.6:System Dependencies(系统依赖,已经弃用)</h3><p><strong>本文的maven记录在github地址:<a href=\"https://github.com/ArnoldShu/Maven-learnning\">https://github.com/ArnoldShu/Maven-learnning</a><br>本文的maven记录在gitee地址:<a href=\"https://gitee.com/ArnoldSu/Maven-learnning\">https://gitee.com/ArnoldSu/Maven-learnning</a><br>个人blog地址:<a href=\"http://www.bestarnold.com/\">http://www.bestarnold.com</a></strong><br><a href=\"https://blog.csdn.net/qq_20340547/article/details/103547879\">本文CSDN链接地址</a></p>"},{"title":"docker摘记-docker相关知识点总结摘要","date":"2020-01-12T08:47:54.000Z","_content":"Docker 是基于 Go 语言实现的开源容器项目,Docker 的构想是要实现“ Build Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging ）、分发（ Distribution ）、部署（ Deployment ）、运行（ Runtime ）生命周期进行管理达到应用组件级别的“一次封装 ，到处运行”,Docker 也并非“从石头缝里蹦出来的”而是站在巨人的肩膀上,其中最重要的就是 Linux 容器(Linux Containers, LXC)技术.\n...\n<!--more-->\n# Docker是啥?\n\nDocker 是基于 Go 语言实现的开源容器项目,Docker 的构想是要实现“ Build Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging ）、分发（ Distribution ）、部署（ Deployment ）、运行（ Runtime ）生命周期进行管理达到应用组件级别的“一次封装 ，到处运行”,Docker 也并非“从石头缝里蹦出来的”而是站在巨人的肩膀上,其中最重要的就是 Linux 容器(Linux Containers, LXC)技术.\n\n# Docker优点\n\n更快速的交付和部署\n更高效的资源利用;\n更轻松地迁移和拓展;\n更简单的更新管理\n\n# Docker与虚拟机的比较\n\nDocker 容器很快，启动和停止可以在秒级实现，这相比传统的虚拟机方式（数分钟）要快得多；\nDocker 容器对系统资源需求很少，一台主机上可以同时运行数千个 Docker 容器（在\nIBM 服务器上已经实现了同时运行！ OK 量级的容器实例）；\nDocker 通过类似 Git 设计理念的操作来方便用户获取、分发和更新应用镜像，存储复\n用，增量更新；\nDocker 通过 Dockerfile 支持灵活的自动化创建和部署机制，以提高工作效率，并标准\n化流程\n\n# Docker 三大核心观念\n\n**镜像(Image)**:类似于虚拟机镜像,看做一个只读模板,镜像是docker的基础\n\n**容器(Container)**:容器类似于一个轻级的沙箱,Docker 利用容器来运行和隔离应用,容器是从镜像创建的应用运行实例它可以启动、开始、停止 删除，而这些容器都是彼此相互隔离、互不可见的\n\n**仓库(Repository)**:仓库类似于代码仓库,是Docker集中存放镜像文件的场所.\n\n# Docker Centos安装\n\nDocker 目前支持 CentOS 及以后的版本 系统的要求跟 Ubuntu 情况类似， 64 位操作\n系统，内核版本至少为 3.10\n\n```bash\n首先，为了方便添加软件源，以及支持 devicemapper 存储类型，安装如下软件包：\n$ sudo yum update \n$ sudo yum instal l -y yum-utils \\ device-mapper-persistent-data \\ lvm2 \n添加Dokcker 稳定版本的 yum 软件源：\n$ sudo yum-conf ig- manager \\ --add-repo https : //download.docker.corn/linux/centos/ docker-ce.repo \n之后更新 yum 软件源缓存，并安装 Docker:\n$ sudo yum update \n$ sudo yum install -y docker-ce \n最后，确认 Docker 服务启动正常\n$ sudo systernctl start docker\n用户还可以使用官方提供的 shell 脚本来在 Linux 系统（目前支持山untu Debian Oracleserv edora Centos OpenSuse Gentoo 等常 发行版）上安装 Docker 最新正式版本，该脚本会自动检测系统信息并进行相应配置：\n$ curl -fsSL https: //get.docker . corn/ I sh \n或者\n$ wget - qO- https://get . docker.corn/ I sh \n如果想尝鲜最新功能，可以使用下面的脚本来安装最新的“尝鲜”版本 但要注意，非稳定版本往往意味着功能还不够稳定，不要在生产环境中使用\n$ curl -fsSL https : //test.docker .corn/ I sh \n另外， 也可以从 store docker.com/search?offering=community&q &type=edition 找到各个平台上的 Docker 安装包，自行下载使用\n其他操作系统可根据官网进行下载安装\n```\n\n# Docker 镜像常用命令\n## 获取镜像\n**命令:docker [image] pull NAME [ :TAG]** \nNAME 是镜像仓库名称（用来区分镜像）,TAG 是镜像的标签（往往用来表示版本信息）。 通常情况下， 描述一个镜像需要包括 “名称＋标签“ 信息,如果不显式指定TAG, 则默认会选择la迳釭标签，这会下载仓库中最新版本的镜像。严格地讲，镜像的仓库名称中还应该添加仓库地址（即registry, 注册服务器）作为前\n缀 ，只是默认使用的是官方DockerHub服务 ，该前缀可以忽略\npull 子命令支持的 选项主要包括：\n\t -a, --all tags=trueifalse: 是否获取仓库中的所有镜像，默认为否\n\t --disable-conyent-trust：取消镜像的内容校验，默认为真\n## 查看镜像信息\n**命令:docker images或docker image ls**\n可以列出本地主机上已有镜像的基本信息\nimages子命令主要支持如下选项， 用户可以自行进行尝试：\n\t-a, --all true I false: 列出所有（包括临时文件）镜像文件，默认为否\n\t--digestS=trueifalse: 列出镜像的数字摘要值，默认为否\n\t-f, --filter=[] : 过滤列出的镜像， 如dangling 式rue 只显示没有被使用的镜像,也可指定带有特定标注的镜像等\n\t--format=\"TEMPLATE\" : 控制输出格式，如. ID代表ID信息，.Repository代表仓库信息等\n\t--no-trunc=true |false: 对输出结果中太长的部分是否进行截断，如镜像的ID信息，默认为是\n\t-q, --quiet=true |false: 仅输出ID信息， 默认为否。\n\t其中， 还支持对输出结果进行控制的选项，如 -f. --filter=[]、--no-trunc =true | false、 -q、 --quiet=true | false等。\n更多子命令选项还可以通过mandocker-images来查看\n\n**命令:docker[image]inspect**\n获取该镜像的详细信息，包括制作者 、 适应架构、各层的数字摘要等\n\n**命令:docker history** \n获取该镜像的历史信息\n\n## 搜索镜像\n**命令:docker search [option] keyword**\n搜索镜像\n支持的命令选项主要包括：\n\t -f, --filer filter: 过滤输出内容\n\t --format string: 格式化输出内容\n\t --limit int：限制输出结果个数，默认为 25 个\n\t --no-trunc: 不截断输出结果\n## 删除和清理镜像\n**命令:docker rmi 或 docker image rm** \n可以删除镜像\ndocker rmi IMAGE [IMAGE ... ] 其中 IMAGE可以为标签或 ID\n支持选项包括：\n\t-f, -force: 强制删除镜像， 即使有容器依赖它\n\t-no-prune: 不要清理未带标签的父镜像\n\n**命令:docker ps -a** \n看到本机上存在的所有容器\n\n**命令:docker image prune** \n来进行清理删除镜像\n支待选项包括：\n\t -a, -all: 删除所有无用镜像， 不光是临时镜像\n\t -filler filler: 只清理符合给定过滤器的镜像\n\t -f, -force: 强制删除镜像， 而不进行提示确认\n## 创建镜像\n**命令:docker [container] commit [OPTIONS] CONTAINER [REPOSITORY [:TAG]]** \n基于已有容器创建镜像\n主要选项包括：\n\t-a, --author=\"\": 作者信息\n\t-c, --change=[] : 提交的时候执行Dockerfile指令， 包括 CMDIENTRYPOINT 但NVIEXPOSEILABELIONBUILDIUSERIVOLUMEIWORKDIR等\n\t-m, --message= \"\": 提交消息\n\t-p, --pause式rue: 提交时暂停容器运行\n\n**命令: docker [image] i mport [OPTIONS] filelURLl -[REPOSITORY [:TAG] ]**\n基于本地模板导入镜像\n\n**基于dockerfile创建镜像,可在官网了解相关知识点**\n\n## 存出和载人镜像\n**命令:docker [image ] save docker [image ] load** \n来存出和载人镜像\n\n**命令:docker [image] push [:TAG] | [REGISTRY_HOST [ :REGISTRY_PORT] / ]NAME [:TAG]**\n上传镜像到仓库，默认上传到 Docker Hub 官方仓库（需要登录）\n\n# Docker 容器常用命令\n## 创建容器\n**命令:docker [container] create** \n命令新建一个容器,使用 docker [container] create 命令新建的容器处于停止状态，可以使用 docker[container] start 命令来启动它,create命令较为强大,可以看相关文档地址:**https://docs.docker.com/engine/reference/commandline/create/**\n\n**命令: docker [container] start** \n来启动一个已经创建的容器\n\n**命令:docker ps**\n可以查看到运行中的容器\n\n**命令: docker [container ］run**\n新建并启动容器\n等价于先执行 docker [container] create 命令,再执行 docker [container] start 命令,\nDocker 在后台运行的标准操作包括：\n\t检查本地是否存在指定的镜像，不存在就从公有仓库下载\n\t利用镜像创建一个容器，并启动该容器\n\t分配 个文件系统给容器，并在只读的镜像层外面挂载一层可读写层\n\t从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n\t从网桥的地址池配置一个 IP 地址给容器\n\t执行用户指定的应用程序\n\t执行完毕后容器被自动终止\n\t\n**命令:docker [container] logs**\n查看容器输出信息\n该命令支持的选项包括：\n\t－details 打印详细信息；\n\t－f, follo ：持续保持输出；\n\t一since string ：输出从某个时间开始的日志；\n\t－tail string 输出最近的若干日志；\n\t－t, timestamps 显示时间戳信息\n\t－until string 输出某个时间之前的日\n## 停止容器\n**命令:docker [container] pause CONTAINER [CONTAINER ...]**\n暂停一个运行中的容器\n\n**命令:docker [contai er pause CONTAINER [CONTAINER ...]**\n来恢复到运行状态\n\n**命令:docker [container] stop [-t I - -time [=10]] [CONTAiNER ...]**\n来终止一个运行中的容器,该命令会首先向容器发送 SIGTERM 信号,等待一段超时时间后（默认为 10 秒）,再发\nSIGKLL 信号来终止容器\n\n**命令:docker container prune**\n会自动清除掉所有处于停止状态的容器\n\n**命令:docker [container] kill**\n直接发送 SIGKILL 信号来强行终止容器\n\n**命令:docker ps -qa** \n查看到所有容器的ID\n\n**命令:docker [container] start**\n重新启动容器\n\n**命令:docker [container] restart** \n命令会将一个运行态 的容器先终止，然后再重新启动\n\n## 进入容器\n\n**命令:docker [container] attach [--detach-keys[;[]]] [--no-stdin] [--sig-proxy[;true]] CONTAINER**\n命令支持三个主要选项：\n－－ detach-keys ［＝［］］：指定退出 attach 模式的快捷键序列， 默认是 CTRL-p CTRL-q;\n－－ no-stdin=trueifalse ：是否关闭标准输入，默认是保持打开\n－－ sig-proxy=truelfalse ：是否代理收到的系统信号给应用进程，默认为 true\n\n**命令:docker [container] exec [-d|-detach] [ detach-keys[=[]]] [-i|--interactive] [ --privileged] [-t|--tty] [-u|user [=USER]] CONTAINER COMMAND [ARG . . . ]**\n比较重要的参数有：\n－ d, --detach 在容器中后台执行命令\n－－ detach-keys =＂＂：指定将容器切回后台的按键\n－ e, - - env= []：指定环境变量列表\n－ i, --interactive=true | false ：打开标准输入接受用户输入命令， 默认值为false \n－－ privileged=true|false 是否给执行命令以高权限，默认值为 false\n－ t, --tty=true|false 分配伪终端，默认值为 false\n－ u, --user =\"\"：执行命令的用户名或 ID\n\n## 删除容器\n\n**命令:docker [container) rm [-f|-- force) [-1|-link] [-v|--volumes] CONTAINER [CONTAINER ...]**\n支持的选项包括\n－ f, --force=false 是否强行终止并删除一个运行中的容器\n－ 1, --link=false ：删除容器的连接 ，但保留容器\n－ v, --volumes=false ：删除容器挂载的数据卷\n\n## 导人和导出容器\n\n**命令:docker [container) export [-o|--output [=””] ] CONTAINER**\n导出容器是指，导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态\n－o 选项来指定导出的tar 文件名，也可以直接通过重定向来实现\n\n**命令:docker import [-c|--change[=[]]] [-m|--message[=MESSAGE]] file|URL|-[REPOSITORY [:TAG]]**\n导入容器\n\n## 查看容器\n\n**命令:用 docker container inspect [OPTIONS] CONTAINER [CONTAINER . .. ］**\n查看容器详情\n\n**命令:docker [container] top [OPTIONS] CONTAINER [CONTAINER...]**\n查看容器内进程\n\n\n**命令:docker [container] stats [OPTIONS] [CONTAINER ... ]**\n查看统计信息,会显示 CPU 、内存、存储、网络等使用情况的统计信息\n支持选项包括\n－ a, -all ：输出所有容器统计信息，默认仅在运行中\n－ format string ：格式化输出信息\n－ no-stream ：不持续输出，默认会自动更新持续实时结果\n－ no-trunc ：不截断输出信息\n\n## 其他容器命令\n\n**命令格式为 docker [container] cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-** \n复制文件\n支持的选项包括\n－ a, -ar chive ：打包模式，复制文件会带有原始的 uid/gid 信息\n－ L, -follow-link ：跟随软连接。当原路径为软连接时＼默认只复制链接信息,使用该选项会复制链接的目标内容\n\n**命令: docker [container] diff CONTAINER**\n查看变更\n\n**命令:docker container port CONTAINER [PRIVATE_PORT[/PROTO ］］**\n查看端口映射\n\n**命令:docker [container] update [OPTIONS] CONTAINER [CONTAINER ...]**\n支持的选项包括：\n－blkio-weight uintl6 ：更新块 IO 限制， 10 1000 ，默认值为 ，代表着无限制\n－ cpu-period int ：限制 CPU 调度器 CFS (Completely Fair Scheduler ）使用时间，单位为微秒，最小 1000\n－ cpu-quota int ：限制 CPU 调度器 CFS 配额，单位为微秒，最小 1000\n－ cpu-rt period int ：限制 CPU 调度器的实时周期，单位为微秒\n－ cpu-rt runtime int ：限制 CPU 调度器的实时运行时，单位为微秒\n－ c, -cpu-shares in 限制 CPU 使用份额\n－ cpus decimal ：限制 CPU 个数\n－ cpuset-cpus string ：允许使用的 CPU 核，如 0-3, 0,1\n－ cpuset mems string ：允许使用的内存块，如 0-3' 0, 1\n－ kernel-memor bytes ：限制使用的内核内存\n－ m, -memory bytes 限制使用的内存\n－memory-reservation bytes ：内存软限制\n－memory-swap bytes ：内存加上缓存区的限制， 表示为对缓冲区无限制\n－ restart stri 口g 容器退出后的重启策略\n# Docker仓库\n**仓库(Repository)**是集中存放镜像的地方，又分公共仓库和私有仓库\n## Docker Hub 公共镜像市场\n**Docker Hub Docker** 官方提供的最大的公共镜像仓库，目前包括了超过 100 000\n像，地址为 **https: //hub.docker.com**\n\n# Docker数据管理\n容器中的管理数据主要有两种方式\n**数据卷 Data Volumes)** 容器内数据直接映射到本地主机环境；\n**数据卷容器（Data Volume Containers)** 使用特定容器维护数据卷\n## 数据卷\n**数据卷 Data Volumes** 是一个可供容器使用的特殊目录，它将主机操作系统目录直接\n映射进容器，类似于 Linux 中的 mout 行为\n**数据卷可以提供很多有用的特性\n\t数据卷可以在容器之间共事和重用，容器间传递数据将变得高效与方便\n\t对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作\n\t对数据卷的更新不会影响镜像，解摘开应用和数据会一直存在 ，直到没有容器使用，可以安心地卸载它**\n## 创建数据卷\n**命令:docker volume create** \n## 绑定数据卷\n**命令:docker [container] run口命令的时候，可以使用 mount 选项来使用数据卷**\nmount 项支持三种类型的数据卷，包括\n\tvolume 普通数据卷，映射到主机／var/ lib /docke /vo lumes 径下\n\tbind ：绑定数据卷，映射到主机指定路径下\n\ttmpfs ：临时数据卷，只存在于内存中\n## 数据卷容器\n**命令:docker run -it --volumes-from dbdata --name dbl ubuntu**\n可以在其他容器中使用－－ volumes-from 来挂载 dbdata 容器中的数据卷，例如如创建 dbl db2 两个容器，并从 dbdata 容器挂载数据卷\n\n**命令:docker rm -v**\n删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用此命令,指定同时删除关联的容器\n\n## 利用数据卷容器来迁移数据\n**命令:docker run -volumes-from dbdata -v $ (pwd) : /backup - -name worker ubuntu tar \ncvf /backup/backup.tar /dbdata**\n利用 buntu 镜像创建了 个容器 worker 使用－ -volumes-from dbdata 参数\n来让 worker 容器挂载 db data 容器的数据卷（ dbdata 数据卷）；使用－ $ (pwd) : /backup \n参数来挂载本地的当前目录到 worke 容器的／backup\nworker 容器启动后，使用 tar cvf /backup/backup.tar /dbdata 令将／dbdata\n下内容备份为容器内的／backup/backup. tar ，即宿主主机当前目录下的 backup.tar\n\n**命令：docker run -v /dbdata --name dbdata2 ubuntu /bin/bash\ndocker run --volumes-from dbdata2 -v $(pwd) :/backup busybox tar xvf \n/backup/backup.tar**\n首先创建一个带有数据卷的容器 bdata2:，然后创建另一个新的容器，挂载 dbdata2 容器，并使用 untar 解压备份文件到所挂载的容器卷中\n\n# 端口映射与容器互联\n**命令:docker run -d -P training/webapp python app.py**\n当容器中运行一些网络应用， 要让外部访问这些应用时， 可以通过-P或-p参数来指定端口映射。 当使用平（大写的）标记时， Docker 会随机映射一个 49000-49900 的端口到内部容器开放的网络端口,-p (小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定 一个容器。支持的格式有IP:HostPort:ContainerPortI IP:: ContainerPort I HostPort:ContainerPort\n\n**命令;docker run -d -p 5000:5000 training/webapp python app.py**\n使用HostPort： ContainerPot格式本地的5000端口映射到容器的5000端口 \n多次使用-p标记可以绑定多个端口。例如:docker run -d -p 5000:5000 -p 3000:80 training/webapp py thon app.py\n\n**命令:docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py**\n可以使用IP:HostPort： ContainerPort格式指定映射使用一个特定地址，比如\nlocalhost地址127.0.0.1\n\n**命令: docker run -d -p 127.0.0.1::5000 training/webapp python app.py** \n使用IP::ContainerPort绑定localhost的任意端口到容器的5000端口，本地主机\n会自动分配一个端口：还可以使用udp标记来指定 udp端口：\n docker run -d -p 127.0.0.1:5000:5000/udp training/webapp PY七hon app.py\n \n**命令: docker port nos talgic_rnorse 5000**\n使用docker port来查看当前映射的端口配置，也可以查看到绑定的地址\n\n# 互联机制实现便捷互访\n**容器的互联(Iinking)**是一种让多个容器中的应用进行快速交互的方式。它会在源和接收容\n器之间创建连接关系，接收容器可以通过容器名快速访问到源容器，而不用指定具体的IP地址\n\n**命令:docker run -d -P --name web training/webapp python app.py**\n使用--name标记可以为容器自定义命名\n\n**命令:docker run -d -P --name web --link db:db taining/webapp python app.py**\n创建一个新的web容器，并将它连接到db容器,db容器和web容器建立互联关系。\n--link参数的格式为--link name: alias, 其中name是要链接的容器的名称 ,alias是别名\n\n# 使用Dockerfile创建镜像\nDockerfile 是一个文本格式的配置文件， 用户可以使用 Dockerfile 来快速创建自定义的镜像\n\n## 基本结构\nDockerfile 由一行行命令语句组成， 并且支持以＃开头的注释行。一般而言， \nDockerfile 主体内容分为四部分：**基础镜像信息**、 **维护者信息**、 **镜像操作指令**和**容器启动时执行指令**\n\n下面就是一个例子\n\n```bash\n#This dockerfile uses the ubuntu image\n#VERSION 2 - EDITION 1\n#Author: docker_user\n#Command format: Instruction [arguments / command] ..\n#1、第一行必须指定 基础镜像信息\nFROM ubuntu\n\n#2、维护者信息\nMAINTAINER docker_user docker_user@email.com\n\n#3、镜像操作指令\nRUN echo \"deb http://archive.ubuntu.com/ubuntu/ raring main universe\" >> /etc/apt/sources.list\nRUN apt-get update && apt-get install -y nginx\nRUN echo \"\\ndaemon off;\" >> /etc/nginx/nginx.conf\n \n#4、容器启动执行指令\nCMD /usr/sbin/nginx\n```\n首行可以通过注释来指定解析器命令， 后续通过注释说明镜像的相关信息。 主体部分首\n先使用FROM指令指明所基于的镜像名称， 接下来一般是使用LABEL指令说明维护者信息。\n后面则是镜像操作指令， 例如RUN指令将对镜像执行跟随的命令。 每运行一条RUN指令，\n镜像添加新的一层， 并提交。 最后是CMD指令， 来指定运行容器时的操作命令\n\n## 指令说明\nDockerfile 中指令的一般格式为 INSTRUCTION arguments, 包括 “配置指令\" (配置\n镜像信息）和 “操作指令\" (具体执行操作）， 参见下表 \nDockerfile中的指令及说明\n分 类 指 令 说 明\n| 分类 | 指令 | 说明 |\n|--|--|--|\n|配置指令  | ARG | 定义创建镜像过程中使用的变簸 |\n| 配置指令|FROM |指定所创建镜像的基础镜像|\n| 配置指令|LABEL |为生成的镜像添加元数据标签信息|\n| 配置指令|EXPOSE |声明镜像内服务监听的端口|\n|配置指令 |ENV| 指定环境变抵|\n| 配置指令|ENTRYPOINT |指定镜像的默认入口命令|\n|配置指令|VOLUME |创建一个数据卷挂载点|\n|配置指令|USER |指定运行容器时的用户名或UID|\n|配置指令|WORKDIR |配置工作目录|\n|配置指令|ONBUILD| 创建子镜像时指定自动执行的操作指令|\n|配置指令|STOPSIGNAL| 指定退出的信号值|\n|配置指令|HEALTH CHECK |配置所启动容器如何进行健康检查|\n|配置指令|SHELL |指定默认shell类型|\n|操作指令|RUN|运行指定命令|\n|操作指令|CMD|启动容器时刻指定默认执行程序|\n|操作指令|ADD|添加内容到镜像|\n|操作指令|COPY |复制内容到镜像|\n\n## 配置指令\n**ARG**\n定义创建镜像过程中使用的变量。\n格式为 `ARG <name>[=<default value>]`\n在执行 docker build 时， 可以通过 -build-arg[=] 来为变量赋值。 当镜像编译成\n功后， ARG 指定的变量将不再存在 (ENV 指定的变量将在镜像中保留）\nDocker 内置了一些镜像创建变量， 用户可以直接使用而无须声明， 包括（不区分大小\n写） HTTP PROXY 、 HTTPS PROXY 、 FTP PROXY 、 NO PROXY\n\n**FROM**\n指定所创建镜像的基础镜像\n格式为:`FROM <image> [AS <name>]` 或 `FROM <image>: <tag> [AS <name>]` \n或`FROM <image>@<digest> [AS <name>]` \n任何 Dockerfile 中第一条指令必须为FROM 指令。 并且， 如果在同一个Dockerfile 中创\n建多个镜像时， 可以使用多个 FROM 指令（每个镜像一次）\n为了保证镜像精简， 可以选用体积较小的镜像如Alpine或Debian 作为基础镜像。 例如：\n\n```\nARG VERSION=9.3 \nFROM debian:${VERSION} \n```\n\n**LABEL**\nLABEL 指令可以为生成的镜像添加元数据标签信息。 这些信息可以用来辅助过滤出特\n定镜像。\n格式为: `LABEL <key>=<value> <key>=<value> <key>=<value> ...`\n例如：\n\n```\nLABEL version=\"l.0.0-rc3\" \nLABEL author=\"yeasy@github\" date=\"2020-01-01\" \nLABEL description=\"This 七ex七 illustra七es\\\nthat label-values can span mul七iple lines.\" \n```\n\n**EXPOSE** \n声明镜像内服务监听的端口\n格式为 `EXPOSE <part> [<part/<protocol>... ]`\n例如：\nEXPOSE 22 80 8443 \n注意该指令只是起到声明作用， 并不会自动完成端口映射\n如果要映射端口出来， 在启动容器时可以使用 -P 参数 (Docker 主机会自动分配一个宿主\n机的临时端口）或-p HOST_PORT:CONTAINER_PORT 参数（具体指定所映射的本地端口）\n\n**ENV**\n指定环境变量， 在镜像生成过程中会被后续RUN指令使用， 在镜像启动的容器中也会存在\n格式为 `ENV <key> <value>或ENV <key>=<value>` \n例如：\n\n```\nENV APP VERSION=l.0.0\nENV APP_HOME=/usr/local/app \nENV PATH $PATH:/usr/local/bin \n```\n指令指定的环境变量在运行时可以被覆盖掉， 如 \n\n```\ndocker run --env <key>=<value> built_image\n```\n\n注意当一条 ENV 指令中同时为多个环境变量赋值并且值也是从环境变量读取时， 会为\n变量都赋值后再更新。 如下面的指令， 最终结果为\n\n```\nkeyl=valuel key2=value2: \nENV keyl;value2 \nENV keyl;valuel key2;${keyl) \n```\n\n**ENTRYPOINT**\n指定镜像的默认入口命令， 该入口命令会在启动容器时作为根命令执行， 所有传人值作\n为该命令的参数\n支持两种格式：\n\n```\n ENTRYPOINT [\"executable\", \"paraml \", \"param2\"]: exec 调用执行\n ENTRYPOINT command param 1 param2: shell 中执行\n```\n此时， CMD指令指定值将作为根命令的参数。\n每个 Dockerfile 中只能有一个 ENTRYPOINT, 当指定多个时， 只有最后一个起效。\n在运行时， 可以被 --entrypoint 参数覆盖掉， 如 docker run --entrypoint\n\n**VOLUME**\n创建一个数据卷挂载点。\n格式为 `VOLUME [\"/data]`\n运行容器时可以从本地主机或其他容器挂载数据卷， 一般用来存放数据库和需要保持的\n数据等。\n\n**USER**\n指定运行容器时的用户名或urn, 后续的RUN等指令也会使用指定的用户身份\n格式为 `USER daemon`\n当服务不需要管理员权限时，可以通过该命令指定运行用户， 并且可以在 Dockerfile\n建所需要的用户 例如：\n\n```\nRUN groupadd -r postgres && useradd --no-log-init -r -g postgres postgres \n```\n\n要临时获取管理员权限可以使用 gosu 命令\n\n **WORKDIR** \n为后续的 RUN CMD ENTRYPO INT 指令配置工作目录\n格式为 `WORKDIR path /to/workd ir`\n可以使用多个 WORKDIR 令，后续命令 果参数是相对路径， 会基于之前命令指定\n的路径 例如\n\n```\nWORKDIR /a \nWORKDIR b \nWORKDIR c \nRUN pwd \n```\n\n最终路径为/a/b/c\n此，为了避免出错，推荐 WORKDIR 指令中只使用绝对路\n\n **ONBUILD** \n指定当基于所生成镜像创建子镜像时，自动执行的操作指\n格式为 `ONBUILD [INSTRUCTION]`\n例如，使用如下的 Dockerfile 创建父镜像 Parent Imag ，指定 ONBUILD\n\n```\n#Dockerfile for Parentimage \n[...] \nONBUILD ADD . / app/src \nONBUILD RUN /usr / local/bin/python build --dir / app/src \n[ ... ] \n```\n\n使用 docker build 命令创建子镜像 hild Image 时（ FROM Parentimage ），会首\n先执行 Parent mage 配置的 ONBUI LD\n#\n\n```\nDockerfile for Childimage \nFROM Parenti mage \n```\n\n等价于在 Childimage Dockerfi 中添加了如下指令\n\n```\n#Automatically run the following when building Ch ldimage\n. / app/src \nRUN /usr/ ocal/ bin python-bu ld --dir /app/src \n```\n\n由于 ONBUILD 指令是隐式执行的，推荐在使用它的镜像标签中进行标注， 例如 ruby:2.l\u0002build\nONBUILD 指令在创建专门用于自动编译、检查等操作的基础镜像时，十分有用\n\n**STOPSIGNAL** \n指定所创建镜像启动的容器接收退出的信号值\n**STOPSIGNAL signal** \n\n**HEALTHCHECK** \n配置所启动容器如 进行健康检查（如 判断健康与否），自 Docker 1.12 开始支持\n格式有两种\nHEALTH HEC [OPTI ONS] CMD comma nd ：根据所执行命令返回值是否为\n判断\nHEALTHCHEC NONE ：禁 基础镜像中的健康检查\nOPTION 支持如下参数\n-interva DURAT (d e fault: 30s ）：过多久检查一次\n-timeout=DURATION (default: 30s 每次检查等待结果的超时\n-retries (de fault : 3）：如果失败了，重试几次才最终确定失败\n\n**SHELL** \n指定其他命令使用 she ll 时的默认 she ll 类型：`SHELL [” executable ”,”parameters”]` \n默认值为 ＂／ bin/sh ＂\n\n## 操作指令\n**RUN** \n运行指定命令\n格式为 `RUN <co mand ＞或 RUN [ \"executable \" , ” paraml ” , param2]`\n意后者指令会被解析为 JSON 数组，因此必须用双引号 前者默认将在 shell 终端中运行命\n令，即／ bin /sh -c 后者则使用 exec 执行，不会启动 shell 环境\n指定使用其他终端类型可以通过第二种方式实现，例如 `RUN [”/bin/bash\" , ” - C ” echo h e llo ”］`\n每条 RUN 指令将在当前镜像基础上执行指定命令，并提交为新的镜像层 当命令较长时\n可以使用＼来换行 例如：\n\n```\nRUN apt-get update \\ \n&& apt-get install -y libsnappy-dev zliblg-dev libbz2-dev \\ \n&& rm -rf /var/cache/apt \\\n&& rm rf /var/lib/apt/lists/*\n```\n **CMD** \nCMD 指令用来指定启动容器时默认执行的命令\n支持三种格式：\n`CMD ［executable ＂，” paraml param2 ＇］`：相当于执行 executable param 1 param2 ，推荐方式；\n`CMD command paraml param2` ：在默认的 Shell 中执行，提供给需要交互的应用；\n`CMD [”paraml ”，” param2` ：提供给 ENTRYPOINT 的默认参数\n每个 Dockerfile 只能有 CMD 命令 如果指定了多条命令，只有最后一条会被执行\n如果用户启动容器时候手动指定了运行的命令（作为 run命令的参数），则会覆盖掉\nCMD 指定的命令\n\n**ADD** \n添加内容到镜像\n格式为 `ADD <SrC> <dest>`\n该命令将复制指定的＜ SrC ＞路径下内容到容器中的＜dest ＞路径下\n其中＜ SrC ＞可以是 Dockerfile 所在目录的一个相对路径（文件或目录）；也可以是一个\nURL ；还可以是一个 tar 文件（自动解压为目录） <dest ＞可以是镜像内绝对路径，或者相\n对于工作目录（WORK.DIR ）的相对路径\n路径支持正则格式，例如：\n\n```\nADD *.c /code/ \n```\n\n**COPY** \n复制内容到镜像\n格式为 `COPY <SrC> <dest>`\n复制本地主机的＜ SrC> （为 Dockerfile 所在目录的相对路径，文件或目录）下内容到镜\n像中的＜dest ＞。目标路径不存在时，会自动创建路径同样支持正则格式\nCOPY与ADD指令功能类似，当使用本地目录为源目录时，推荐使用 COPY\n\n## 创建镜像\n编写完成 Docker file 之后，可以通过 `docker [image] build` 命令来创建镜像\n基本的格式为 `docker build [OPTIONS] PATH [ URL I -`\n该命令将读取指定路径下（包括子目录）的 Dockrfile ，并将该路径下所有数据作为上下\n文（ Context ）发送给 Docker 服务端 Docker 服务端在校验 Dockerfile 格式通过后，逐条执行\n其中定义的指令，碰到 ADD COPY RUN 指令会生成 层新的镜像 最终如果创建镜像成功，会返回最终镜像的 ID\n命令选项\n| 选项 | 说明 |\n|--|--|\n|-add-host list |添加自定义的主机名到IP映射 |\n|-build-arg list |添加创建时的变量                  |\n|-cache-from strings| 使用指定镜像作为缓存源       |\n|-cgroup-parent string |继承的上层 cgroup          |\n|-compress |使用gzip来压缩创建上下文数据         |\n|-cpu-period int |分配的 CFS 调度器时长            |\n|cpu-quota int |CFS 调度都总份额                    |\n|-c, cpu-shares int |CPU权重                           |\n|-cpuset-cpus string |多CPU 允许使用的CPU             |\n|-cpuset-mems string |多CPU允许使用的内存               |\n|-disable-content-trust |不进行镜像校验，默认为真  |\n|-f, -file string | Dockerfile 名称              |\n|-force-rm |总是删除中间过程的容器                    |\n|-iidfile string |将镜像ID写入到文件          |\n|-isolation string |容器的隔离机制                 |\n|-label list | 配置镜像的元数据                     |\n|-m,-memory bytes |限制使用内存盘                |\n|memory-swap bytes | 限制内存和缓存的总盐           |\n|-network string |指定RUN命令时的网络模式        |\n|-no-cache |创建镜像不适用缓存                       |\n|-platform string | 指定平台类型                    |\n|-pull  |总是尝试获取镜像的最新版本                  |\n|-q, -quiet | 不打印创建过程中的日志信息            |\n|-rm | 创建成功后自动删除中间过程容器，默认为真      |\n|-security-opt strings  |指定安全相关的选项        |\n|-shm-size bytes| /dev/shm 的大小                  |\n|-squash |将新创建的多层挤压放入到一层            |\n|-stream | 持续获取创建的上下文                    |\n|-t, -tag list |指定镜像的标签列表                |\n|target string | 指定创建的目标阶段                 |\n|-ulimit ulmit |指定 ulimit 的配置                |\n\n## 选择父镜像\n大部分情况下，生成新的镜像都需要通过 FROM 指令来指定父镜像 父镜像是生成镜像\n的基础，会直接影到所生成镜像的大小和功能,用户可 选择两种镜像作为父镜像，一种是所谓的基础镜像（ baseiage ），另外一种普通的镜像（往往由第三方创建，基于基础镜像）镜像较特殊，其 Dockerfile 中往往不存在指令，或者基于 scratch 镜像(FROM scratch ），这意味着其在整个镜像树中处于根的位置\n下面的 Dockerfile定义了 个简单的基础镜像，将用户提前编译好的二进制 可执行文件binary到镜像中，运行容器 执行 inary 命令：\n\n```bash\nFROM scratch \nADD binary /\nCMD ［\"binary\"]\n```\n\n普通镜像也可以作为父镜像来使用， 括常见的 busybox debian ubuntu\n\n## 使用 dockerigno 文件\n通过 .dockerignore文件（每一行添 一条匹配模式）来让 Docker忽略匹配路径或或文件，在建镜像时候不将无关数据发送到服务端\ndockerignore 文件中模式语法支持 Golang 风格的路径正则格式：\n“＊”表示任意多个字符；\n“？”代表单个字符；\n“！”表示不匹配（即不忽略指定的路径或文件）\n\n\n\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/103848953](https://blog.csdn.net/qq_20340547/article/details/103848953)","source":"_posts/book/2020-01-12-16.md","raw":"---\ntitle: docker摘记-docker相关知识点总结摘要\ndate: 2020-01-12 16:47:54\ntags: Docker\ncategories: 看书摘记\n---\nDocker 是基于 Go 语言实现的开源容器项目,Docker 的构想是要实现“ Build Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging ）、分发（ Distribution ）、部署（ Deployment ）、运行（ Runtime ）生命周期进行管理达到应用组件级别的“一次封装 ，到处运行”,Docker 也并非“从石头缝里蹦出来的”而是站在巨人的肩膀上,其中最重要的就是 Linux 容器(Linux Containers, LXC)技术.\n...\n<!--more-->\n# Docker是啥?\n\nDocker 是基于 Go 语言实现的开源容器项目,Docker 的构想是要实现“ Build Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging ）、分发（ Distribution ）、部署（ Deployment ）、运行（ Runtime ）生命周期进行管理达到应用组件级别的“一次封装 ，到处运行”,Docker 也并非“从石头缝里蹦出来的”而是站在巨人的肩膀上,其中最重要的就是 Linux 容器(Linux Containers, LXC)技术.\n\n# Docker优点\n\n更快速的交付和部署\n更高效的资源利用;\n更轻松地迁移和拓展;\n更简单的更新管理\n\n# Docker与虚拟机的比较\n\nDocker 容器很快，启动和停止可以在秒级实现，这相比传统的虚拟机方式（数分钟）要快得多；\nDocker 容器对系统资源需求很少，一台主机上可以同时运行数千个 Docker 容器（在\nIBM 服务器上已经实现了同时运行！ OK 量级的容器实例）；\nDocker 通过类似 Git 设计理念的操作来方便用户获取、分发和更新应用镜像，存储复\n用，增量更新；\nDocker 通过 Dockerfile 支持灵活的自动化创建和部署机制，以提高工作效率，并标准\n化流程\n\n# Docker 三大核心观念\n\n**镜像(Image)**:类似于虚拟机镜像,看做一个只读模板,镜像是docker的基础\n\n**容器(Container)**:容器类似于一个轻级的沙箱,Docker 利用容器来运行和隔离应用,容器是从镜像创建的应用运行实例它可以启动、开始、停止 删除，而这些容器都是彼此相互隔离、互不可见的\n\n**仓库(Repository)**:仓库类似于代码仓库,是Docker集中存放镜像文件的场所.\n\n# Docker Centos安装\n\nDocker 目前支持 CentOS 及以后的版本 系统的要求跟 Ubuntu 情况类似， 64 位操作\n系统，内核版本至少为 3.10\n\n```bash\n首先，为了方便添加软件源，以及支持 devicemapper 存储类型，安装如下软件包：\n$ sudo yum update \n$ sudo yum instal l -y yum-utils \\ device-mapper-persistent-data \\ lvm2 \n添加Dokcker 稳定版本的 yum 软件源：\n$ sudo yum-conf ig- manager \\ --add-repo https : //download.docker.corn/linux/centos/ docker-ce.repo \n之后更新 yum 软件源缓存，并安装 Docker:\n$ sudo yum update \n$ sudo yum install -y docker-ce \n最后，确认 Docker 服务启动正常\n$ sudo systernctl start docker\n用户还可以使用官方提供的 shell 脚本来在 Linux 系统（目前支持山untu Debian Oracleserv edora Centos OpenSuse Gentoo 等常 发行版）上安装 Docker 最新正式版本，该脚本会自动检测系统信息并进行相应配置：\n$ curl -fsSL https: //get.docker . corn/ I sh \n或者\n$ wget - qO- https://get . docker.corn/ I sh \n如果想尝鲜最新功能，可以使用下面的脚本来安装最新的“尝鲜”版本 但要注意，非稳定版本往往意味着功能还不够稳定，不要在生产环境中使用\n$ curl -fsSL https : //test.docker .corn/ I sh \n另外， 也可以从 store docker.com/search?offering=community&q &type=edition 找到各个平台上的 Docker 安装包，自行下载使用\n其他操作系统可根据官网进行下载安装\n```\n\n# Docker 镜像常用命令\n## 获取镜像\n**命令:docker [image] pull NAME [ :TAG]** \nNAME 是镜像仓库名称（用来区分镜像）,TAG 是镜像的标签（往往用来表示版本信息）。 通常情况下， 描述一个镜像需要包括 “名称＋标签“ 信息,如果不显式指定TAG, 则默认会选择la迳釭标签，这会下载仓库中最新版本的镜像。严格地讲，镜像的仓库名称中还应该添加仓库地址（即registry, 注册服务器）作为前\n缀 ，只是默认使用的是官方DockerHub服务 ，该前缀可以忽略\npull 子命令支持的 选项主要包括：\n\t -a, --all tags=trueifalse: 是否获取仓库中的所有镜像，默认为否\n\t --disable-conyent-trust：取消镜像的内容校验，默认为真\n## 查看镜像信息\n**命令:docker images或docker image ls**\n可以列出本地主机上已有镜像的基本信息\nimages子命令主要支持如下选项， 用户可以自行进行尝试：\n\t-a, --all true I false: 列出所有（包括临时文件）镜像文件，默认为否\n\t--digestS=trueifalse: 列出镜像的数字摘要值，默认为否\n\t-f, --filter=[] : 过滤列出的镜像， 如dangling 式rue 只显示没有被使用的镜像,也可指定带有特定标注的镜像等\n\t--format=\"TEMPLATE\" : 控制输出格式，如. ID代表ID信息，.Repository代表仓库信息等\n\t--no-trunc=true |false: 对输出结果中太长的部分是否进行截断，如镜像的ID信息，默认为是\n\t-q, --quiet=true |false: 仅输出ID信息， 默认为否。\n\t其中， 还支持对输出结果进行控制的选项，如 -f. --filter=[]、--no-trunc =true | false、 -q、 --quiet=true | false等。\n更多子命令选项还可以通过mandocker-images来查看\n\n**命令:docker[image]inspect**\n获取该镜像的详细信息，包括制作者 、 适应架构、各层的数字摘要等\n\n**命令:docker history** \n获取该镜像的历史信息\n\n## 搜索镜像\n**命令:docker search [option] keyword**\n搜索镜像\n支持的命令选项主要包括：\n\t -f, --filer filter: 过滤输出内容\n\t --format string: 格式化输出内容\n\t --limit int：限制输出结果个数，默认为 25 个\n\t --no-trunc: 不截断输出结果\n## 删除和清理镜像\n**命令:docker rmi 或 docker image rm** \n可以删除镜像\ndocker rmi IMAGE [IMAGE ... ] 其中 IMAGE可以为标签或 ID\n支持选项包括：\n\t-f, -force: 强制删除镜像， 即使有容器依赖它\n\t-no-prune: 不要清理未带标签的父镜像\n\n**命令:docker ps -a** \n看到本机上存在的所有容器\n\n**命令:docker image prune** \n来进行清理删除镜像\n支待选项包括：\n\t -a, -all: 删除所有无用镜像， 不光是临时镜像\n\t -filler filler: 只清理符合给定过滤器的镜像\n\t -f, -force: 强制删除镜像， 而不进行提示确认\n## 创建镜像\n**命令:docker [container] commit [OPTIONS] CONTAINER [REPOSITORY [:TAG]]** \n基于已有容器创建镜像\n主要选项包括：\n\t-a, --author=\"\": 作者信息\n\t-c, --change=[] : 提交的时候执行Dockerfile指令， 包括 CMDIENTRYPOINT 但NVIEXPOSEILABELIONBUILDIUSERIVOLUMEIWORKDIR等\n\t-m, --message= \"\": 提交消息\n\t-p, --pause式rue: 提交时暂停容器运行\n\n**命令: docker [image] i mport [OPTIONS] filelURLl -[REPOSITORY [:TAG] ]**\n基于本地模板导入镜像\n\n**基于dockerfile创建镜像,可在官网了解相关知识点**\n\n## 存出和载人镜像\n**命令:docker [image ] save docker [image ] load** \n来存出和载人镜像\n\n**命令:docker [image] push [:TAG] | [REGISTRY_HOST [ :REGISTRY_PORT] / ]NAME [:TAG]**\n上传镜像到仓库，默认上传到 Docker Hub 官方仓库（需要登录）\n\n# Docker 容器常用命令\n## 创建容器\n**命令:docker [container] create** \n命令新建一个容器,使用 docker [container] create 命令新建的容器处于停止状态，可以使用 docker[container] start 命令来启动它,create命令较为强大,可以看相关文档地址:**https://docs.docker.com/engine/reference/commandline/create/**\n\n**命令: docker [container] start** \n来启动一个已经创建的容器\n\n**命令:docker ps**\n可以查看到运行中的容器\n\n**命令: docker [container ］run**\n新建并启动容器\n等价于先执行 docker [container] create 命令,再执行 docker [container] start 命令,\nDocker 在后台运行的标准操作包括：\n\t检查本地是否存在指定的镜像，不存在就从公有仓库下载\n\t利用镜像创建一个容器，并启动该容器\n\t分配 个文件系统给容器，并在只读的镜像层外面挂载一层可读写层\n\t从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n\t从网桥的地址池配置一个 IP 地址给容器\n\t执行用户指定的应用程序\n\t执行完毕后容器被自动终止\n\t\n**命令:docker [container] logs**\n查看容器输出信息\n该命令支持的选项包括：\n\t－details 打印详细信息；\n\t－f, follo ：持续保持输出；\n\t一since string ：输出从某个时间开始的日志；\n\t－tail string 输出最近的若干日志；\n\t－t, timestamps 显示时间戳信息\n\t－until string 输出某个时间之前的日\n## 停止容器\n**命令:docker [container] pause CONTAINER [CONTAINER ...]**\n暂停一个运行中的容器\n\n**命令:docker [contai er pause CONTAINER [CONTAINER ...]**\n来恢复到运行状态\n\n**命令:docker [container] stop [-t I - -time [=10]] [CONTAiNER ...]**\n来终止一个运行中的容器,该命令会首先向容器发送 SIGTERM 信号,等待一段超时时间后（默认为 10 秒）,再发\nSIGKLL 信号来终止容器\n\n**命令:docker container prune**\n会自动清除掉所有处于停止状态的容器\n\n**命令:docker [container] kill**\n直接发送 SIGKILL 信号来强行终止容器\n\n**命令:docker ps -qa** \n查看到所有容器的ID\n\n**命令:docker [container] start**\n重新启动容器\n\n**命令:docker [container] restart** \n命令会将一个运行态 的容器先终止，然后再重新启动\n\n## 进入容器\n\n**命令:docker [container] attach [--detach-keys[;[]]] [--no-stdin] [--sig-proxy[;true]] CONTAINER**\n命令支持三个主要选项：\n－－ detach-keys ［＝［］］：指定退出 attach 模式的快捷键序列， 默认是 CTRL-p CTRL-q;\n－－ no-stdin=trueifalse ：是否关闭标准输入，默认是保持打开\n－－ sig-proxy=truelfalse ：是否代理收到的系统信号给应用进程，默认为 true\n\n**命令:docker [container] exec [-d|-detach] [ detach-keys[=[]]] [-i|--interactive] [ --privileged] [-t|--tty] [-u|user [=USER]] CONTAINER COMMAND [ARG . . . ]**\n比较重要的参数有：\n－ d, --detach 在容器中后台执行命令\n－－ detach-keys =＂＂：指定将容器切回后台的按键\n－ e, - - env= []：指定环境变量列表\n－ i, --interactive=true | false ：打开标准输入接受用户输入命令， 默认值为false \n－－ privileged=true|false 是否给执行命令以高权限，默认值为 false\n－ t, --tty=true|false 分配伪终端，默认值为 false\n－ u, --user =\"\"：执行命令的用户名或 ID\n\n## 删除容器\n\n**命令:docker [container) rm [-f|-- force) [-1|-link] [-v|--volumes] CONTAINER [CONTAINER ...]**\n支持的选项包括\n－ f, --force=false 是否强行终止并删除一个运行中的容器\n－ 1, --link=false ：删除容器的连接 ，但保留容器\n－ v, --volumes=false ：删除容器挂载的数据卷\n\n## 导人和导出容器\n\n**命令:docker [container) export [-o|--output [=””] ] CONTAINER**\n导出容器是指，导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态\n－o 选项来指定导出的tar 文件名，也可以直接通过重定向来实现\n\n**命令:docker import [-c|--change[=[]]] [-m|--message[=MESSAGE]] file|URL|-[REPOSITORY [:TAG]]**\n导入容器\n\n## 查看容器\n\n**命令:用 docker container inspect [OPTIONS] CONTAINER [CONTAINER . .. ］**\n查看容器详情\n\n**命令:docker [container] top [OPTIONS] CONTAINER [CONTAINER...]**\n查看容器内进程\n\n\n**命令:docker [container] stats [OPTIONS] [CONTAINER ... ]**\n查看统计信息,会显示 CPU 、内存、存储、网络等使用情况的统计信息\n支持选项包括\n－ a, -all ：输出所有容器统计信息，默认仅在运行中\n－ format string ：格式化输出信息\n－ no-stream ：不持续输出，默认会自动更新持续实时结果\n－ no-trunc ：不截断输出信息\n\n## 其他容器命令\n\n**命令格式为 docker [container] cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-** \n复制文件\n支持的选项包括\n－ a, -ar chive ：打包模式，复制文件会带有原始的 uid/gid 信息\n－ L, -follow-link ：跟随软连接。当原路径为软连接时＼默认只复制链接信息,使用该选项会复制链接的目标内容\n\n**命令: docker [container] diff CONTAINER**\n查看变更\n\n**命令:docker container port CONTAINER [PRIVATE_PORT[/PROTO ］］**\n查看端口映射\n\n**命令:docker [container] update [OPTIONS] CONTAINER [CONTAINER ...]**\n支持的选项包括：\n－blkio-weight uintl6 ：更新块 IO 限制， 10 1000 ，默认值为 ，代表着无限制\n－ cpu-period int ：限制 CPU 调度器 CFS (Completely Fair Scheduler ）使用时间，单位为微秒，最小 1000\n－ cpu-quota int ：限制 CPU 调度器 CFS 配额，单位为微秒，最小 1000\n－ cpu-rt period int ：限制 CPU 调度器的实时周期，单位为微秒\n－ cpu-rt runtime int ：限制 CPU 调度器的实时运行时，单位为微秒\n－ c, -cpu-shares in 限制 CPU 使用份额\n－ cpus decimal ：限制 CPU 个数\n－ cpuset-cpus string ：允许使用的 CPU 核，如 0-3, 0,1\n－ cpuset mems string ：允许使用的内存块，如 0-3' 0, 1\n－ kernel-memor bytes ：限制使用的内核内存\n－ m, -memory bytes 限制使用的内存\n－memory-reservation bytes ：内存软限制\n－memory-swap bytes ：内存加上缓存区的限制， 表示为对缓冲区无限制\n－ restart stri 口g 容器退出后的重启策略\n# Docker仓库\n**仓库(Repository)**是集中存放镜像的地方，又分公共仓库和私有仓库\n## Docker Hub 公共镜像市场\n**Docker Hub Docker** 官方提供的最大的公共镜像仓库，目前包括了超过 100 000\n像，地址为 **https: //hub.docker.com**\n\n# Docker数据管理\n容器中的管理数据主要有两种方式\n**数据卷 Data Volumes)** 容器内数据直接映射到本地主机环境；\n**数据卷容器（Data Volume Containers)** 使用特定容器维护数据卷\n## 数据卷\n**数据卷 Data Volumes** 是一个可供容器使用的特殊目录，它将主机操作系统目录直接\n映射进容器，类似于 Linux 中的 mout 行为\n**数据卷可以提供很多有用的特性\n\t数据卷可以在容器之间共事和重用，容器间传递数据将变得高效与方便\n\t对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作\n\t对数据卷的更新不会影响镜像，解摘开应用和数据会一直存在 ，直到没有容器使用，可以安心地卸载它**\n## 创建数据卷\n**命令:docker volume create** \n## 绑定数据卷\n**命令:docker [container] run口命令的时候，可以使用 mount 选项来使用数据卷**\nmount 项支持三种类型的数据卷，包括\n\tvolume 普通数据卷，映射到主机／var/ lib /docke /vo lumes 径下\n\tbind ：绑定数据卷，映射到主机指定路径下\n\ttmpfs ：临时数据卷，只存在于内存中\n## 数据卷容器\n**命令:docker run -it --volumes-from dbdata --name dbl ubuntu**\n可以在其他容器中使用－－ volumes-from 来挂载 dbdata 容器中的数据卷，例如如创建 dbl db2 两个容器，并从 dbdata 容器挂载数据卷\n\n**命令:docker rm -v**\n删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用此命令,指定同时删除关联的容器\n\n## 利用数据卷容器来迁移数据\n**命令:docker run -volumes-from dbdata -v $ (pwd) : /backup - -name worker ubuntu tar \ncvf /backup/backup.tar /dbdata**\n利用 buntu 镜像创建了 个容器 worker 使用－ -volumes-from dbdata 参数\n来让 worker 容器挂载 db data 容器的数据卷（ dbdata 数据卷）；使用－ $ (pwd) : /backup \n参数来挂载本地的当前目录到 worke 容器的／backup\nworker 容器启动后，使用 tar cvf /backup/backup.tar /dbdata 令将／dbdata\n下内容备份为容器内的／backup/backup. tar ，即宿主主机当前目录下的 backup.tar\n\n**命令：docker run -v /dbdata --name dbdata2 ubuntu /bin/bash\ndocker run --volumes-from dbdata2 -v $(pwd) :/backup busybox tar xvf \n/backup/backup.tar**\n首先创建一个带有数据卷的容器 bdata2:，然后创建另一个新的容器，挂载 dbdata2 容器，并使用 untar 解压备份文件到所挂载的容器卷中\n\n# 端口映射与容器互联\n**命令:docker run -d -P training/webapp python app.py**\n当容器中运行一些网络应用， 要让外部访问这些应用时， 可以通过-P或-p参数来指定端口映射。 当使用平（大写的）标记时， Docker 会随机映射一个 49000-49900 的端口到内部容器开放的网络端口,-p (小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定 一个容器。支持的格式有IP:HostPort:ContainerPortI IP:: ContainerPort I HostPort:ContainerPort\n\n**命令;docker run -d -p 5000:5000 training/webapp python app.py**\n使用HostPort： ContainerPot格式本地的5000端口映射到容器的5000端口 \n多次使用-p标记可以绑定多个端口。例如:docker run -d -p 5000:5000 -p 3000:80 training/webapp py thon app.py\n\n**命令:docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py**\n可以使用IP:HostPort： ContainerPort格式指定映射使用一个特定地址，比如\nlocalhost地址127.0.0.1\n\n**命令: docker run -d -p 127.0.0.1::5000 training/webapp python app.py** \n使用IP::ContainerPort绑定localhost的任意端口到容器的5000端口，本地主机\n会自动分配一个端口：还可以使用udp标记来指定 udp端口：\n docker run -d -p 127.0.0.1:5000:5000/udp training/webapp PY七hon app.py\n \n**命令: docker port nos talgic_rnorse 5000**\n使用docker port来查看当前映射的端口配置，也可以查看到绑定的地址\n\n# 互联机制实现便捷互访\n**容器的互联(Iinking)**是一种让多个容器中的应用进行快速交互的方式。它会在源和接收容\n器之间创建连接关系，接收容器可以通过容器名快速访问到源容器，而不用指定具体的IP地址\n\n**命令:docker run -d -P --name web training/webapp python app.py**\n使用--name标记可以为容器自定义命名\n\n**命令:docker run -d -P --name web --link db:db taining/webapp python app.py**\n创建一个新的web容器，并将它连接到db容器,db容器和web容器建立互联关系。\n--link参数的格式为--link name: alias, 其中name是要链接的容器的名称 ,alias是别名\n\n# 使用Dockerfile创建镜像\nDockerfile 是一个文本格式的配置文件， 用户可以使用 Dockerfile 来快速创建自定义的镜像\n\n## 基本结构\nDockerfile 由一行行命令语句组成， 并且支持以＃开头的注释行。一般而言， \nDockerfile 主体内容分为四部分：**基础镜像信息**、 **维护者信息**、 **镜像操作指令**和**容器启动时执行指令**\n\n下面就是一个例子\n\n```bash\n#This dockerfile uses the ubuntu image\n#VERSION 2 - EDITION 1\n#Author: docker_user\n#Command format: Instruction [arguments / command] ..\n#1、第一行必须指定 基础镜像信息\nFROM ubuntu\n\n#2、维护者信息\nMAINTAINER docker_user docker_user@email.com\n\n#3、镜像操作指令\nRUN echo \"deb http://archive.ubuntu.com/ubuntu/ raring main universe\" >> /etc/apt/sources.list\nRUN apt-get update && apt-get install -y nginx\nRUN echo \"\\ndaemon off;\" >> /etc/nginx/nginx.conf\n \n#4、容器启动执行指令\nCMD /usr/sbin/nginx\n```\n首行可以通过注释来指定解析器命令， 后续通过注释说明镜像的相关信息。 主体部分首\n先使用FROM指令指明所基于的镜像名称， 接下来一般是使用LABEL指令说明维护者信息。\n后面则是镜像操作指令， 例如RUN指令将对镜像执行跟随的命令。 每运行一条RUN指令，\n镜像添加新的一层， 并提交。 最后是CMD指令， 来指定运行容器时的操作命令\n\n## 指令说明\nDockerfile 中指令的一般格式为 INSTRUCTION arguments, 包括 “配置指令\" (配置\n镜像信息）和 “操作指令\" (具体执行操作）， 参见下表 \nDockerfile中的指令及说明\n分 类 指 令 说 明\n| 分类 | 指令 | 说明 |\n|--|--|--|\n|配置指令  | ARG | 定义创建镜像过程中使用的变簸 |\n| 配置指令|FROM |指定所创建镜像的基础镜像|\n| 配置指令|LABEL |为生成的镜像添加元数据标签信息|\n| 配置指令|EXPOSE |声明镜像内服务监听的端口|\n|配置指令 |ENV| 指定环境变抵|\n| 配置指令|ENTRYPOINT |指定镜像的默认入口命令|\n|配置指令|VOLUME |创建一个数据卷挂载点|\n|配置指令|USER |指定运行容器时的用户名或UID|\n|配置指令|WORKDIR |配置工作目录|\n|配置指令|ONBUILD| 创建子镜像时指定自动执行的操作指令|\n|配置指令|STOPSIGNAL| 指定退出的信号值|\n|配置指令|HEALTH CHECK |配置所启动容器如何进行健康检查|\n|配置指令|SHELL |指定默认shell类型|\n|操作指令|RUN|运行指定命令|\n|操作指令|CMD|启动容器时刻指定默认执行程序|\n|操作指令|ADD|添加内容到镜像|\n|操作指令|COPY |复制内容到镜像|\n\n## 配置指令\n**ARG**\n定义创建镜像过程中使用的变量。\n格式为 `ARG <name>[=<default value>]`\n在执行 docker build 时， 可以通过 -build-arg[=] 来为变量赋值。 当镜像编译成\n功后， ARG 指定的变量将不再存在 (ENV 指定的变量将在镜像中保留）\nDocker 内置了一些镜像创建变量， 用户可以直接使用而无须声明， 包括（不区分大小\n写） HTTP PROXY 、 HTTPS PROXY 、 FTP PROXY 、 NO PROXY\n\n**FROM**\n指定所创建镜像的基础镜像\n格式为:`FROM <image> [AS <name>]` 或 `FROM <image>: <tag> [AS <name>]` \n或`FROM <image>@<digest> [AS <name>]` \n任何 Dockerfile 中第一条指令必须为FROM 指令。 并且， 如果在同一个Dockerfile 中创\n建多个镜像时， 可以使用多个 FROM 指令（每个镜像一次）\n为了保证镜像精简， 可以选用体积较小的镜像如Alpine或Debian 作为基础镜像。 例如：\n\n```\nARG VERSION=9.3 \nFROM debian:${VERSION} \n```\n\n**LABEL**\nLABEL 指令可以为生成的镜像添加元数据标签信息。 这些信息可以用来辅助过滤出特\n定镜像。\n格式为: `LABEL <key>=<value> <key>=<value> <key>=<value> ...`\n例如：\n\n```\nLABEL version=\"l.0.0-rc3\" \nLABEL author=\"yeasy@github\" date=\"2020-01-01\" \nLABEL description=\"This 七ex七 illustra七es\\\nthat label-values can span mul七iple lines.\" \n```\n\n**EXPOSE** \n声明镜像内服务监听的端口\n格式为 `EXPOSE <part> [<part/<protocol>... ]`\n例如：\nEXPOSE 22 80 8443 \n注意该指令只是起到声明作用， 并不会自动完成端口映射\n如果要映射端口出来， 在启动容器时可以使用 -P 参数 (Docker 主机会自动分配一个宿主\n机的临时端口）或-p HOST_PORT:CONTAINER_PORT 参数（具体指定所映射的本地端口）\n\n**ENV**\n指定环境变量， 在镜像生成过程中会被后续RUN指令使用， 在镜像启动的容器中也会存在\n格式为 `ENV <key> <value>或ENV <key>=<value>` \n例如：\n\n```\nENV APP VERSION=l.0.0\nENV APP_HOME=/usr/local/app \nENV PATH $PATH:/usr/local/bin \n```\n指令指定的环境变量在运行时可以被覆盖掉， 如 \n\n```\ndocker run --env <key>=<value> built_image\n```\n\n注意当一条 ENV 指令中同时为多个环境变量赋值并且值也是从环境变量读取时， 会为\n变量都赋值后再更新。 如下面的指令， 最终结果为\n\n```\nkeyl=valuel key2=value2: \nENV keyl;value2 \nENV keyl;valuel key2;${keyl) \n```\n\n**ENTRYPOINT**\n指定镜像的默认入口命令， 该入口命令会在启动容器时作为根命令执行， 所有传人值作\n为该命令的参数\n支持两种格式：\n\n```\n ENTRYPOINT [\"executable\", \"paraml \", \"param2\"]: exec 调用执行\n ENTRYPOINT command param 1 param2: shell 中执行\n```\n此时， CMD指令指定值将作为根命令的参数。\n每个 Dockerfile 中只能有一个 ENTRYPOINT, 当指定多个时， 只有最后一个起效。\n在运行时， 可以被 --entrypoint 参数覆盖掉， 如 docker run --entrypoint\n\n**VOLUME**\n创建一个数据卷挂载点。\n格式为 `VOLUME [\"/data]`\n运行容器时可以从本地主机或其他容器挂载数据卷， 一般用来存放数据库和需要保持的\n数据等。\n\n**USER**\n指定运行容器时的用户名或urn, 后续的RUN等指令也会使用指定的用户身份\n格式为 `USER daemon`\n当服务不需要管理员权限时，可以通过该命令指定运行用户， 并且可以在 Dockerfile\n建所需要的用户 例如：\n\n```\nRUN groupadd -r postgres && useradd --no-log-init -r -g postgres postgres \n```\n\n要临时获取管理员权限可以使用 gosu 命令\n\n **WORKDIR** \n为后续的 RUN CMD ENTRYPO INT 指令配置工作目录\n格式为 `WORKDIR path /to/workd ir`\n可以使用多个 WORKDIR 令，后续命令 果参数是相对路径， 会基于之前命令指定\n的路径 例如\n\n```\nWORKDIR /a \nWORKDIR b \nWORKDIR c \nRUN pwd \n```\n\n最终路径为/a/b/c\n此，为了避免出错，推荐 WORKDIR 指令中只使用绝对路\n\n **ONBUILD** \n指定当基于所生成镜像创建子镜像时，自动执行的操作指\n格式为 `ONBUILD [INSTRUCTION]`\n例如，使用如下的 Dockerfile 创建父镜像 Parent Imag ，指定 ONBUILD\n\n```\n#Dockerfile for Parentimage \n[...] \nONBUILD ADD . / app/src \nONBUILD RUN /usr / local/bin/python build --dir / app/src \n[ ... ] \n```\n\n使用 docker build 命令创建子镜像 hild Image 时（ FROM Parentimage ），会首\n先执行 Parent mage 配置的 ONBUI LD\n#\n\n```\nDockerfile for Childimage \nFROM Parenti mage \n```\n\n等价于在 Childimage Dockerfi 中添加了如下指令\n\n```\n#Automatically run the following when building Ch ldimage\n. / app/src \nRUN /usr/ ocal/ bin python-bu ld --dir /app/src \n```\n\n由于 ONBUILD 指令是隐式执行的，推荐在使用它的镜像标签中进行标注， 例如 ruby:2.l\u0002build\nONBUILD 指令在创建专门用于自动编译、检查等操作的基础镜像时，十分有用\n\n**STOPSIGNAL** \n指定所创建镜像启动的容器接收退出的信号值\n**STOPSIGNAL signal** \n\n**HEALTHCHECK** \n配置所启动容器如 进行健康检查（如 判断健康与否），自 Docker 1.12 开始支持\n格式有两种\nHEALTH HEC [OPTI ONS] CMD comma nd ：根据所执行命令返回值是否为\n判断\nHEALTHCHEC NONE ：禁 基础镜像中的健康检查\nOPTION 支持如下参数\n-interva DURAT (d e fault: 30s ）：过多久检查一次\n-timeout=DURATION (default: 30s 每次检查等待结果的超时\n-retries (de fault : 3）：如果失败了，重试几次才最终确定失败\n\n**SHELL** \n指定其他命令使用 she ll 时的默认 she ll 类型：`SHELL [” executable ”,”parameters”]` \n默认值为 ＂／ bin/sh ＂\n\n## 操作指令\n**RUN** \n运行指定命令\n格式为 `RUN <co mand ＞或 RUN [ \"executable \" , ” paraml ” , param2]`\n意后者指令会被解析为 JSON 数组，因此必须用双引号 前者默认将在 shell 终端中运行命\n令，即／ bin /sh -c 后者则使用 exec 执行，不会启动 shell 环境\n指定使用其他终端类型可以通过第二种方式实现，例如 `RUN [”/bin/bash\" , ” - C ” echo h e llo ”］`\n每条 RUN 指令将在当前镜像基础上执行指定命令，并提交为新的镜像层 当命令较长时\n可以使用＼来换行 例如：\n\n```\nRUN apt-get update \\ \n&& apt-get install -y libsnappy-dev zliblg-dev libbz2-dev \\ \n&& rm -rf /var/cache/apt \\\n&& rm rf /var/lib/apt/lists/*\n```\n **CMD** \nCMD 指令用来指定启动容器时默认执行的命令\n支持三种格式：\n`CMD ［executable ＂，” paraml param2 ＇］`：相当于执行 executable param 1 param2 ，推荐方式；\n`CMD command paraml param2` ：在默认的 Shell 中执行，提供给需要交互的应用；\n`CMD [”paraml ”，” param2` ：提供给 ENTRYPOINT 的默认参数\n每个 Dockerfile 只能有 CMD 命令 如果指定了多条命令，只有最后一条会被执行\n如果用户启动容器时候手动指定了运行的命令（作为 run命令的参数），则会覆盖掉\nCMD 指定的命令\n\n**ADD** \n添加内容到镜像\n格式为 `ADD <SrC> <dest>`\n该命令将复制指定的＜ SrC ＞路径下内容到容器中的＜dest ＞路径下\n其中＜ SrC ＞可以是 Dockerfile 所在目录的一个相对路径（文件或目录）；也可以是一个\nURL ；还可以是一个 tar 文件（自动解压为目录） <dest ＞可以是镜像内绝对路径，或者相\n对于工作目录（WORK.DIR ）的相对路径\n路径支持正则格式，例如：\n\n```\nADD *.c /code/ \n```\n\n**COPY** \n复制内容到镜像\n格式为 `COPY <SrC> <dest>`\n复制本地主机的＜ SrC> （为 Dockerfile 所在目录的相对路径，文件或目录）下内容到镜\n像中的＜dest ＞。目标路径不存在时，会自动创建路径同样支持正则格式\nCOPY与ADD指令功能类似，当使用本地目录为源目录时，推荐使用 COPY\n\n## 创建镜像\n编写完成 Docker file 之后，可以通过 `docker [image] build` 命令来创建镜像\n基本的格式为 `docker build [OPTIONS] PATH [ URL I -`\n该命令将读取指定路径下（包括子目录）的 Dockrfile ，并将该路径下所有数据作为上下\n文（ Context ）发送给 Docker 服务端 Docker 服务端在校验 Dockerfile 格式通过后，逐条执行\n其中定义的指令，碰到 ADD COPY RUN 指令会生成 层新的镜像 最终如果创建镜像成功，会返回最终镜像的 ID\n命令选项\n| 选项 | 说明 |\n|--|--|\n|-add-host list |添加自定义的主机名到IP映射 |\n|-build-arg list |添加创建时的变量                  |\n|-cache-from strings| 使用指定镜像作为缓存源       |\n|-cgroup-parent string |继承的上层 cgroup          |\n|-compress |使用gzip来压缩创建上下文数据         |\n|-cpu-period int |分配的 CFS 调度器时长            |\n|cpu-quota int |CFS 调度都总份额                    |\n|-c, cpu-shares int |CPU权重                           |\n|-cpuset-cpus string |多CPU 允许使用的CPU             |\n|-cpuset-mems string |多CPU允许使用的内存               |\n|-disable-content-trust |不进行镜像校验，默认为真  |\n|-f, -file string | Dockerfile 名称              |\n|-force-rm |总是删除中间过程的容器                    |\n|-iidfile string |将镜像ID写入到文件          |\n|-isolation string |容器的隔离机制                 |\n|-label list | 配置镜像的元数据                     |\n|-m,-memory bytes |限制使用内存盘                |\n|memory-swap bytes | 限制内存和缓存的总盐           |\n|-network string |指定RUN命令时的网络模式        |\n|-no-cache |创建镜像不适用缓存                       |\n|-platform string | 指定平台类型                    |\n|-pull  |总是尝试获取镜像的最新版本                  |\n|-q, -quiet | 不打印创建过程中的日志信息            |\n|-rm | 创建成功后自动删除中间过程容器，默认为真      |\n|-security-opt strings  |指定安全相关的选项        |\n|-shm-size bytes| /dev/shm 的大小                  |\n|-squash |将新创建的多层挤压放入到一层            |\n|-stream | 持续获取创建的上下文                    |\n|-t, -tag list |指定镜像的标签列表                |\n|target string | 指定创建的目标阶段                 |\n|-ulimit ulmit |指定 ulimit 的配置                |\n\n## 选择父镜像\n大部分情况下，生成新的镜像都需要通过 FROM 指令来指定父镜像 父镜像是生成镜像\n的基础，会直接影到所生成镜像的大小和功能,用户可 选择两种镜像作为父镜像，一种是所谓的基础镜像（ baseiage ），另外一种普通的镜像（往往由第三方创建，基于基础镜像）镜像较特殊，其 Dockerfile 中往往不存在指令，或者基于 scratch 镜像(FROM scratch ），这意味着其在整个镜像树中处于根的位置\n下面的 Dockerfile定义了 个简单的基础镜像，将用户提前编译好的二进制 可执行文件binary到镜像中，运行容器 执行 inary 命令：\n\n```bash\nFROM scratch \nADD binary /\nCMD ［\"binary\"]\n```\n\n普通镜像也可以作为父镜像来使用， 括常见的 busybox debian ubuntu\n\n## 使用 dockerigno 文件\n通过 .dockerignore文件（每一行添 一条匹配模式）来让 Docker忽略匹配路径或或文件，在建镜像时候不将无关数据发送到服务端\ndockerignore 文件中模式语法支持 Golang 风格的路径正则格式：\n“＊”表示任意多个字符；\n“？”代表单个字符；\n“！”表示不匹配（即不忽略指定的路径或文件）\n\n\n\n[本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/103848953](https://blog.csdn.net/qq_20340547/article/details/103848953)","slug":"book/2020-01-12-16","published":1,"updated":"2020-01-12T09:01:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckgnsue2s001jbcvzd97a7n0u","content":"<p>Docker 是基于 Go 语言实现的开源容器项目,Docker 的构想是要实现“ Build Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging ）、分发（ Distribution ）、部署（ Deployment ）、运行（ Runtime ）生命周期进行管理达到应用组件级别的“一次封装 ，到处运行”,Docker 也并非“从石头缝里蹦出来的”而是站在巨人的肩膀上,其中最重要的就是 Linux 容器(Linux Containers, LXC)技术.<br>…</p>\n<a id=\"more\"></a>\n<h1 id=\"Docker是啥\"><a href=\"#Docker是啥\" class=\"headerlink\" title=\"Docker是啥?\"></a>Docker是啥?</h1><p>Docker 是基于 Go 语言实现的开源容器项目,Docker 的构想是要实现“ Build Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging ）、分发（ Distribution ）、部署（ Deployment ）、运行（ Runtime ）生命周期进行管理达到应用组件级别的“一次封装 ，到处运行”,Docker 也并非“从石头缝里蹦出来的”而是站在巨人的肩膀上,其中最重要的就是 Linux 容器(Linux Containers, LXC)技术.</p>\n<h1 id=\"Docker优点\"><a href=\"#Docker优点\" class=\"headerlink\" title=\"Docker优点\"></a>Docker优点</h1><p>更快速的交付和部署<br>更高效的资源利用;<br>更轻松地迁移和拓展;<br>更简单的更新管理</p>\n<h1 id=\"Docker与虚拟机的比较\"><a href=\"#Docker与虚拟机的比较\" class=\"headerlink\" title=\"Docker与虚拟机的比较\"></a>Docker与虚拟机的比较</h1><p>Docker 容器很快，启动和停止可以在秒级实现，这相比传统的虚拟机方式（数分钟）要快得多；<br>Docker 容器对系统资源需求很少，一台主机上可以同时运行数千个 Docker 容器（在<br>IBM 服务器上已经实现了同时运行！ OK 量级的容器实例）；<br>Docker 通过类似 Git 设计理念的操作来方便用户获取、分发和更新应用镜像，存储复<br>用，增量更新；<br>Docker 通过 Dockerfile 支持灵活的自动化创建和部署机制，以提高工作效率，并标准<br>化流程</p>\n<h1 id=\"Docker-三大核心观念\"><a href=\"#Docker-三大核心观念\" class=\"headerlink\" title=\"Docker 三大核心观念\"></a>Docker 三大核心观念</h1><p><strong>镜像(Image)</strong>:类似于虚拟机镜像,看做一个只读模板,镜像是docker的基础</p>\n<p><strong>容器(Container)</strong>:容器类似于一个轻级的沙箱,Docker 利用容器来运行和隔离应用,容器是从镜像创建的应用运行实例它可以启动、开始、停止 删除，而这些容器都是彼此相互隔离、互不可见的</p>\n<p><strong>仓库(Repository)</strong>:仓库类似于代码仓库,是Docker集中存放镜像文件的场所.</p>\n<h1 id=\"Docker-Centos安装\"><a href=\"#Docker-Centos安装\" class=\"headerlink\" title=\"Docker Centos安装\"></a>Docker Centos安装</h1><p>Docker 目前支持 CentOS 及以后的版本 系统的要求跟 Ubuntu 情况类似， 64 位操作<br>系统，内核版本至少为 3.10</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">首先，为了方便添加软件源，以及支持 devicemapper 存储类型，安装如下软件包：</span><br><span class=\"line\">$ sudo yum update </span><br><span class=\"line\">$ sudo yum instal l -y yum-utils \\ device-mapper-persistent-data \\ lvm2 </span><br><span class=\"line\">添加Dokcker 稳定版本的 yum 软件源：</span><br><span class=\"line\">$ sudo yum-conf ig- manager \\ --add-repo https : //download.docker.corn/linux/centos/ docker-ce.repo </span><br><span class=\"line\">之后更新 yum 软件源缓存，并安装 Docker:</span><br><span class=\"line\">$ sudo yum update </span><br><span class=\"line\">$ sudo yum install -y docker-ce </span><br><span class=\"line\">最后，确认 Docker 服务启动正常</span><br><span class=\"line\">$ sudo systernctl start docker</span><br><span class=\"line\">用户还可以使用官方提供的 shell 脚本来在 Linux 系统（目前支持山untu Debian Oracleserv edora Centos OpenSuse Gentoo 等常 发行版）上安装 Docker 最新正式版本，该脚本会自动检测系统信息并进行相应配置：</span><br><span class=\"line\">$ curl -fsSL https: //get.docker . corn/ I sh </span><br><span class=\"line\">或者</span><br><span class=\"line\">$ wget - qO- https://get . docker.corn/ I sh </span><br><span class=\"line\">如果想尝鲜最新功能，可以使用下面的脚本来安装最新的“尝鲜”版本 但要注意，非稳定版本往往意味着功能还不够稳定，不要在生产环境中使用</span><br><span class=\"line\">$ curl -fsSL https : //test.docker .corn/ I sh </span><br><span class=\"line\">另外， 也可以从 store docker.com/search?offering=community&amp;q &amp;<span class=\"built_in\">type</span>=edition 找到各个平台上的 Docker 安装包，自行下载使用</span><br><span class=\"line\">其他操作系统可根据官网进行下载安装</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Docker-镜像常用命令\"><a href=\"#Docker-镜像常用命令\" class=\"headerlink\" title=\"Docker 镜像常用命令\"></a>Docker 镜像常用命令</h1><h2 id=\"获取镜像\"><a href=\"#获取镜像\" class=\"headerlink\" title=\"获取镜像\"></a>获取镜像</h2><p><strong>命令:docker [image] pull NAME [ :TAG]</strong><br>NAME 是镜像仓库名称（用来区分镜像）,TAG 是镜像的标签（往往用来表示版本信息）。 通常情况下， 描述一个镜像需要包括 “名称＋标签“ 信息,如果不显式指定TAG, 则默认会选择la迳釭标签，这会下载仓库中最新版本的镜像。严格地讲，镜像的仓库名称中还应该添加仓库地址（即registry, 注册服务器）作为前<br>缀 ，只是默认使用的是官方DockerHub服务 ，该前缀可以忽略<br>pull 子命令支持的 选项主要包括：<br>     -a, –all tags=trueifalse: 是否获取仓库中的所有镜像，默认为否<br>     –disable-conyent-trust：取消镜像的内容校验，默认为真</p>\n<h2 id=\"查看镜像信息\"><a href=\"#查看镜像信息\" class=\"headerlink\" title=\"查看镜像信息\"></a>查看镜像信息</h2><p><strong>命令:docker images或docker image ls</strong><br>可以列出本地主机上已有镜像的基本信息<br>images子命令主要支持如下选项， 用户可以自行进行尝试：<br>    -a, –all true I false: 列出所有（包括临时文件）镜像文件，默认为否<br>    –digestS=trueifalse: 列出镜像的数字摘要值，默认为否<br>    -f, –filter=[] : 过滤列出的镜像， 如dangling 式rue 只显示没有被使用的镜像,也可指定带有特定标注的镜像等<br>    –format=”TEMPLATE” : 控制输出格式，如. ID代表ID信息，.Repository代表仓库信息等<br>    –no-trunc=true |false: 对输出结果中太长的部分是否进行截断，如镜像的ID信息，默认为是<br>    -q, –quiet=true |false: 仅输出ID信息， 默认为否。<br>    其中， 还支持对输出结果进行控制的选项，如 -f. –filter=[]、–no-trunc =true | false、 -q、 –quiet=true | false等。<br>更多子命令选项还可以通过mandocker-images来查看</p>\n<p><strong>命令:docker[image]inspect</strong><br>获取该镜像的详细信息，包括制作者 、 适应架构、各层的数字摘要等</p>\n<p><strong>命令:docker history</strong><br>获取该镜像的历史信息</p>\n<h2 id=\"搜索镜像\"><a href=\"#搜索镜像\" class=\"headerlink\" title=\"搜索镜像\"></a>搜索镜像</h2><p><strong>命令:docker search [option] keyword</strong><br>搜索镜像<br>支持的命令选项主要包括：<br>     -f, –filer filter: 过滤输出内容<br>     –format string: 格式化输出内容<br>     –limit int：限制输出结果个数，默认为 25 个<br>     –no-trunc: 不截断输出结果</p>\n<h2 id=\"删除和清理镜像\"><a href=\"#删除和清理镜像\" class=\"headerlink\" title=\"删除和清理镜像\"></a>删除和清理镜像</h2><p><strong>命令:docker rmi 或 docker image rm</strong><br>可以删除镜像<br>docker rmi IMAGE [IMAGE … ] 其中 IMAGE可以为标签或 ID<br>支持选项包括：<br>    -f, -force: 强制删除镜像， 即使有容器依赖它<br>    -no-prune: 不要清理未带标签的父镜像</p>\n<p><strong>命令:docker ps -a</strong><br>看到本机上存在的所有容器</p>\n<p><strong>命令:docker image prune</strong><br>来进行清理删除镜像<br>支待选项包括：<br>     -a, -all: 删除所有无用镜像， 不光是临时镜像<br>     -filler filler: 只清理符合给定过滤器的镜像<br>     -f, -force: 强制删除镜像， 而不进行提示确认</p>\n<h2 id=\"创建镜像\"><a href=\"#创建镜像\" class=\"headerlink\" title=\"创建镜像\"></a>创建镜像</h2><p><strong>命令:docker [container] commit [OPTIONS] CONTAINER [REPOSITORY [:TAG]]</strong><br>基于已有容器创建镜像<br>主要选项包括：<br>    -a, –author=””: 作者信息<br>    -c, –change=[] : 提交的时候执行Dockerfile指令， 包括 CMDIENTRYPOINT 但NVIEXPOSEILABELIONBUILDIUSERIVOLUMEIWORKDIR等<br>    -m, –message= “”: 提交消息<br>    -p, –pause式rue: 提交时暂停容器运行</p>\n<p><strong>命令: docker [image] i mport [OPTIONS] filelURLl -[REPOSITORY [:TAG] ]</strong><br>基于本地模板导入镜像</p>\n<p><strong>基于dockerfile创建镜像,可在官网了解相关知识点</strong></p>\n<h2 id=\"存出和载人镜像\"><a href=\"#存出和载人镜像\" class=\"headerlink\" title=\"存出和载人镜像\"></a>存出和载人镜像</h2><p><strong>命令:docker [image ] save docker [image ] load</strong><br>来存出和载人镜像</p>\n<p><strong>命令:docker [image] push [:TAG] | [REGISTRY_HOST [ :REGISTRY_PORT] / ]NAME [:TAG]</strong><br>上传镜像到仓库，默认上传到 Docker Hub 官方仓库（需要登录）</p>\n<h1 id=\"Docker-容器常用命令\"><a href=\"#Docker-容器常用命令\" class=\"headerlink\" title=\"Docker 容器常用命令\"></a>Docker 容器常用命令</h1><h2 id=\"创建容器\"><a href=\"#创建容器\" class=\"headerlink\" title=\"创建容器\"></a>创建容器</h2><p><strong>命令:docker [container] create</strong><br>命令新建一个容器,使用 docker [container] create 命令新建的容器处于停止状态，可以使用 docker[container] start 命令来启动它,create命令较为强大,可以看相关文档地址:<strong><a href=\"https://docs.docker.com/engine/reference/commandline/create/\">https://docs.docker.com/engine/reference/commandline/create/</a></strong></p>\n<p><strong>命令: docker [container] start</strong><br>来启动一个已经创建的容器</p>\n<p><strong>命令:docker ps</strong><br>可以查看到运行中的容器</p>\n<p><strong>命令: docker [container ］run</strong><br>新建并启动容器<br>等价于先执行 docker [container] create 命令,再执行 docker [container] start 命令,<br>Docker 在后台运行的标准操作包括：<br>    检查本地是否存在指定的镜像，不存在就从公有仓库下载<br>    利用镜像创建一个容器，并启动该容器<br>    分配 个文件系统给容器，并在只读的镜像层外面挂载一层可读写层<br>    从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去<br>    从网桥的地址池配置一个 IP 地址给容器<br>    执行用户指定的应用程序<br>    执行完毕后容器被自动终止</p>\n<p><strong>命令:docker [container] logs</strong><br>查看容器输出信息<br>该命令支持的选项包括：<br>    －details 打印详细信息；<br>    －f, follo ：持续保持输出；<br>    一since string ：输出从某个时间开始的日志；<br>    －tail string 输出最近的若干日志；<br>    －t, timestamps 显示时间戳信息<br>    －until string 输出某个时间之前的日</p>\n<h2 id=\"停止容器\"><a href=\"#停止容器\" class=\"headerlink\" title=\"停止容器\"></a>停止容器</h2><p><strong>命令:docker [container] pause CONTAINER [CONTAINER …]</strong><br>暂停一个运行中的容器</p>\n<p><strong>命令:docker [contai er pause CONTAINER [CONTAINER …]</strong><br>来恢复到运行状态</p>\n<p><strong>命令:docker [container] stop [-t I - -time [=10]] [CONTAiNER …]</strong><br>来终止一个运行中的容器,该命令会首先向容器发送 SIGTERM 信号,等待一段超时时间后（默认为 10 秒）,再发<br>SIGKLL 信号来终止容器</p>\n<p><strong>命令:docker container prune</strong><br>会自动清除掉所有处于停止状态的容器</p>\n<p><strong>命令:docker [container] kill</strong><br>直接发送 SIGKILL 信号来强行终止容器</p>\n<p><strong>命令:docker ps -qa</strong><br>查看到所有容器的ID</p>\n<p><strong>命令:docker [container] start</strong><br>重新启动容器</p>\n<p><strong>命令:docker [container] restart</strong><br>命令会将一个运行态 的容器先终止，然后再重新启动</p>\n<h2 id=\"进入容器\"><a href=\"#进入容器\" class=\"headerlink\" title=\"进入容器\"></a>进入容器</h2><p><strong>命令:docker [container] attach [–detach-keys[;[]]] [–no-stdin] [–sig-proxy[;true]] CONTAINER</strong><br>命令支持三个主要选项：<br>－－ detach-keys ［＝［］］：指定退出 attach 模式的快捷键序列， 默认是 CTRL-p CTRL-q;<br>－－ no-stdin=trueifalse ：是否关闭标准输入，默认是保持打开<br>－－ sig-proxy=truelfalse ：是否代理收到的系统信号给应用进程，默认为 true</p>\n<p><strong>命令:docker [container] exec [-d|-detach] [ detach-keys[=[]]] [-i|–interactive] [ –privileged] [-t|–tty] [-u|user [=USER]] CONTAINER COMMAND [ARG . . . ]</strong><br>比较重要的参数有：<br>－ d, –detach 在容器中后台执行命令<br>－－ detach-keys =＂＂：指定将容器切回后台的按键<br>－ e, - - env= []：指定环境变量列表<br>－ i, –interactive=true | false ：打开标准输入接受用户输入命令， 默认值为false<br>－－ privileged=true|false 是否给执行命令以高权限，默认值为 false<br>－ t, –tty=true|false 分配伪终端，默认值为 false<br>－ u, –user =””：执行命令的用户名或 ID</p>\n<h2 id=\"删除容器\"><a href=\"#删除容器\" class=\"headerlink\" title=\"删除容器\"></a>删除容器</h2><p><strong>命令:docker [container) rm [-f|– force) [-1|-link] [-v|–volumes] CONTAINER [CONTAINER …]</strong><br>支持的选项包括<br>－ f, –force=false 是否强行终止并删除一个运行中的容器<br>－ 1, –link=false ：删除容器的连接 ，但保留容器<br>－ v, –volumes=false ：删除容器挂载的数据卷</p>\n<h2 id=\"导人和导出容器\"><a href=\"#导人和导出容器\" class=\"headerlink\" title=\"导人和导出容器\"></a>导人和导出容器</h2><p><strong>命令:docker [container) export [-o|–output [=””] ] CONTAINER</strong><br>导出容器是指，导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态<br>－o 选项来指定导出的tar 文件名，也可以直接通过重定向来实现</p>\n<p><strong>命令:docker import [-c|–change[=[]]] [-m|–message[=MESSAGE]] file|URL|-[REPOSITORY [:TAG]]</strong><br>导入容器</p>\n<h2 id=\"查看容器\"><a href=\"#查看容器\" class=\"headerlink\" title=\"查看容器\"></a>查看容器</h2><p><strong>命令:用 docker container inspect [OPTIONS] CONTAINER [CONTAINER . .. ］</strong><br>查看容器详情</p>\n<p><strong>命令:docker [container] top [OPTIONS] CONTAINER [CONTAINER…]</strong><br>查看容器内进程</p>\n<p><strong>命令:docker [container] stats [OPTIONS] [CONTAINER … ]</strong><br>查看统计信息,会显示 CPU 、内存、存储、网络等使用情况的统计信息<br>支持选项包括<br>－ a, -all ：输出所有容器统计信息，默认仅在运行中<br>－ format string ：格式化输出信息<br>－ no-stream ：不持续输出，默认会自动更新持续实时结果<br>－ no-trunc ：不截断输出信息</p>\n<h2 id=\"其他容器命令\"><a href=\"#其他容器命令\" class=\"headerlink\" title=\"其他容器命令\"></a>其他容器命令</h2><p><strong>命令格式为 docker [container] cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-</strong><br>复制文件<br>支持的选项包括<br>－ a, -ar chive ：打包模式，复制文件会带有原始的 uid/gid 信息<br>－ L, -follow-link ：跟随软连接。当原路径为软连接时＼默认只复制链接信息,使用该选项会复制链接的目标内容</p>\n<p><strong>命令: docker [container] diff CONTAINER</strong><br>查看变更</p>\n<p><strong>命令:docker container port CONTAINER [PRIVATE_PORT[/PROTO ］］</strong><br>查看端口映射</p>\n<p><strong>命令:docker [container] update [OPTIONS] CONTAINER [CONTAINER …]</strong><br>支持的选项包括：<br>－blkio-weight uintl6 ：更新块 IO 限制， 10 1000 ，默认值为 ，代表着无限制<br>－ cpu-period int ：限制 CPU 调度器 CFS (Completely Fair Scheduler ）使用时间，单位为微秒，最小 1000<br>－ cpu-quota int ：限制 CPU 调度器 CFS 配额，单位为微秒，最小 1000<br>－ cpu-rt period int ：限制 CPU 调度器的实时周期，单位为微秒<br>－ cpu-rt runtime int ：限制 CPU 调度器的实时运行时，单位为微秒<br>－ c, -cpu-shares in 限制 CPU 使用份额<br>－ cpus decimal ：限制 CPU 个数<br>－ cpuset-cpus string ：允许使用的 CPU 核，如 0-3, 0,1<br>－ cpuset mems string ：允许使用的内存块，如 0-3’ 0, 1<br>－ kernel-memor bytes ：限制使用的内核内存<br>－ m, -memory bytes 限制使用的内存<br>－memory-reservation bytes ：内存软限制<br>－memory-swap bytes ：内存加上缓存区的限制， 表示为对缓冲区无限制<br>－ restart stri 口g 容器退出后的重启策略</p>\n<h1 id=\"Docker仓库\"><a href=\"#Docker仓库\" class=\"headerlink\" title=\"Docker仓库\"></a>Docker仓库</h1><p>**仓库(Repository)**是集中存放镜像的地方，又分公共仓库和私有仓库</p>\n<h2 id=\"Docker-Hub-公共镜像市场\"><a href=\"#Docker-Hub-公共镜像市场\" class=\"headerlink\" title=\"Docker Hub 公共镜像市场\"></a>Docker Hub 公共镜像市场</h2><p><strong>Docker Hub Docker</strong> 官方提供的最大的公共镜像仓库，目前包括了超过 100 000<br>像，地址为 <strong>https: //hub.docker.com</strong></p>\n<h1 id=\"Docker数据管理\"><a href=\"#Docker数据管理\" class=\"headerlink\" title=\"Docker数据管理\"></a>Docker数据管理</h1><p>容器中的管理数据主要有两种方式<br><strong>数据卷 Data Volumes)</strong> 容器内数据直接映射到本地主机环境；<br><strong>数据卷容器（Data Volume Containers)</strong> 使用特定容器维护数据卷</p>\n<h2 id=\"数据卷\"><a href=\"#数据卷\" class=\"headerlink\" title=\"数据卷\"></a>数据卷</h2><p><strong>数据卷 Data Volumes</strong> 是一个可供容器使用的特殊目录，它将主机操作系统目录直接<br>映射进容器，类似于 Linux 中的 mout 行为<br><strong>数据卷可以提供很多有用的特性<br>    数据卷可以在容器之间共事和重用，容器间传递数据将变得高效与方便<br>    对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作<br>    对数据卷的更新不会影响镜像，解摘开应用和数据会一直存在 ，直到没有容器使用，可以安心地卸载它</strong></p>\n<h2 id=\"创建数据卷\"><a href=\"#创建数据卷\" class=\"headerlink\" title=\"创建数据卷\"></a>创建数据卷</h2><p><strong>命令:docker volume create</strong> </p>\n<h2 id=\"绑定数据卷\"><a href=\"#绑定数据卷\" class=\"headerlink\" title=\"绑定数据卷\"></a>绑定数据卷</h2><p><strong>命令:docker [container] run口命令的时候，可以使用 mount 选项来使用数据卷</strong><br>mount 项支持三种类型的数据卷，包括<br>    volume 普通数据卷，映射到主机／var/ lib /docke /vo lumes 径下<br>    bind ：绑定数据卷，映射到主机指定路径下<br>    tmpfs ：临时数据卷，只存在于内存中</p>\n<h2 id=\"数据卷容器\"><a href=\"#数据卷容器\" class=\"headerlink\" title=\"数据卷容器\"></a>数据卷容器</h2><p><strong>命令:docker run -it –volumes-from dbdata –name dbl ubuntu</strong><br>可以在其他容器中使用－－ volumes-from 来挂载 dbdata 容器中的数据卷，例如如创建 dbl db2 两个容器，并从 dbdata 容器挂载数据卷</p>\n<p><strong>命令:docker rm -v</strong><br>删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用此命令,指定同时删除关联的容器</p>\n<h2 id=\"利用数据卷容器来迁移数据\"><a href=\"#利用数据卷容器来迁移数据\" class=\"headerlink\" title=\"利用数据卷容器来迁移数据\"></a>利用数据卷容器来迁移数据</h2><p><strong>命令:docker run -volumes-from dbdata -v $ (pwd) : /backup - -name worker ubuntu tar<br>cvf /backup/backup.tar /dbdata</strong><br>利用 buntu 镜像创建了 个容器 worker 使用－ -volumes-from dbdata 参数<br>来让 worker 容器挂载 db data 容器的数据卷（ dbdata 数据卷）；使用－ $ (pwd) : /backup<br>参数来挂载本地的当前目录到 worke 容器的／backup<br>worker 容器启动后，使用 tar cvf /backup/backup.tar /dbdata 令将／dbdata<br>下内容备份为容器内的／backup/backup. tar ，即宿主主机当前目录下的 backup.tar</p>\n<p><strong>命令：docker run -v /dbdata –name dbdata2 ubuntu /bin/bash<br>docker run –volumes-from dbdata2 -v $(pwd) :/backup busybox tar xvf<br>/backup/backup.tar</strong><br>首先创建一个带有数据卷的容器 bdata2:，然后创建另一个新的容器，挂载 dbdata2 容器，并使用 untar 解压备份文件到所挂载的容器卷中</p>\n<h1 id=\"端口映射与容器互联\"><a href=\"#端口映射与容器互联\" class=\"headerlink\" title=\"端口映射与容器互联\"></a>端口映射与容器互联</h1><p><strong>命令:docker run -d -P training/webapp python app.py</strong><br>当容器中运行一些网络应用， 要让外部访问这些应用时， 可以通过-P或-p参数来指定端口映射。 当使用平（大写的）标记时， Docker 会随机映射一个 49000-49900 的端口到内部容器开放的网络端口,-p (小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定 一个容器。支持的格式有IP:HostPort:ContainerPortI IP:: ContainerPort I HostPort:ContainerPort</p>\n<p><strong>命令;docker run -d -p 5000:5000 training/webapp python app.py</strong><br>使用HostPort： ContainerPot格式本地的5000端口映射到容器的5000端口<br>多次使用-p标记可以绑定多个端口。例如:docker run -d -p 5000:5000 -p 3000:80 training/webapp py thon app.py</p>\n<p><strong>命令:docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py</strong><br>可以使用IP:HostPort： ContainerPort格式指定映射使用一个特定地址，比如<br>localhost地址127.0.0.1</p>\n<p><strong>命令: docker run -d -p 127.0.0.1::5000 training/webapp python app.py</strong><br>使用IP::ContainerPort绑定localhost的任意端口到容器的5000端口，本地主机<br>会自动分配一个端口：还可以使用udp标记来指定 udp端口：<br> docker run -d -p 127.0.0.1:5000:5000/udp training/webapp PY七hon app.py</p>\n<p><strong>命令: docker port nos talgic_rnorse 5000</strong><br>使用docker port来查看当前映射的端口配置，也可以查看到绑定的地址</p>\n<h1 id=\"互联机制实现便捷互访\"><a href=\"#互联机制实现便捷互访\" class=\"headerlink\" title=\"互联机制实现便捷互访\"></a>互联机制实现便捷互访</h1><p>**容器的互联(Iinking)**是一种让多个容器中的应用进行快速交互的方式。它会在源和接收容<br>器之间创建连接关系，接收容器可以通过容器名快速访问到源容器，而不用指定具体的IP地址</p>\n<p><strong>命令:docker run -d -P –name web training/webapp python app.py</strong><br>使用–name标记可以为容器自定义命名</p>\n<p><strong>命令:docker run -d -P –name web –link db:db taining/webapp python app.py</strong><br>创建一个新的web容器，并将它连接到db容器,db容器和web容器建立互联关系。<br>–link参数的格式为–link name: alias, 其中name是要链接的容器的名称 ,alias是别名</p>\n<h1 id=\"使用Dockerfile创建镜像\"><a href=\"#使用Dockerfile创建镜像\" class=\"headerlink\" title=\"使用Dockerfile创建镜像\"></a>使用Dockerfile创建镜像</h1><p>Dockerfile 是一个文本格式的配置文件， 用户可以使用 Dockerfile 来快速创建自定义的镜像</p>\n<h2 id=\"基本结构\"><a href=\"#基本结构\" class=\"headerlink\" title=\"基本结构\"></a>基本结构</h2><p>Dockerfile 由一行行命令语句组成， 并且支持以＃开头的注释行。一般而言，<br>Dockerfile 主体内容分为四部分：<strong>基础镜像信息</strong>、 <strong>维护者信息</strong>、 <strong>镜像操作指令</strong>和<strong>容器启动时执行指令</strong></p>\n<p>下面就是一个例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#This dockerfile uses the ubuntu image</span></span><br><span class=\"line\"><span class=\"comment\">#VERSION 2 - EDITION 1</span></span><br><span class=\"line\"><span class=\"comment\">#Author: docker_user</span></span><br><span class=\"line\"><span class=\"comment\">#Command format: Instruction [arguments / command] ..</span></span><br><span class=\"line\"><span class=\"comment\">#1、第一行必须指定 基础镜像信息</span></span><br><span class=\"line\">FROM ubuntu</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2、维护者信息</span></span><br><span class=\"line\">MAINTAINER docker_user docker_user@email.com</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3、镜像操作指令</span></span><br><span class=\"line\">RUN <span class=\"built_in\">echo</span> <span class=\"string\">&quot;deb http://archive.ubuntu.com/ubuntu/ raring main universe&quot;</span> &gt;&gt; /etc/apt/sources.list</span><br><span class=\"line\">RUN apt-get update &amp;&amp; apt-get install -y nginx</span><br><span class=\"line\">RUN <span class=\"built_in\">echo</span> <span class=\"string\">&quot;\\ndaemon off;&quot;</span> &gt;&gt; /etc/nginx/nginx.conf</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">#4、容器启动执行指令</span></span><br><span class=\"line\">CMD /usr/sbin/nginx</span><br></pre></td></tr></table></figure>\n<p>首行可以通过注释来指定解析器命令， 后续通过注释说明镜像的相关信息。 主体部分首<br>先使用FROM指令指明所基于的镜像名称， 接下来一般是使用LABEL指令说明维护者信息。<br>后面则是镜像操作指令， 例如RUN指令将对镜像执行跟随的命令。 每运行一条RUN指令，<br>镜像添加新的一层， 并提交。 最后是CMD指令， 来指定运行容器时的操作命令</p>\n<h2 id=\"指令说明\"><a href=\"#指令说明\" class=\"headerlink\" title=\"指令说明\"></a>指令说明</h2><p>Dockerfile 中指令的一般格式为 INSTRUCTION arguments, 包括 “配置指令” (配置<br>镜像信息）和 “操作指令” (具体执行操作）， 参见下表<br>Dockerfile中的指令及说明<br>分 类 指 令 说 明<br>| 分类 | 指令 | 说明 |<br>|–|–|–|<br>|配置指令  | ARG | 定义创建镜像过程中使用的变簸 |<br>| 配置指令|FROM |指定所创建镜像的基础镜像|<br>| 配置指令|LABEL |为生成的镜像添加元数据标签信息|<br>| 配置指令|EXPOSE |声明镜像内服务监听的端口|<br>|配置指令 |ENV| 指定环境变抵|<br>| 配置指令|ENTRYPOINT |指定镜像的默认入口命令|<br>|配置指令|VOLUME |创建一个数据卷挂载点|<br>|配置指令|USER |指定运行容器时的用户名或UID|<br>|配置指令|WORKDIR |配置工作目录|<br>|配置指令|ONBUILD| 创建子镜像时指定自动执行的操作指令|<br>|配置指令|STOPSIGNAL| 指定退出的信号值|<br>|配置指令|HEALTH CHECK |配置所启动容器如何进行健康检查|<br>|配置指令|SHELL |指定默认shell类型|<br>|操作指令|RUN|运行指定命令|<br>|操作指令|CMD|启动容器时刻指定默认执行程序|<br>|操作指令|ADD|添加内容到镜像|<br>|操作指令|COPY |复制内容到镜像|</p>\n<h2 id=\"配置指令\"><a href=\"#配置指令\" class=\"headerlink\" title=\"配置指令\"></a>配置指令</h2><p><strong>ARG</strong><br>定义创建镜像过程中使用的变量。<br>格式为 <code>ARG &lt;name&gt;[=&lt;default value&gt;]</code><br>在执行 docker build 时， 可以通过 -build-arg[=] 来为变量赋值。 当镜像编译成<br>功后， ARG 指定的变量将不再存在 (ENV 指定的变量将在镜像中保留）<br>Docker 内置了一些镜像创建变量， 用户可以直接使用而无须声明， 包括（不区分大小<br>写） HTTP PROXY 、 HTTPS PROXY 、 FTP PROXY 、 NO PROXY</p>\n<p><strong>FROM</strong><br>指定所创建镜像的基础镜像<br>格式为:<code>FROM &lt;image&gt; [AS &lt;name&gt;]</code> 或 <code>FROM &lt;image&gt;: &lt;tag&gt; [AS &lt;name&gt;]</code><br>或<code>FROM &lt;image&gt;@&lt;digest&gt; [AS &lt;name&gt;]</code><br>任何 Dockerfile 中第一条指令必须为FROM 指令。 并且， 如果在同一个Dockerfile 中创<br>建多个镜像时， 可以使用多个 FROM 指令（每个镜像一次）<br>为了保证镜像精简， 可以选用体积较小的镜像如Alpine或Debian 作为基础镜像。 例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ARG VERSION&#x3D;9.3 </span><br><span class=\"line\">FROM debian:$&#123;VERSION&#125; </span><br></pre></td></tr></table></figure>\n\n<p><strong>LABEL</strong><br>LABEL 指令可以为生成的镜像添加元数据标签信息。 这些信息可以用来辅助过滤出特<br>定镜像。<br>格式为: <code>LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...</code><br>例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LABEL version&#x3D;&quot;l.0.0-rc3&quot; </span><br><span class=\"line\">LABEL author&#x3D;&quot;yeasy@github&quot; date&#x3D;&quot;2020-01-01&quot; </span><br><span class=\"line\">LABEL description&#x3D;&quot;This 七ex七 illustra七es\\</span><br><span class=\"line\">that label-values can span mul七iple lines.&quot; </span><br></pre></td></tr></table></figure>\n\n<p><strong>EXPOSE</strong><br>声明镜像内服务监听的端口<br>格式为 <code>EXPOSE &lt;part&gt; [&lt;part/&lt;protocol&gt;... ]</code><br>例如：<br>EXPOSE 22 80 8443<br>注意该指令只是起到声明作用， 并不会自动完成端口映射<br>如果要映射端口出来， 在启动容器时可以使用 -P 参数 (Docker 主机会自动分配一个宿主<br>机的临时端口）或-p HOST_PORT:CONTAINER_PORT 参数（具体指定所映射的本地端口）</p>\n<p><strong>ENV</strong><br>指定环境变量， 在镜像生成过程中会被后续RUN指令使用， 在镜像启动的容器中也会存在<br>格式为 <code>ENV &lt;key&gt; &lt;value&gt;或ENV &lt;key&gt;=&lt;value&gt;</code><br>例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ENV APP VERSION&#x3D;l.0.0</span><br><span class=\"line\">ENV APP_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;app </span><br><span class=\"line\">ENV PATH $PATH:&#x2F;usr&#x2F;local&#x2F;bin </span><br></pre></td></tr></table></figure>\n<p>指令指定的环境变量在运行时可以被覆盖掉， 如 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run --env &lt;key&gt;&#x3D;&lt;value&gt; built_image</span><br></pre></td></tr></table></figure>\n\n<p>注意当一条 ENV 指令中同时为多个环境变量赋值并且值也是从环境变量读取时， 会为<br>变量都赋值后再更新。 如下面的指令， 最终结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keyl&#x3D;valuel key2&#x3D;value2: </span><br><span class=\"line\">ENV keyl;value2 </span><br><span class=\"line\">ENV keyl;valuel key2;$&#123;keyl) </span><br></pre></td></tr></table></figure>\n\n<p><strong>ENTRYPOINT</strong><br>指定镜像的默认入口命令， 该入口命令会在启动容器时作为根命令执行， 所有传人值作<br>为该命令的参数<br>支持两种格式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ENTRYPOINT [&quot;executable&quot;, &quot;paraml &quot;, &quot;param2&quot;]: exec 调用执行</span><br><span class=\"line\">ENTRYPOINT command param 1 param2: shell 中执行</span><br></pre></td></tr></table></figure>\n<p>此时， CMD指令指定值将作为根命令的参数。<br>每个 Dockerfile 中只能有一个 ENTRYPOINT, 当指定多个时， 只有最后一个起效。<br>在运行时， 可以被 –entrypoint 参数覆盖掉， 如 docker run –entrypoint</p>\n<p><strong>VOLUME</strong><br>创建一个数据卷挂载点。<br>格式为 <code>VOLUME [&quot;/data]</code><br>运行容器时可以从本地主机或其他容器挂载数据卷， 一般用来存放数据库和需要保持的<br>数据等。</p>\n<p><strong>USER</strong><br>指定运行容器时的用户名或urn, 后续的RUN等指令也会使用指定的用户身份<br>格式为 <code>USER daemon</code><br>当服务不需要管理员权限时，可以通过该命令指定运行用户， 并且可以在 Dockerfile<br>建所需要的用户 例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RUN groupadd -r postgres &amp;&amp; useradd --no-log-init -r -g postgres postgres </span><br></pre></td></tr></table></figure>\n\n<p>要临时获取管理员权限可以使用 gosu 命令</p>\n<p> <strong>WORKDIR</strong><br>为后续的 RUN CMD ENTRYPO INT 指令配置工作目录<br>格式为 <code>WORKDIR path /to/workd ir</code><br>可以使用多个 WORKDIR 令，后续命令 果参数是相对路径， 会基于之前命令指定<br>的路径 例如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WORKDIR &#x2F;a </span><br><span class=\"line\">WORKDIR b </span><br><span class=\"line\">WORKDIR c </span><br><span class=\"line\">RUN pwd </span><br></pre></td></tr></table></figure>\n\n<p>最终路径为/a/b/c<br>此，为了避免出错，推荐 WORKDIR 指令中只使用绝对路</p>\n<p> <strong>ONBUILD</strong><br>指定当基于所生成镜像创建子镜像时，自动执行的操作指<br>格式为 <code>ONBUILD [INSTRUCTION]</code><br>例如，使用如下的 Dockerfile 创建父镜像 Parent Imag ，指定 ONBUILD</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#Dockerfile for Parentimage </span><br><span class=\"line\">[...] </span><br><span class=\"line\">ONBUILD ADD . &#x2F; app&#x2F;src </span><br><span class=\"line\">ONBUILD RUN &#x2F;usr &#x2F; local&#x2F;bin&#x2F;python build --dir &#x2F; app&#x2F;src </span><br><span class=\"line\">[ ... ] </span><br></pre></td></tr></table></figure>\n\n<p>使用 docker build 命令创建子镜像 hild Image 时（ FROM Parentimage ），会首<br>先执行 Parent mage 配置的 ONBUI LD<br>#</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Dockerfile for Childimage </span><br><span class=\"line\">FROM Parenti mage </span><br></pre></td></tr></table></figure>\n\n<p>等价于在 Childimage Dockerfi 中添加了如下指令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#Automatically run the following when building Ch ldimage</span><br><span class=\"line\">. &#x2F; app&#x2F;src </span><br><span class=\"line\">RUN &#x2F;usr&#x2F; ocal&#x2F; bin python-bu ld --dir &#x2F;app&#x2F;src </span><br></pre></td></tr></table></figure>\n\n<p>由于 ONBUILD 指令是隐式执行的，推荐在使用它的镜像标签中进行标注， 例如 ruby:2.l\u0002build<br>ONBUILD 指令在创建专门用于自动编译、检查等操作的基础镜像时，十分有用</p>\n<p><strong>STOPSIGNAL</strong><br>指定所创建镜像启动的容器接收退出的信号值<br><strong>STOPSIGNAL signal</strong> </p>\n<p><strong>HEALTHCHECK</strong><br>配置所启动容器如 进行健康检查（如 判断健康与否），自 Docker 1.12 开始支持<br>格式有两种<br>HEALTH HEC [OPTI ONS] CMD comma nd ：根据所执行命令返回值是否为<br>判断<br>HEALTHCHEC NONE ：禁 基础镜像中的健康检查<br>OPTION 支持如下参数<br>-interva DURAT (d e fault: 30s ）：过多久检查一次<br>-timeout=DURATION (default: 30s 每次检查等待结果的超时<br>-retries (de fault : 3）：如果失败了，重试几次才最终确定失败</p>\n<p><strong>SHELL</strong><br>指定其他命令使用 she ll 时的默认 she ll 类型：<code>SHELL [” executable ”,”parameters”]</code><br>默认值为 ＂／ bin/sh ＂</p>\n<h2 id=\"操作指令\"><a href=\"#操作指令\" class=\"headerlink\" title=\"操作指令\"></a>操作指令</h2><p><strong>RUN</strong><br>运行指定命令<br>格式为 <code>RUN &lt;co mand ＞或 RUN [ &quot;executable &quot; , ” paraml ” , param2]</code><br>意后者指令会被解析为 JSON 数组，因此必须用双引号 前者默认将在 shell 终端中运行命<br>令，即／ bin /sh -c 后者则使用 exec 执行，不会启动 shell 环境<br>指定使用其他终端类型可以通过第二种方式实现，例如 <code>RUN [”/bin/bash&quot; , ” - C ” echo h e llo ”］</code><br>每条 RUN 指令将在当前镜像基础上执行指定命令，并提交为新的镜像层 当命令较长时<br>可以使用＼来换行 例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RUN apt-get update \\ </span><br><span class=\"line\">&amp;&amp; apt-get install -y libsnappy-dev zliblg-dev libbz2-dev \\ </span><br><span class=\"line\">&amp;&amp; rm -rf &#x2F;var&#x2F;cache&#x2F;apt \\</span><br><span class=\"line\">&amp;&amp; rm rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*</span><br></pre></td></tr></table></figure>\n<p> <strong>CMD</strong><br>CMD 指令用来指定启动容器时默认执行的命令<br>支持三种格式：<br><code>CMD ［executable ＂，” paraml param2 ＇］</code>：相当于执行 executable param 1 param2 ，推荐方式；<br><code>CMD command paraml param2</code> ：在默认的 Shell 中执行，提供给需要交互的应用；<br><code>CMD [”paraml ”，” param2</code> ：提供给 ENTRYPOINT 的默认参数<br>每个 Dockerfile 只能有 CMD 命令 如果指定了多条命令，只有最后一条会被执行<br>如果用户启动容器时候手动指定了运行的命令（作为 run命令的参数），则会覆盖掉<br>CMD 指定的命令</p>\n<p><strong>ADD</strong><br>添加内容到镜像<br>格式为 <code>ADD &lt;SrC&gt; &lt;dest&gt;</code><br>该命令将复制指定的＜ SrC ＞路径下内容到容器中的＜dest ＞路径下<br>其中＜ SrC ＞可以是 Dockerfile 所在目录的一个相对路径（文件或目录）；也可以是一个<br>URL ；还可以是一个 tar 文件（自动解压为目录） &lt;dest ＞可以是镜像内绝对路径，或者相<br>对于工作目录（WORK.DIR ）的相对路径<br>路径支持正则格式，例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD *.c &#x2F;code&#x2F; </span><br></pre></td></tr></table></figure>\n\n<p><strong>COPY</strong><br>复制内容到镜像<br>格式为 <code>COPY &lt;SrC&gt; &lt;dest&gt;</code><br>复制本地主机的＜ SrC&gt; （为 Dockerfile 所在目录的相对路径，文件或目录）下内容到镜<br>像中的＜dest ＞。目标路径不存在时，会自动创建路径同样支持正则格式<br>COPY与ADD指令功能类似，当使用本地目录为源目录时，推荐使用 COPY</p>\n<h2 id=\"创建镜像-1\"><a href=\"#创建镜像-1\" class=\"headerlink\" title=\"创建镜像\"></a>创建镜像</h2><p>编写完成 Docker file 之后，可以通过 <code>docker [image] build</code> 命令来创建镜像<br>基本的格式为 <code>docker build [OPTIONS] PATH [ URL I -</code><br>该命令将读取指定路径下（包括子目录）的 Dockrfile ，并将该路径下所有数据作为上下<br>文（ Context ）发送给 Docker 服务端 Docker 服务端在校验 Dockerfile 格式通过后，逐条执行<br>其中定义的指令，碰到 ADD COPY RUN 指令会生成 层新的镜像 最终如果创建镜像成功，会返回最终镜像的 ID<br>命令选项<br>| 选项 | 说明 |<br>|–|–|<br>|-add-host list |添加自定义的主机名到IP映射 |<br>|-build-arg list |添加创建时的变量                  |<br>|-cache-from strings| 使用指定镜像作为缓存源       |<br>|-cgroup-parent string |继承的上层 cgroup          |<br>|-compress |使用gzip来压缩创建上下文数据         |<br>|-cpu-period int |分配的 CFS 调度器时长            |<br>|cpu-quota int |CFS 调度都总份额                    |<br>|-c, cpu-shares int |CPU权重                           |<br>|-cpuset-cpus string |多CPU 允许使用的CPU             |<br>|-cpuset-mems string |多CPU允许使用的内存               |<br>|-disable-content-trust |不进行镜像校验，默认为真  |<br>|-f, -file string | Dockerfile 名称              |<br>|-force-rm |总是删除中间过程的容器                    |<br>|-iidfile string |将镜像ID写入到文件          |<br>|-isolation string |容器的隔离机制                 |<br>|-label list | 配置镜像的元数据                     |<br>|-m,-memory bytes |限制使用内存盘                |<br>|memory-swap bytes | 限制内存和缓存的总盐           |<br>|-network string |指定RUN命令时的网络模式        |<br>|-no-cache |创建镜像不适用缓存                       |<br>|-platform string | 指定平台类型                    |<br>|-pull  |总是尝试获取镜像的最新版本                  |<br>|-q, -quiet | 不打印创建过程中的日志信息            |<br>|-rm | 创建成功后自动删除中间过程容器，默认为真      |<br>|-security-opt strings  |指定安全相关的选项        |<br>|-shm-size bytes| /dev/shm 的大小                  |<br>|-squash |将新创建的多层挤压放入到一层            |<br>|-stream | 持续获取创建的上下文                    |<br>|-t, -tag list |指定镜像的标签列表                |<br>|target string | 指定创建的目标阶段                 |<br>|-ulimit ulmit |指定 ulimit 的配置                |</p>\n<h2 id=\"选择父镜像\"><a href=\"#选择父镜像\" class=\"headerlink\" title=\"选择父镜像\"></a>选择父镜像</h2><p>大部分情况下，生成新的镜像都需要通过 FROM 指令来指定父镜像 父镜像是生成镜像<br>的基础，会直接影到所生成镜像的大小和功能,用户可 选择两种镜像作为父镜像，一种是所谓的基础镜像（ baseiage ），另外一种普通的镜像（往往由第三方创建，基于基础镜像）镜像较特殊，其 Dockerfile 中往往不存在指令，或者基于 scratch 镜像(FROM scratch ），这意味着其在整个镜像树中处于根的位置<br>下面的 Dockerfile定义了 个简单的基础镜像，将用户提前编译好的二进制 可执行文件binary到镜像中，运行容器 执行 inary 命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM scratch </span><br><span class=\"line\">ADD binary /</span><br><span class=\"line\">CMD ［<span class=\"string\">&quot;binary&quot;</span>]</span><br></pre></td></tr></table></figure>\n\n<p>普通镜像也可以作为父镜像来使用， 括常见的 busybox debian ubuntu</p>\n<h2 id=\"使用-dockerigno-文件\"><a href=\"#使用-dockerigno-文件\" class=\"headerlink\" title=\"使用 dockerigno 文件\"></a>使用 dockerigno 文件</h2><p>通过 .dockerignore文件（每一行添 一条匹配模式）来让 Docker忽略匹配路径或或文件，在建镜像时候不将无关数据发送到服务端<br>dockerignore 文件中模式语法支持 Golang 风格的路径正则格式：<br>“＊”表示任意多个字符；<br>“？”代表单个字符；<br>“！”表示不匹配（即不忽略指定的路径或文件）</p>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/103848953\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/103848953</a></p>\n","site":{"data":{}},"excerpt":"<p>Docker 是基于 Go 语言实现的开源容器项目,Docker 的构想是要实现“ Build Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging ）、分发（ Distribution ）、部署（ Deployment ）、运行（ Runtime ）生命周期进行管理达到应用组件级别的“一次封装 ，到处运行”,Docker 也并非“从石头缝里蹦出来的”而是站在巨人的肩膀上,其中最重要的就是 Linux 容器(Linux Containers, LXC)技术.<br>…</p>","more":"<h1 id=\"Docker是啥\"><a href=\"#Docker是啥\" class=\"headerlink\" title=\"Docker是啥?\"></a>Docker是啥?</h1><p>Docker 是基于 Go 语言实现的开源容器项目,Docker 的构想是要实现“ Build Ship and Run Any App, Anywhere ”，即通过对应用的封装（ Packaging ）、分发（ Distribution ）、部署（ Deployment ）、运行（ Runtime ）生命周期进行管理达到应用组件级别的“一次封装 ，到处运行”,Docker 也并非“从石头缝里蹦出来的”而是站在巨人的肩膀上,其中最重要的就是 Linux 容器(Linux Containers, LXC)技术.</p>\n<h1 id=\"Docker优点\"><a href=\"#Docker优点\" class=\"headerlink\" title=\"Docker优点\"></a>Docker优点</h1><p>更快速的交付和部署<br>更高效的资源利用;<br>更轻松地迁移和拓展;<br>更简单的更新管理</p>\n<h1 id=\"Docker与虚拟机的比较\"><a href=\"#Docker与虚拟机的比较\" class=\"headerlink\" title=\"Docker与虚拟机的比较\"></a>Docker与虚拟机的比较</h1><p>Docker 容器很快，启动和停止可以在秒级实现，这相比传统的虚拟机方式（数分钟）要快得多；<br>Docker 容器对系统资源需求很少，一台主机上可以同时运行数千个 Docker 容器（在<br>IBM 服务器上已经实现了同时运行！ OK 量级的容器实例）；<br>Docker 通过类似 Git 设计理念的操作来方便用户获取、分发和更新应用镜像，存储复<br>用，增量更新；<br>Docker 通过 Dockerfile 支持灵活的自动化创建和部署机制，以提高工作效率，并标准<br>化流程</p>\n<h1 id=\"Docker-三大核心观念\"><a href=\"#Docker-三大核心观念\" class=\"headerlink\" title=\"Docker 三大核心观念\"></a>Docker 三大核心观念</h1><p><strong>镜像(Image)</strong>:类似于虚拟机镜像,看做一个只读模板,镜像是docker的基础</p>\n<p><strong>容器(Container)</strong>:容器类似于一个轻级的沙箱,Docker 利用容器来运行和隔离应用,容器是从镜像创建的应用运行实例它可以启动、开始、停止 删除，而这些容器都是彼此相互隔离、互不可见的</p>\n<p><strong>仓库(Repository)</strong>:仓库类似于代码仓库,是Docker集中存放镜像文件的场所.</p>\n<h1 id=\"Docker-Centos安装\"><a href=\"#Docker-Centos安装\" class=\"headerlink\" title=\"Docker Centos安装\"></a>Docker Centos安装</h1><p>Docker 目前支持 CentOS 及以后的版本 系统的要求跟 Ubuntu 情况类似， 64 位操作<br>系统，内核版本至少为 3.10</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">首先，为了方便添加软件源，以及支持 devicemapper 存储类型，安装如下软件包：</span><br><span class=\"line\">$ sudo yum update </span><br><span class=\"line\">$ sudo yum instal l -y yum-utils \\ device-mapper-persistent-data \\ lvm2 </span><br><span class=\"line\">添加Dokcker 稳定版本的 yum 软件源：</span><br><span class=\"line\">$ sudo yum-conf ig- manager \\ --add-repo https : //download.docker.corn/linux/centos/ docker-ce.repo </span><br><span class=\"line\">之后更新 yum 软件源缓存，并安装 Docker:</span><br><span class=\"line\">$ sudo yum update </span><br><span class=\"line\">$ sudo yum install -y docker-ce </span><br><span class=\"line\">最后，确认 Docker 服务启动正常</span><br><span class=\"line\">$ sudo systernctl start docker</span><br><span class=\"line\">用户还可以使用官方提供的 shell 脚本来在 Linux 系统（目前支持山untu Debian Oracleserv edora Centos OpenSuse Gentoo 等常 发行版）上安装 Docker 最新正式版本，该脚本会自动检测系统信息并进行相应配置：</span><br><span class=\"line\">$ curl -fsSL https: //get.docker . corn/ I sh </span><br><span class=\"line\">或者</span><br><span class=\"line\">$ wget - qO- https://get . docker.corn/ I sh </span><br><span class=\"line\">如果想尝鲜最新功能，可以使用下面的脚本来安装最新的“尝鲜”版本 但要注意，非稳定版本往往意味着功能还不够稳定，不要在生产环境中使用</span><br><span class=\"line\">$ curl -fsSL https : //test.docker .corn/ I sh </span><br><span class=\"line\">另外， 也可以从 store docker.com/search?offering=community&amp;q &amp;<span class=\"built_in\">type</span>=edition 找到各个平台上的 Docker 安装包，自行下载使用</span><br><span class=\"line\">其他操作系统可根据官网进行下载安装</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"Docker-镜像常用命令\"><a href=\"#Docker-镜像常用命令\" class=\"headerlink\" title=\"Docker 镜像常用命令\"></a>Docker 镜像常用命令</h1><h2 id=\"获取镜像\"><a href=\"#获取镜像\" class=\"headerlink\" title=\"获取镜像\"></a>获取镜像</h2><p><strong>命令:docker [image] pull NAME [ :TAG]</strong><br>NAME 是镜像仓库名称（用来区分镜像）,TAG 是镜像的标签（往往用来表示版本信息）。 通常情况下， 描述一个镜像需要包括 “名称＋标签“ 信息,如果不显式指定TAG, 则默认会选择la迳釭标签，这会下载仓库中最新版本的镜像。严格地讲，镜像的仓库名称中还应该添加仓库地址（即registry, 注册服务器）作为前<br>缀 ，只是默认使用的是官方DockerHub服务 ，该前缀可以忽略<br>pull 子命令支持的 选项主要包括：<br>     -a, –all tags=trueifalse: 是否获取仓库中的所有镜像，默认为否<br>     –disable-conyent-trust：取消镜像的内容校验，默认为真</p>\n<h2 id=\"查看镜像信息\"><a href=\"#查看镜像信息\" class=\"headerlink\" title=\"查看镜像信息\"></a>查看镜像信息</h2><p><strong>命令:docker images或docker image ls</strong><br>可以列出本地主机上已有镜像的基本信息<br>images子命令主要支持如下选项， 用户可以自行进行尝试：<br>    -a, –all true I false: 列出所有（包括临时文件）镜像文件，默认为否<br>    –digestS=trueifalse: 列出镜像的数字摘要值，默认为否<br>    -f, –filter=[] : 过滤列出的镜像， 如dangling 式rue 只显示没有被使用的镜像,也可指定带有特定标注的镜像等<br>    –format=”TEMPLATE” : 控制输出格式，如. ID代表ID信息，.Repository代表仓库信息等<br>    –no-trunc=true |false: 对输出结果中太长的部分是否进行截断，如镜像的ID信息，默认为是<br>    -q, –quiet=true |false: 仅输出ID信息， 默认为否。<br>    其中， 还支持对输出结果进行控制的选项，如 -f. –filter=[]、–no-trunc =true | false、 -q、 –quiet=true | false等。<br>更多子命令选项还可以通过mandocker-images来查看</p>\n<p><strong>命令:docker[image]inspect</strong><br>获取该镜像的详细信息，包括制作者 、 适应架构、各层的数字摘要等</p>\n<p><strong>命令:docker history</strong><br>获取该镜像的历史信息</p>\n<h2 id=\"搜索镜像\"><a href=\"#搜索镜像\" class=\"headerlink\" title=\"搜索镜像\"></a>搜索镜像</h2><p><strong>命令:docker search [option] keyword</strong><br>搜索镜像<br>支持的命令选项主要包括：<br>     -f, –filer filter: 过滤输出内容<br>     –format string: 格式化输出内容<br>     –limit int：限制输出结果个数，默认为 25 个<br>     –no-trunc: 不截断输出结果</p>\n<h2 id=\"删除和清理镜像\"><a href=\"#删除和清理镜像\" class=\"headerlink\" title=\"删除和清理镜像\"></a>删除和清理镜像</h2><p><strong>命令:docker rmi 或 docker image rm</strong><br>可以删除镜像<br>docker rmi IMAGE [IMAGE … ] 其中 IMAGE可以为标签或 ID<br>支持选项包括：<br>    -f, -force: 强制删除镜像， 即使有容器依赖它<br>    -no-prune: 不要清理未带标签的父镜像</p>\n<p><strong>命令:docker ps -a</strong><br>看到本机上存在的所有容器</p>\n<p><strong>命令:docker image prune</strong><br>来进行清理删除镜像<br>支待选项包括：<br>     -a, -all: 删除所有无用镜像， 不光是临时镜像<br>     -filler filler: 只清理符合给定过滤器的镜像<br>     -f, -force: 强制删除镜像， 而不进行提示确认</p>\n<h2 id=\"创建镜像\"><a href=\"#创建镜像\" class=\"headerlink\" title=\"创建镜像\"></a>创建镜像</h2><p><strong>命令:docker [container] commit [OPTIONS] CONTAINER [REPOSITORY [:TAG]]</strong><br>基于已有容器创建镜像<br>主要选项包括：<br>    -a, –author=””: 作者信息<br>    -c, –change=[] : 提交的时候执行Dockerfile指令， 包括 CMDIENTRYPOINT 但NVIEXPOSEILABELIONBUILDIUSERIVOLUMEIWORKDIR等<br>    -m, –message= “”: 提交消息<br>    -p, –pause式rue: 提交时暂停容器运行</p>\n<p><strong>命令: docker [image] i mport [OPTIONS] filelURLl -[REPOSITORY [:TAG] ]</strong><br>基于本地模板导入镜像</p>\n<p><strong>基于dockerfile创建镜像,可在官网了解相关知识点</strong></p>\n<h2 id=\"存出和载人镜像\"><a href=\"#存出和载人镜像\" class=\"headerlink\" title=\"存出和载人镜像\"></a>存出和载人镜像</h2><p><strong>命令:docker [image ] save docker [image ] load</strong><br>来存出和载人镜像</p>\n<p><strong>命令:docker [image] push [:TAG] | [REGISTRY_HOST [ :REGISTRY_PORT] / ]NAME [:TAG]</strong><br>上传镜像到仓库，默认上传到 Docker Hub 官方仓库（需要登录）</p>\n<h1 id=\"Docker-容器常用命令\"><a href=\"#Docker-容器常用命令\" class=\"headerlink\" title=\"Docker 容器常用命令\"></a>Docker 容器常用命令</h1><h2 id=\"创建容器\"><a href=\"#创建容器\" class=\"headerlink\" title=\"创建容器\"></a>创建容器</h2><p><strong>命令:docker [container] create</strong><br>命令新建一个容器,使用 docker [container] create 命令新建的容器处于停止状态，可以使用 docker[container] start 命令来启动它,create命令较为强大,可以看相关文档地址:<strong><a href=\"https://docs.docker.com/engine/reference/commandline/create/\">https://docs.docker.com/engine/reference/commandline/create/</a></strong></p>\n<p><strong>命令: docker [container] start</strong><br>来启动一个已经创建的容器</p>\n<p><strong>命令:docker ps</strong><br>可以查看到运行中的容器</p>\n<p><strong>命令: docker [container ］run</strong><br>新建并启动容器<br>等价于先执行 docker [container] create 命令,再执行 docker [container] start 命令,<br>Docker 在后台运行的标准操作包括：<br>    检查本地是否存在指定的镜像，不存在就从公有仓库下载<br>    利用镜像创建一个容器，并启动该容器<br>    分配 个文件系统给容器，并在只读的镜像层外面挂载一层可读写层<br>    从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去<br>    从网桥的地址池配置一个 IP 地址给容器<br>    执行用户指定的应用程序<br>    执行完毕后容器被自动终止</p>\n<p><strong>命令:docker [container] logs</strong><br>查看容器输出信息<br>该命令支持的选项包括：<br>    －details 打印详细信息；<br>    －f, follo ：持续保持输出；<br>    一since string ：输出从某个时间开始的日志；<br>    －tail string 输出最近的若干日志；<br>    －t, timestamps 显示时间戳信息<br>    －until string 输出某个时间之前的日</p>\n<h2 id=\"停止容器\"><a href=\"#停止容器\" class=\"headerlink\" title=\"停止容器\"></a>停止容器</h2><p><strong>命令:docker [container] pause CONTAINER [CONTAINER …]</strong><br>暂停一个运行中的容器</p>\n<p><strong>命令:docker [contai er pause CONTAINER [CONTAINER …]</strong><br>来恢复到运行状态</p>\n<p><strong>命令:docker [container] stop [-t I - -time [=10]] [CONTAiNER …]</strong><br>来终止一个运行中的容器,该命令会首先向容器发送 SIGTERM 信号,等待一段超时时间后（默认为 10 秒）,再发<br>SIGKLL 信号来终止容器</p>\n<p><strong>命令:docker container prune</strong><br>会自动清除掉所有处于停止状态的容器</p>\n<p><strong>命令:docker [container] kill</strong><br>直接发送 SIGKILL 信号来强行终止容器</p>\n<p><strong>命令:docker ps -qa</strong><br>查看到所有容器的ID</p>\n<p><strong>命令:docker [container] start</strong><br>重新启动容器</p>\n<p><strong>命令:docker [container] restart</strong><br>命令会将一个运行态 的容器先终止，然后再重新启动</p>\n<h2 id=\"进入容器\"><a href=\"#进入容器\" class=\"headerlink\" title=\"进入容器\"></a>进入容器</h2><p><strong>命令:docker [container] attach [–detach-keys[;[]]] [–no-stdin] [–sig-proxy[;true]] CONTAINER</strong><br>命令支持三个主要选项：<br>－－ detach-keys ［＝［］］：指定退出 attach 模式的快捷键序列， 默认是 CTRL-p CTRL-q;<br>－－ no-stdin=trueifalse ：是否关闭标准输入，默认是保持打开<br>－－ sig-proxy=truelfalse ：是否代理收到的系统信号给应用进程，默认为 true</p>\n<p><strong>命令:docker [container] exec [-d|-detach] [ detach-keys[=[]]] [-i|–interactive] [ –privileged] [-t|–tty] [-u|user [=USER]] CONTAINER COMMAND [ARG . . . ]</strong><br>比较重要的参数有：<br>－ d, –detach 在容器中后台执行命令<br>－－ detach-keys =＂＂：指定将容器切回后台的按键<br>－ e, - - env= []：指定环境变量列表<br>－ i, –interactive=true | false ：打开标准输入接受用户输入命令， 默认值为false<br>－－ privileged=true|false 是否给执行命令以高权限，默认值为 false<br>－ t, –tty=true|false 分配伪终端，默认值为 false<br>－ u, –user =””：执行命令的用户名或 ID</p>\n<h2 id=\"删除容器\"><a href=\"#删除容器\" class=\"headerlink\" title=\"删除容器\"></a>删除容器</h2><p><strong>命令:docker [container) rm [-f|– force) [-1|-link] [-v|–volumes] CONTAINER [CONTAINER …]</strong><br>支持的选项包括<br>－ f, –force=false 是否强行终止并删除一个运行中的容器<br>－ 1, –link=false ：删除容器的连接 ，但保留容器<br>－ v, –volumes=false ：删除容器挂载的数据卷</p>\n<h2 id=\"导人和导出容器\"><a href=\"#导人和导出容器\" class=\"headerlink\" title=\"导人和导出容器\"></a>导人和导出容器</h2><p><strong>命令:docker [container) export [-o|–output [=””] ] CONTAINER</strong><br>导出容器是指，导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态<br>－o 选项来指定导出的tar 文件名，也可以直接通过重定向来实现</p>\n<p><strong>命令:docker import [-c|–change[=[]]] [-m|–message[=MESSAGE]] file|URL|-[REPOSITORY [:TAG]]</strong><br>导入容器</p>\n<h2 id=\"查看容器\"><a href=\"#查看容器\" class=\"headerlink\" title=\"查看容器\"></a>查看容器</h2><p><strong>命令:用 docker container inspect [OPTIONS] CONTAINER [CONTAINER . .. ］</strong><br>查看容器详情</p>\n<p><strong>命令:docker [container] top [OPTIONS] CONTAINER [CONTAINER…]</strong><br>查看容器内进程</p>\n<p><strong>命令:docker [container] stats [OPTIONS] [CONTAINER … ]</strong><br>查看统计信息,会显示 CPU 、内存、存储、网络等使用情况的统计信息<br>支持选项包括<br>－ a, -all ：输出所有容器统计信息，默认仅在运行中<br>－ format string ：格式化输出信息<br>－ no-stream ：不持续输出，默认会自动更新持续实时结果<br>－ no-trunc ：不截断输出信息</p>\n<h2 id=\"其他容器命令\"><a href=\"#其他容器命令\" class=\"headerlink\" title=\"其他容器命令\"></a>其他容器命令</h2><p><strong>命令格式为 docker [container] cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-</strong><br>复制文件<br>支持的选项包括<br>－ a, -ar chive ：打包模式，复制文件会带有原始的 uid/gid 信息<br>－ L, -follow-link ：跟随软连接。当原路径为软连接时＼默认只复制链接信息,使用该选项会复制链接的目标内容</p>\n<p><strong>命令: docker [container] diff CONTAINER</strong><br>查看变更</p>\n<p><strong>命令:docker container port CONTAINER [PRIVATE_PORT[/PROTO ］］</strong><br>查看端口映射</p>\n<p><strong>命令:docker [container] update [OPTIONS] CONTAINER [CONTAINER …]</strong><br>支持的选项包括：<br>－blkio-weight uintl6 ：更新块 IO 限制， 10 1000 ，默认值为 ，代表着无限制<br>－ cpu-period int ：限制 CPU 调度器 CFS (Completely Fair Scheduler ）使用时间，单位为微秒，最小 1000<br>－ cpu-quota int ：限制 CPU 调度器 CFS 配额，单位为微秒，最小 1000<br>－ cpu-rt period int ：限制 CPU 调度器的实时周期，单位为微秒<br>－ cpu-rt runtime int ：限制 CPU 调度器的实时运行时，单位为微秒<br>－ c, -cpu-shares in 限制 CPU 使用份额<br>－ cpus decimal ：限制 CPU 个数<br>－ cpuset-cpus string ：允许使用的 CPU 核，如 0-3, 0,1<br>－ cpuset mems string ：允许使用的内存块，如 0-3’ 0, 1<br>－ kernel-memor bytes ：限制使用的内核内存<br>－ m, -memory bytes 限制使用的内存<br>－memory-reservation bytes ：内存软限制<br>－memory-swap bytes ：内存加上缓存区的限制， 表示为对缓冲区无限制<br>－ restart stri 口g 容器退出后的重启策略</p>\n<h1 id=\"Docker仓库\"><a href=\"#Docker仓库\" class=\"headerlink\" title=\"Docker仓库\"></a>Docker仓库</h1><p>**仓库(Repository)**是集中存放镜像的地方，又分公共仓库和私有仓库</p>\n<h2 id=\"Docker-Hub-公共镜像市场\"><a href=\"#Docker-Hub-公共镜像市场\" class=\"headerlink\" title=\"Docker Hub 公共镜像市场\"></a>Docker Hub 公共镜像市场</h2><p><strong>Docker Hub Docker</strong> 官方提供的最大的公共镜像仓库，目前包括了超过 100 000<br>像，地址为 <strong>https: //hub.docker.com</strong></p>\n<h1 id=\"Docker数据管理\"><a href=\"#Docker数据管理\" class=\"headerlink\" title=\"Docker数据管理\"></a>Docker数据管理</h1><p>容器中的管理数据主要有两种方式<br><strong>数据卷 Data Volumes)</strong> 容器内数据直接映射到本地主机环境；<br><strong>数据卷容器（Data Volume Containers)</strong> 使用特定容器维护数据卷</p>\n<h2 id=\"数据卷\"><a href=\"#数据卷\" class=\"headerlink\" title=\"数据卷\"></a>数据卷</h2><p><strong>数据卷 Data Volumes</strong> 是一个可供容器使用的特殊目录，它将主机操作系统目录直接<br>映射进容器，类似于 Linux 中的 mout 行为<br><strong>数据卷可以提供很多有用的特性<br>    数据卷可以在容器之间共事和重用，容器间传递数据将变得高效与方便<br>    对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作<br>    对数据卷的更新不会影响镜像，解摘开应用和数据会一直存在 ，直到没有容器使用，可以安心地卸载它</strong></p>\n<h2 id=\"创建数据卷\"><a href=\"#创建数据卷\" class=\"headerlink\" title=\"创建数据卷\"></a>创建数据卷</h2><p><strong>命令:docker volume create</strong> </p>\n<h2 id=\"绑定数据卷\"><a href=\"#绑定数据卷\" class=\"headerlink\" title=\"绑定数据卷\"></a>绑定数据卷</h2><p><strong>命令:docker [container] run口命令的时候，可以使用 mount 选项来使用数据卷</strong><br>mount 项支持三种类型的数据卷，包括<br>    volume 普通数据卷，映射到主机／var/ lib /docke /vo lumes 径下<br>    bind ：绑定数据卷，映射到主机指定路径下<br>    tmpfs ：临时数据卷，只存在于内存中</p>\n<h2 id=\"数据卷容器\"><a href=\"#数据卷容器\" class=\"headerlink\" title=\"数据卷容器\"></a>数据卷容器</h2><p><strong>命令:docker run -it –volumes-from dbdata –name dbl ubuntu</strong><br>可以在其他容器中使用－－ volumes-from 来挂载 dbdata 容器中的数据卷，例如如创建 dbl db2 两个容器，并从 dbdata 容器挂载数据卷</p>\n<p><strong>命令:docker rm -v</strong><br>删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用此命令,指定同时删除关联的容器</p>\n<h2 id=\"利用数据卷容器来迁移数据\"><a href=\"#利用数据卷容器来迁移数据\" class=\"headerlink\" title=\"利用数据卷容器来迁移数据\"></a>利用数据卷容器来迁移数据</h2><p><strong>命令:docker run -volumes-from dbdata -v $ (pwd) : /backup - -name worker ubuntu tar<br>cvf /backup/backup.tar /dbdata</strong><br>利用 buntu 镜像创建了 个容器 worker 使用－ -volumes-from dbdata 参数<br>来让 worker 容器挂载 db data 容器的数据卷（ dbdata 数据卷）；使用－ $ (pwd) : /backup<br>参数来挂载本地的当前目录到 worke 容器的／backup<br>worker 容器启动后，使用 tar cvf /backup/backup.tar /dbdata 令将／dbdata<br>下内容备份为容器内的／backup/backup. tar ，即宿主主机当前目录下的 backup.tar</p>\n<p><strong>命令：docker run -v /dbdata –name dbdata2 ubuntu /bin/bash<br>docker run –volumes-from dbdata2 -v $(pwd) :/backup busybox tar xvf<br>/backup/backup.tar</strong><br>首先创建一个带有数据卷的容器 bdata2:，然后创建另一个新的容器，挂载 dbdata2 容器，并使用 untar 解压备份文件到所挂载的容器卷中</p>\n<h1 id=\"端口映射与容器互联\"><a href=\"#端口映射与容器互联\" class=\"headerlink\" title=\"端口映射与容器互联\"></a>端口映射与容器互联</h1><p><strong>命令:docker run -d -P training/webapp python app.py</strong><br>当容器中运行一些网络应用， 要让外部访问这些应用时， 可以通过-P或-p参数来指定端口映射。 当使用平（大写的）标记时， Docker 会随机映射一个 49000-49900 的端口到内部容器开放的网络端口,-p (小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定 一个容器。支持的格式有IP:HostPort:ContainerPortI IP:: ContainerPort I HostPort:ContainerPort</p>\n<p><strong>命令;docker run -d -p 5000:5000 training/webapp python app.py</strong><br>使用HostPort： ContainerPot格式本地的5000端口映射到容器的5000端口<br>多次使用-p标记可以绑定多个端口。例如:docker run -d -p 5000:5000 -p 3000:80 training/webapp py thon app.py</p>\n<p><strong>命令:docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py</strong><br>可以使用IP:HostPort： ContainerPort格式指定映射使用一个特定地址，比如<br>localhost地址127.0.0.1</p>\n<p><strong>命令: docker run -d -p 127.0.0.1::5000 training/webapp python app.py</strong><br>使用IP::ContainerPort绑定localhost的任意端口到容器的5000端口，本地主机<br>会自动分配一个端口：还可以使用udp标记来指定 udp端口：<br> docker run -d -p 127.0.0.1:5000:5000/udp training/webapp PY七hon app.py</p>\n<p><strong>命令: docker port nos talgic_rnorse 5000</strong><br>使用docker port来查看当前映射的端口配置，也可以查看到绑定的地址</p>\n<h1 id=\"互联机制实现便捷互访\"><a href=\"#互联机制实现便捷互访\" class=\"headerlink\" title=\"互联机制实现便捷互访\"></a>互联机制实现便捷互访</h1><p>**容器的互联(Iinking)**是一种让多个容器中的应用进行快速交互的方式。它会在源和接收容<br>器之间创建连接关系，接收容器可以通过容器名快速访问到源容器，而不用指定具体的IP地址</p>\n<p><strong>命令:docker run -d -P –name web training/webapp python app.py</strong><br>使用–name标记可以为容器自定义命名</p>\n<p><strong>命令:docker run -d -P –name web –link db:db taining/webapp python app.py</strong><br>创建一个新的web容器，并将它连接到db容器,db容器和web容器建立互联关系。<br>–link参数的格式为–link name: alias, 其中name是要链接的容器的名称 ,alias是别名</p>\n<h1 id=\"使用Dockerfile创建镜像\"><a href=\"#使用Dockerfile创建镜像\" class=\"headerlink\" title=\"使用Dockerfile创建镜像\"></a>使用Dockerfile创建镜像</h1><p>Dockerfile 是一个文本格式的配置文件， 用户可以使用 Dockerfile 来快速创建自定义的镜像</p>\n<h2 id=\"基本结构\"><a href=\"#基本结构\" class=\"headerlink\" title=\"基本结构\"></a>基本结构</h2><p>Dockerfile 由一行行命令语句组成， 并且支持以＃开头的注释行。一般而言，<br>Dockerfile 主体内容分为四部分：<strong>基础镜像信息</strong>、 <strong>维护者信息</strong>、 <strong>镜像操作指令</strong>和<strong>容器启动时执行指令</strong></p>\n<p>下面就是一个例子</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#This dockerfile uses the ubuntu image</span></span><br><span class=\"line\"><span class=\"comment\">#VERSION 2 - EDITION 1</span></span><br><span class=\"line\"><span class=\"comment\">#Author: docker_user</span></span><br><span class=\"line\"><span class=\"comment\">#Command format: Instruction [arguments / command] ..</span></span><br><span class=\"line\"><span class=\"comment\">#1、第一行必须指定 基础镜像信息</span></span><br><span class=\"line\">FROM ubuntu</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#2、维护者信息</span></span><br><span class=\"line\">MAINTAINER docker_user docker_user@email.com</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#3、镜像操作指令</span></span><br><span class=\"line\">RUN <span class=\"built_in\">echo</span> <span class=\"string\">&quot;deb http://archive.ubuntu.com/ubuntu/ raring main universe&quot;</span> &gt;&gt; /etc/apt/sources.list</span><br><span class=\"line\">RUN apt-get update &amp;&amp; apt-get install -y nginx</span><br><span class=\"line\">RUN <span class=\"built_in\">echo</span> <span class=\"string\">&quot;\\ndaemon off;&quot;</span> &gt;&gt; /etc/nginx/nginx.conf</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">#4、容器启动执行指令</span></span><br><span class=\"line\">CMD /usr/sbin/nginx</span><br></pre></td></tr></table></figure>\n<p>首行可以通过注释来指定解析器命令， 后续通过注释说明镜像的相关信息。 主体部分首<br>先使用FROM指令指明所基于的镜像名称， 接下来一般是使用LABEL指令说明维护者信息。<br>后面则是镜像操作指令， 例如RUN指令将对镜像执行跟随的命令。 每运行一条RUN指令，<br>镜像添加新的一层， 并提交。 最后是CMD指令， 来指定运行容器时的操作命令</p>\n<h2 id=\"指令说明\"><a href=\"#指令说明\" class=\"headerlink\" title=\"指令说明\"></a>指令说明</h2><p>Dockerfile 中指令的一般格式为 INSTRUCTION arguments, 包括 “配置指令” (配置<br>镜像信息）和 “操作指令” (具体执行操作）， 参见下表<br>Dockerfile中的指令及说明<br>分 类 指 令 说 明<br>| 分类 | 指令 | 说明 |<br>|–|–|–|<br>|配置指令  | ARG | 定义创建镜像过程中使用的变簸 |<br>| 配置指令|FROM |指定所创建镜像的基础镜像|<br>| 配置指令|LABEL |为生成的镜像添加元数据标签信息|<br>| 配置指令|EXPOSE |声明镜像内服务监听的端口|<br>|配置指令 |ENV| 指定环境变抵|<br>| 配置指令|ENTRYPOINT |指定镜像的默认入口命令|<br>|配置指令|VOLUME |创建一个数据卷挂载点|<br>|配置指令|USER |指定运行容器时的用户名或UID|<br>|配置指令|WORKDIR |配置工作目录|<br>|配置指令|ONBUILD| 创建子镜像时指定自动执行的操作指令|<br>|配置指令|STOPSIGNAL| 指定退出的信号值|<br>|配置指令|HEALTH CHECK |配置所启动容器如何进行健康检查|<br>|配置指令|SHELL |指定默认shell类型|<br>|操作指令|RUN|运行指定命令|<br>|操作指令|CMD|启动容器时刻指定默认执行程序|<br>|操作指令|ADD|添加内容到镜像|<br>|操作指令|COPY |复制内容到镜像|</p>\n<h2 id=\"配置指令\"><a href=\"#配置指令\" class=\"headerlink\" title=\"配置指令\"></a>配置指令</h2><p><strong>ARG</strong><br>定义创建镜像过程中使用的变量。<br>格式为 <code>ARG &lt;name&gt;[=&lt;default value&gt;]</code><br>在执行 docker build 时， 可以通过 -build-arg[=] 来为变量赋值。 当镜像编译成<br>功后， ARG 指定的变量将不再存在 (ENV 指定的变量将在镜像中保留）<br>Docker 内置了一些镜像创建变量， 用户可以直接使用而无须声明， 包括（不区分大小<br>写） HTTP PROXY 、 HTTPS PROXY 、 FTP PROXY 、 NO PROXY</p>\n<p><strong>FROM</strong><br>指定所创建镜像的基础镜像<br>格式为:<code>FROM &lt;image&gt; [AS &lt;name&gt;]</code> 或 <code>FROM &lt;image&gt;: &lt;tag&gt; [AS &lt;name&gt;]</code><br>或<code>FROM &lt;image&gt;@&lt;digest&gt; [AS &lt;name&gt;]</code><br>任何 Dockerfile 中第一条指令必须为FROM 指令。 并且， 如果在同一个Dockerfile 中创<br>建多个镜像时， 可以使用多个 FROM 指令（每个镜像一次）<br>为了保证镜像精简， 可以选用体积较小的镜像如Alpine或Debian 作为基础镜像。 例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ARG VERSION&#x3D;9.3 </span><br><span class=\"line\">FROM debian:$&#123;VERSION&#125; </span><br></pre></td></tr></table></figure>\n\n<p><strong>LABEL</strong><br>LABEL 指令可以为生成的镜像添加元数据标签信息。 这些信息可以用来辅助过滤出特<br>定镜像。<br>格式为: <code>LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...</code><br>例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LABEL version&#x3D;&quot;l.0.0-rc3&quot; </span><br><span class=\"line\">LABEL author&#x3D;&quot;yeasy@github&quot; date&#x3D;&quot;2020-01-01&quot; </span><br><span class=\"line\">LABEL description&#x3D;&quot;This 七ex七 illustra七es\\</span><br><span class=\"line\">that label-values can span mul七iple lines.&quot; </span><br></pre></td></tr></table></figure>\n\n<p><strong>EXPOSE</strong><br>声明镜像内服务监听的端口<br>格式为 <code>EXPOSE &lt;part&gt; [&lt;part/&lt;protocol&gt;... ]</code><br>例如：<br>EXPOSE 22 80 8443<br>注意该指令只是起到声明作用， 并不会自动完成端口映射<br>如果要映射端口出来， 在启动容器时可以使用 -P 参数 (Docker 主机会自动分配一个宿主<br>机的临时端口）或-p HOST_PORT:CONTAINER_PORT 参数（具体指定所映射的本地端口）</p>\n<p><strong>ENV</strong><br>指定环境变量， 在镜像生成过程中会被后续RUN指令使用， 在镜像启动的容器中也会存在<br>格式为 <code>ENV &lt;key&gt; &lt;value&gt;或ENV &lt;key&gt;=&lt;value&gt;</code><br>例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ENV APP VERSION&#x3D;l.0.0</span><br><span class=\"line\">ENV APP_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;app </span><br><span class=\"line\">ENV PATH $PATH:&#x2F;usr&#x2F;local&#x2F;bin </span><br></pre></td></tr></table></figure>\n<p>指令指定的环境变量在运行时可以被覆盖掉， 如 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run --env &lt;key&gt;&#x3D;&lt;value&gt; built_image</span><br></pre></td></tr></table></figure>\n\n<p>注意当一条 ENV 指令中同时为多个环境变量赋值并且值也是从环境变量读取时， 会为<br>变量都赋值后再更新。 如下面的指令， 最终结果为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">keyl&#x3D;valuel key2&#x3D;value2: </span><br><span class=\"line\">ENV keyl;value2 </span><br><span class=\"line\">ENV keyl;valuel key2;$&#123;keyl) </span><br></pre></td></tr></table></figure>\n\n<p><strong>ENTRYPOINT</strong><br>指定镜像的默认入口命令， 该入口命令会在启动容器时作为根命令执行， 所有传人值作<br>为该命令的参数<br>支持两种格式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ENTRYPOINT [&quot;executable&quot;, &quot;paraml &quot;, &quot;param2&quot;]: exec 调用执行</span><br><span class=\"line\">ENTRYPOINT command param 1 param2: shell 中执行</span><br></pre></td></tr></table></figure>\n<p>此时， CMD指令指定值将作为根命令的参数。<br>每个 Dockerfile 中只能有一个 ENTRYPOINT, 当指定多个时， 只有最后一个起效。<br>在运行时， 可以被 –entrypoint 参数覆盖掉， 如 docker run –entrypoint</p>\n<p><strong>VOLUME</strong><br>创建一个数据卷挂载点。<br>格式为 <code>VOLUME [&quot;/data]</code><br>运行容器时可以从本地主机或其他容器挂载数据卷， 一般用来存放数据库和需要保持的<br>数据等。</p>\n<p><strong>USER</strong><br>指定运行容器时的用户名或urn, 后续的RUN等指令也会使用指定的用户身份<br>格式为 <code>USER daemon</code><br>当服务不需要管理员权限时，可以通过该命令指定运行用户， 并且可以在 Dockerfile<br>建所需要的用户 例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RUN groupadd -r postgres &amp;&amp; useradd --no-log-init -r -g postgres postgres </span><br></pre></td></tr></table></figure>\n\n<p>要临时获取管理员权限可以使用 gosu 命令</p>\n<p> <strong>WORKDIR</strong><br>为后续的 RUN CMD ENTRYPO INT 指令配置工作目录<br>格式为 <code>WORKDIR path /to/workd ir</code><br>可以使用多个 WORKDIR 令，后续命令 果参数是相对路径， 会基于之前命令指定<br>的路径 例如</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WORKDIR &#x2F;a </span><br><span class=\"line\">WORKDIR b </span><br><span class=\"line\">WORKDIR c </span><br><span class=\"line\">RUN pwd </span><br></pre></td></tr></table></figure>\n\n<p>最终路径为/a/b/c<br>此，为了避免出错，推荐 WORKDIR 指令中只使用绝对路</p>\n<p> <strong>ONBUILD</strong><br>指定当基于所生成镜像创建子镜像时，自动执行的操作指<br>格式为 <code>ONBUILD [INSTRUCTION]</code><br>例如，使用如下的 Dockerfile 创建父镜像 Parent Imag ，指定 ONBUILD</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#Dockerfile for Parentimage </span><br><span class=\"line\">[...] </span><br><span class=\"line\">ONBUILD ADD . &#x2F; app&#x2F;src </span><br><span class=\"line\">ONBUILD RUN &#x2F;usr &#x2F; local&#x2F;bin&#x2F;python build --dir &#x2F; app&#x2F;src </span><br><span class=\"line\">[ ... ] </span><br></pre></td></tr></table></figure>\n\n<p>使用 docker build 命令创建子镜像 hild Image 时（ FROM Parentimage ），会首<br>先执行 Parent mage 配置的 ONBUI LD<br>#</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Dockerfile for Childimage </span><br><span class=\"line\">FROM Parenti mage </span><br></pre></td></tr></table></figure>\n\n<p>等价于在 Childimage Dockerfi 中添加了如下指令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#Automatically run the following when building Ch ldimage</span><br><span class=\"line\">. &#x2F; app&#x2F;src </span><br><span class=\"line\">RUN &#x2F;usr&#x2F; ocal&#x2F; bin python-bu ld --dir &#x2F;app&#x2F;src </span><br></pre></td></tr></table></figure>\n\n<p>由于 ONBUILD 指令是隐式执行的，推荐在使用它的镜像标签中进行标注， 例如 ruby:2.l\u0002build<br>ONBUILD 指令在创建专门用于自动编译、检查等操作的基础镜像时，十分有用</p>\n<p><strong>STOPSIGNAL</strong><br>指定所创建镜像启动的容器接收退出的信号值<br><strong>STOPSIGNAL signal</strong> </p>\n<p><strong>HEALTHCHECK</strong><br>配置所启动容器如 进行健康检查（如 判断健康与否），自 Docker 1.12 开始支持<br>格式有两种<br>HEALTH HEC [OPTI ONS] CMD comma nd ：根据所执行命令返回值是否为<br>判断<br>HEALTHCHEC NONE ：禁 基础镜像中的健康检查<br>OPTION 支持如下参数<br>-interva DURAT (d e fault: 30s ）：过多久检查一次<br>-timeout=DURATION (default: 30s 每次检查等待结果的超时<br>-retries (de fault : 3）：如果失败了，重试几次才最终确定失败</p>\n<p><strong>SHELL</strong><br>指定其他命令使用 she ll 时的默认 she ll 类型：<code>SHELL [” executable ”,”parameters”]</code><br>默认值为 ＂／ bin/sh ＂</p>\n<h2 id=\"操作指令\"><a href=\"#操作指令\" class=\"headerlink\" title=\"操作指令\"></a>操作指令</h2><p><strong>RUN</strong><br>运行指定命令<br>格式为 <code>RUN &lt;co mand ＞或 RUN [ &quot;executable &quot; , ” paraml ” , param2]</code><br>意后者指令会被解析为 JSON 数组，因此必须用双引号 前者默认将在 shell 终端中运行命<br>令，即／ bin /sh -c 后者则使用 exec 执行，不会启动 shell 环境<br>指定使用其他终端类型可以通过第二种方式实现，例如 <code>RUN [”/bin/bash&quot; , ” - C ” echo h e llo ”］</code><br>每条 RUN 指令将在当前镜像基础上执行指定命令，并提交为新的镜像层 当命令较长时<br>可以使用＼来换行 例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RUN apt-get update \\ </span><br><span class=\"line\">&amp;&amp; apt-get install -y libsnappy-dev zliblg-dev libbz2-dev \\ </span><br><span class=\"line\">&amp;&amp; rm -rf &#x2F;var&#x2F;cache&#x2F;apt \\</span><br><span class=\"line\">&amp;&amp; rm rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*</span><br></pre></td></tr></table></figure>\n<p> <strong>CMD</strong><br>CMD 指令用来指定启动容器时默认执行的命令<br>支持三种格式：<br><code>CMD ［executable ＂，” paraml param2 ＇］</code>：相当于执行 executable param 1 param2 ，推荐方式；<br><code>CMD command paraml param2</code> ：在默认的 Shell 中执行，提供给需要交互的应用；<br><code>CMD [”paraml ”，” param2</code> ：提供给 ENTRYPOINT 的默认参数<br>每个 Dockerfile 只能有 CMD 命令 如果指定了多条命令，只有最后一条会被执行<br>如果用户启动容器时候手动指定了运行的命令（作为 run命令的参数），则会覆盖掉<br>CMD 指定的命令</p>\n<p><strong>ADD</strong><br>添加内容到镜像<br>格式为 <code>ADD &lt;SrC&gt; &lt;dest&gt;</code><br>该命令将复制指定的＜ SrC ＞路径下内容到容器中的＜dest ＞路径下<br>其中＜ SrC ＞可以是 Dockerfile 所在目录的一个相对路径（文件或目录）；也可以是一个<br>URL ；还可以是一个 tar 文件（自动解压为目录） &lt;dest ＞可以是镜像内绝对路径，或者相<br>对于工作目录（WORK.DIR ）的相对路径<br>路径支持正则格式，例如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD *.c &#x2F;code&#x2F; </span><br></pre></td></tr></table></figure>\n\n<p><strong>COPY</strong><br>复制内容到镜像<br>格式为 <code>COPY &lt;SrC&gt; &lt;dest&gt;</code><br>复制本地主机的＜ SrC&gt; （为 Dockerfile 所在目录的相对路径，文件或目录）下内容到镜<br>像中的＜dest ＞。目标路径不存在时，会自动创建路径同样支持正则格式<br>COPY与ADD指令功能类似，当使用本地目录为源目录时，推荐使用 COPY</p>\n<h2 id=\"创建镜像-1\"><a href=\"#创建镜像-1\" class=\"headerlink\" title=\"创建镜像\"></a>创建镜像</h2><p>编写完成 Docker file 之后，可以通过 <code>docker [image] build</code> 命令来创建镜像<br>基本的格式为 <code>docker build [OPTIONS] PATH [ URL I -</code><br>该命令将读取指定路径下（包括子目录）的 Dockrfile ，并将该路径下所有数据作为上下<br>文（ Context ）发送给 Docker 服务端 Docker 服务端在校验 Dockerfile 格式通过后，逐条执行<br>其中定义的指令，碰到 ADD COPY RUN 指令会生成 层新的镜像 最终如果创建镜像成功，会返回最终镜像的 ID<br>命令选项<br>| 选项 | 说明 |<br>|–|–|<br>|-add-host list |添加自定义的主机名到IP映射 |<br>|-build-arg list |添加创建时的变量                  |<br>|-cache-from strings| 使用指定镜像作为缓存源       |<br>|-cgroup-parent string |继承的上层 cgroup          |<br>|-compress |使用gzip来压缩创建上下文数据         |<br>|-cpu-period int |分配的 CFS 调度器时长            |<br>|cpu-quota int |CFS 调度都总份额                    |<br>|-c, cpu-shares int |CPU权重                           |<br>|-cpuset-cpus string |多CPU 允许使用的CPU             |<br>|-cpuset-mems string |多CPU允许使用的内存               |<br>|-disable-content-trust |不进行镜像校验，默认为真  |<br>|-f, -file string | Dockerfile 名称              |<br>|-force-rm |总是删除中间过程的容器                    |<br>|-iidfile string |将镜像ID写入到文件          |<br>|-isolation string |容器的隔离机制                 |<br>|-label list | 配置镜像的元数据                     |<br>|-m,-memory bytes |限制使用内存盘                |<br>|memory-swap bytes | 限制内存和缓存的总盐           |<br>|-network string |指定RUN命令时的网络模式        |<br>|-no-cache |创建镜像不适用缓存                       |<br>|-platform string | 指定平台类型                    |<br>|-pull  |总是尝试获取镜像的最新版本                  |<br>|-q, -quiet | 不打印创建过程中的日志信息            |<br>|-rm | 创建成功后自动删除中间过程容器，默认为真      |<br>|-security-opt strings  |指定安全相关的选项        |<br>|-shm-size bytes| /dev/shm 的大小                  |<br>|-squash |将新创建的多层挤压放入到一层            |<br>|-stream | 持续获取创建的上下文                    |<br>|-t, -tag list |指定镜像的标签列表                |<br>|target string | 指定创建的目标阶段                 |<br>|-ulimit ulmit |指定 ulimit 的配置                |</p>\n<h2 id=\"选择父镜像\"><a href=\"#选择父镜像\" class=\"headerlink\" title=\"选择父镜像\"></a>选择父镜像</h2><p>大部分情况下，生成新的镜像都需要通过 FROM 指令来指定父镜像 父镜像是生成镜像<br>的基础，会直接影到所生成镜像的大小和功能,用户可 选择两种镜像作为父镜像，一种是所谓的基础镜像（ baseiage ），另外一种普通的镜像（往往由第三方创建，基于基础镜像）镜像较特殊，其 Dockerfile 中往往不存在指令，或者基于 scratch 镜像(FROM scratch ），这意味着其在整个镜像树中处于根的位置<br>下面的 Dockerfile定义了 个简单的基础镜像，将用户提前编译好的二进制 可执行文件binary到镜像中，运行容器 执行 inary 命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM scratch </span><br><span class=\"line\">ADD binary /</span><br><span class=\"line\">CMD ［<span class=\"string\">&quot;binary&quot;</span>]</span><br></pre></td></tr></table></figure>\n\n<p>普通镜像也可以作为父镜像来使用， 括常见的 busybox debian ubuntu</p>\n<h2 id=\"使用-dockerigno-文件\"><a href=\"#使用-dockerigno-文件\" class=\"headerlink\" title=\"使用 dockerigno 文件\"></a>使用 dockerigno 文件</h2><p>通过 .dockerignore文件（每一行添 一条匹配模式）来让 Docker忽略匹配路径或或文件，在建镜像时候不将无关数据发送到服务端<br>dockerignore 文件中模式语法支持 Golang 风格的路径正则格式：<br>“＊”表示任意多个字符；<br>“？”代表单个字符；<br>“！”表示不匹配（即不忽略指定的路径或文件）</p>\n<p><a href=\"https://blog.csdn.net/qq_20340547/article/details/103848953\">本文CSDN链接地址：https://blog.csdn.net/qq_20340547/article/details/103848953</a></p>"}],"PostAsset":[],"PostCategory":[{"post_id":"ckgnsue1y000abcvzbbekcf56","category_id":"ckgnsue1t0006bcvz9fvjh74q","_id":"ckgnsue29000ibcvz5jjx4n1l"},{"post_id":"ckgnsue1h0003bcvz1sa992uq","category_id":"ckgnsue1t0006bcvz9fvjh74q","_id":"ckgnsue2b000nbcvzh3x8hbfv"},{"post_id":"ckgnsue1s0005bcvzfs7627dy","category_id":"ckgnsue1t0006bcvz9fvjh74q","_id":"ckgnsue2b000pbcvz9bkvbw3o"},{"post_id":"ckgnsue1w0009bcvzf3cs7t6w","category_id":"ckgnsue1t0006bcvz9fvjh74q","_id":"ckgnsue2c000sbcvz6bfwci6x"},{"post_id":"ckgnsue1z000bbcvzen4n3ide","category_id":"ckgnsue2b000obcvz8pcwf2d0","_id":"ckgnsue2d000xbcvz1qy6duru"},{"post_id":"ckgnsue22000fbcvz4hs22rt5","category_id":"ckgnsue2b000obcvz8pcwf2d0","_id":"ckgnsue2e0010bcvzg06m9a7y"},{"post_id":"ckgnsue28000hbcvz6rhk1js3","category_id":"ckgnsue2b000obcvz8pcwf2d0","_id":"ckgnsue2f0013bcvz2nq14hiu"},{"post_id":"ckgnsue2a000mbcvzavpnc3yp","category_id":"ckgnsue2b000obcvz8pcwf2d0","_id":"ckgnsue2g0016bcvz4ttwbxcc"},{"post_id":"ckgnsue2n001fbcvzgica4yxb","category_id":"ckgnsue2b000obcvz8pcwf2d0","_id":"ckgnsue2o001hbcvz5e5c1uc5"},{"post_id":"ckgnsue2s001jbcvzd97a7n0u","category_id":"ckgnsue1t0006bcvz9fvjh74q","_id":"ckgnsue34001lbcvz2mnphedd"}],"PostTag":[{"post_id":"ckgnsue1y000abcvzbbekcf56","tag_id":"ckgnsue1v0007bcvz3u4u24ft","_id":"ckgnsue22000ebcvzgz1v9mmb"},{"post_id":"ckgnsue1h0003bcvz1sa992uq","tag_id":"ckgnsue1v0007bcvz3u4u24ft","_id":"ckgnsue28000gbcvzaamncn50"},{"post_id":"ckgnsue1s0005bcvzfs7627dy","tag_id":"ckgnsue1v0007bcvz3u4u24ft","_id":"ckgnsue2a000lbcvz7d3a5z9w"},{"post_id":"ckgnsue1w0009bcvzf3cs7t6w","tag_id":"ckgnsue1v0007bcvz3u4u24ft","_id":"ckgnsue2c000rbcvzahq34ajw"},{"post_id":"ckgnsue1z000bbcvzen4n3ide","tag_id":"ckgnsue2c000qbcvzgvchfm07","_id":"ckgnsue2d000vbcvz77a43rcg"},{"post_id":"ckgnsue22000fbcvz4hs22rt5","tag_id":"ckgnsue2c000ubcvzbwju20lm","_id":"ckgnsue2f0012bcvzb5vob9hi"},{"post_id":"ckgnsue22000fbcvz4hs22rt5","tag_id":"ckgnsue2e000ybcvz8ecjalns","_id":"ckgnsue2f0014bcvzarg016xd"},{"post_id":"ckgnsue28000hbcvz6rhk1js3","tag_id":"ckgnsue2f0011bcvzbknp96t1","_id":"ckgnsue2g0018bcvz7lrp4l6r"},{"post_id":"ckgnsue28000hbcvz6rhk1js3","tag_id":"ckgnsue2f0015bcvzggxc53m4","_id":"ckgnsue2g0019bcvz7hm5eu6a"},{"post_id":"ckgnsue2a000mbcvzavpnc3yp","tag_id":"ckgnsue2c000ubcvzbwju20lm","_id":"ckgnsue2k001cbcvz6hij61jp"},{"post_id":"ckgnsue2a000mbcvzavpnc3yp","tag_id":"ckgnsue2g001abcvz0qex42yk","_id":"ckgnsue2k001dbcvz1aoyd8kl"},{"post_id":"ckgnsue2a000mbcvzavpnc3yp","tag_id":"ckgnsue2h001bbcvz77qn8lng","_id":"ckgnsue2k001ebcvzcg9h5493"},{"post_id":"ckgnsue2n001fbcvzgica4yxb","tag_id":"ckgnsue2o001gbcvzb1oi8yl2","_id":"ckgnsue2o001ibcvzcwpsh3rf"},{"post_id":"ckgnsue2s001jbcvzd97a7n0u","tag_id":"ckgnsue2t001kbcvz4wpmfwig","_id":"ckgnsue36001mbcvz5vwcban6"}],"Tag":[{"name":"Data structure and algorithm","_id":"ckgnsue1v0007bcvz3u4u24ft"},{"name":"linux","_id":"ckgnsue2c000qbcvzgvchfm07"},{"name":"java","_id":"ckgnsue2c000ubcvzbwju20lm"},{"name":"annotations","_id":"ckgnsue2e000ybcvz8ecjalns"},{"name":"大数据","_id":"ckgnsue2f0011bcvzbknp96t1"},{"name":"zookeeper","_id":"ckgnsue2f0015bcvzggxc53m4"},{"name":"中间件","_id":"ckgnsue2g001abcvz0qex42yk"},{"name":"kafka","_id":"ckgnsue2h001bbcvz77qn8lng"},{"name":"maven","_id":"ckgnsue2o001gbcvzb1oi8yl2"},{"name":"Docker","_id":"ckgnsue2t001kbcvz4wpmfwig"}]}}